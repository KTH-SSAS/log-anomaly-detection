{
	"layers": 6,
	"feedforward_dim": 2048,
	"model_dim": 512,
	"attention_heads": 8,
	"vocab_size": 28199,
	"dropout": 0.1,

	"context_layers": 6,
	"context_feedforward_dim": 2048,
	"context_attention_heads": 8,
	"context_dropout": 0.1
}