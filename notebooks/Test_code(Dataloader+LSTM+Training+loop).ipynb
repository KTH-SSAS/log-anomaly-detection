{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHjrroZ3KHgR"
   },
   "source": [
    "*This is code to test the functionality of LSTM. If this code is messy, sorry in advance... this is my third or second time dealing with Pytorch...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1825,
     "status": "ok",
     "timestamp": 1616791087071,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "-jHRSWrKAiLV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "# torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7-RVMKFGxV_"
   },
   "source": [
    "# Parameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1826,
     "status": "ok",
     "timestamp": 1616791087076,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "U-taqYgpwa-l"
   },
   "outputs": [],
   "source": [
    "#manual setting for parameters\n",
    "cwd = os.getcwd()\n",
    "specpath = cwd + '/safekit/features/specs/lm/'\n",
    "datapath = cwd + '/data_examples/lanl/lm_feats/'\n",
    "layer_list = [10] #hidden units of each layer.\n",
    "lr = 1e-3 #learning rate .\n",
    "embedding_dim = 20 # one word/char will be mapped to this dimension.\n",
    "mb_size = 128 #size of mini batch.\n",
    "maxbadcount = 10\n",
    "patience = 20\n",
    "test = True\n",
    "delimiter = ' '\n",
    "direction = 'fwd' \n",
    "token_level = 'word'\n",
    "tiered = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1823,
     "status": "ok",
     "timestamp": 1616791087077,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "IvOiQ6jUwfEy"
   },
   "outputs": [],
   "source": [
    "if token_level == 'word':\n",
    "    datafolder = datapath + 'word_day_split/'\n",
    "    config = 'lanl_word_config.json'\n",
    "    jagged = False\n",
    "else:\n",
    "    datafolder = datapath + 'raw_day_split/'\n",
    "    config = 'lanl_char_config.json'\n",
    "    jagged = True\n",
    "\n",
    "if direction == 'fwd':\n",
    "    bid = False\n",
    "else: \n",
    "    bid = True\n",
    "\n",
    "if direction == 'fwd' and token_level == 'word':\n",
    "    skipsos = True\n",
    "else:\n",
    "    skipsos = False\n",
    "\n",
    "conf = json.load(open(specpath + config, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1616791087077,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "pU9M0LU_wgKr"
   },
   "outputs": [],
   "source": [
    "vocab_size = conf['token_set_size']  \n",
    "weekend_days = conf[\"weekend_days\"]\n",
    "sentence_length = conf['sentence_length'] - 1 - int(skipsos) + int(bid)\n",
    "if test:\n",
    "    files = conf[\"train_files\"] + conf[\"test_files\"] # 5000 lines from each of day 0, day 1 and day 2\n",
    "else:\n",
    "    files = [str(i) + '.txt' for i in range(conf[\"num_days\"]) if i not in weekend_days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKtKVxdBwlX7"
   },
   "source": [
    "# Class: Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1616791087078,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "ZcThzOufwu9k"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter % 10 == 0:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}. Best loss: {-self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3WovjO0wyFa"
   },
   "source": [
    "# Class: Dataset handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1814,
     "status": "ok",
     "timestamp": 1616791087079,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "lFqZ7Ld-MGQG"
   },
   "outputs": [],
   "source": [
    "def get_mask(lens, num_tokens):\n",
    "    \"\"\"\n",
    "    For masking output of lm_rnn for jagged sequences for correct gradient update.\n",
    "    Sequence length of 0 will output nan for that row of mask so don't do this.\n",
    "\n",
    "    :param lens: Numpy vector of sequence lengths\n",
    "    :param num_tokens: (int) Number of predicted tokens in sentence.\n",
    "    :return: A numpy array mask MB X num_tokens\n",
    "             For each row there are: lens[i] values of 1/lens[i]\n",
    "                                     followed by num_tokens - lens[i] zeros\n",
    "    \"\"\"\n",
    "    mask_template = torch.arange(num_tokens, dtype=torch.float)\n",
    "    return (mask_template < lens) / lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1810,
     "status": "ok",
     "timestamp": 1616791087079,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "WjEzp-zJwzO6"
   },
   "outputs": [],
   "source": [
    "class LazyTextDataset(Dataset):\n",
    "    def __init__(self, filename, sentence_length, skipsos, jagged, bidir, delimiter, transform=None):\n",
    "        self._filename = filename\n",
    "        self._total_data = 0\n",
    "        self.transform = transform\n",
    "        self.f = open(filename, 'r')\n",
    "        self._total_data = len(self.f.readlines()) - 1\n",
    "        self.f = open(filename, 'r')\n",
    "        \n",
    "        self.delimiter = delimiter\n",
    "        self.skipsos = skipsos\n",
    "        self.jagged = jagged\n",
    "        self.bidir = bidir\n",
    "        self.sentence_length = sentence_length\n",
    "       \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        l = self.f.readline()\n",
    "        sentence_length = self.sentence_length - 1 - int(self.skipsos) + int(self.bidir)\n",
    "        if l != '':\n",
    "            line = torch.tensor([int(k) for k in l.strip().split(self.delimiter)])\n",
    "            self.endx = len(line) - int(not self.bidir)\n",
    "            self.endt = len(line) - int(self.bidir)\n",
    "\n",
    "            self.datadict = {'line': line[0],\n",
    "                            'second': line[1],\n",
    "                            'day': line[2],\n",
    "                            'user': line[3],\n",
    "                            'red': line[4],\n",
    "                            'x': line[(5 + int(self.jagged) + int(self.skipsos)):self.endx],\n",
    "                            't': line[(6 + int(self.jagged) + int(self.skipsos)):self.endt]}\n",
    "            if self.jagged:\n",
    "                self.datadict['length'] = line[5]\n",
    "                self.datadict['mask'] = get_mask(self.datadict['length'] - 2*int(self.bidir) - int(self.skipsos), self.sentence_length - 2*int(self.bidir))\n",
    "                # assert np.all(self.datadict['lengths'] <= x.get_shape().as_list()[1]), 'Sequence found greater than num_tokens_predicted'\n",
    "                # assert np.nonzero(self.datadict['lengths'])[0].shape[0] == self.datadict['lengths'].shape[0], \\\n",
    "                #     'Sequence lengths must be greater than zero.' \\\n",
    "                #     'Found zero length sequence in datadict[\"lengths\"]: %s' % self.datadict['lengths']  \n",
    "\n",
    "        return self.datadict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._total_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handler for a tiered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineLMBatcher: \n",
    "    # It seems Pytorch dataset and dataloader can't sort users... so I needed to build it from scratch..\n",
    "    def __init__(self, file_path, conf, context_size, skipsos, jagged, bidir, batch_size=100, num_steps=5, delimiter=\" \", skiprows=0):\n",
    "        cols = ['line', 'second', 'day', 'user', 'red'] + [f'x_{i}' for i in range(conf['sentence_length'])]\n",
    "        self.day_df = dd.read_csv(file_path, names=cols, sep = ' ', blocksize=25e3)\n",
    "        self.user_id = [] # set()\n",
    "        self.lst_avail_id = []\n",
    "        self.pre_lst_avail_id = []\n",
    "        self.df_id = {}\n",
    "        self.len_id = {}\n",
    "        self.saved_lstm = {}\n",
    "        self.context_size = context_size\n",
    "        self.sel_part = 0\n",
    "        self.current_num_batch = 0\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.staggler_num_steps = 1\n",
    "        self.jagged = jagged\n",
    "        self.skipsos = skipsos\n",
    "        self.bidir = bidir\n",
    "        self.sentence_length = (conf['sentence_length'] - 1) - int(self.skipsos) + int(self.bidir)\n",
    "        self.empty = False\n",
    "        \n",
    "    def filter_partition(self):\n",
    "        partition = self.day_df.get_partition(self.sel_part)\n",
    "        current_ids = partition.user.drop_duplicates().compute().tolist()\n",
    "        for c_id in current_ids:\n",
    "            if c_id not in self.user_id:\n",
    "                self.df_id[c_id] = None\n",
    "                self.saved_lstm[c_id] = (torch.zeros((self.context_size[0])),\\\n",
    "                                         torch.zeros((len(self.context_size), self.context_size[0])),\\\n",
    "                                         torch.zeros((len(self.context_size), self.context_size[0])))\n",
    "            self.df_id[c_id] = pd.concat([self.df_id[c_id], partition[partition.user == c_id].compute()], axis=0)\n",
    "            self.len_id[c_id] = len(self.df_id[c_id])\n",
    "\n",
    "        self.user_id = current_ids + [usr for usr in self.user_id if usr not in current_ids]\n",
    "        self.sel_part += 1   \n",
    "\n",
    "    def update_len(self):\n",
    "        self.lst_avail_id = []\n",
    "        self.current_num_batch = 0\n",
    "        for j in self.user_id:\n",
    "            above_num_steps = self.len_id[j] >= self.num_steps\n",
    "            self.current_num_batch += above_num_steps\n",
    "            if above_num_steps and j not in self.lst_avail_id:\n",
    "                self.lst_avail_id.append(j)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while not self.empty:\n",
    "            output = []\n",
    "            datadict = {}\n",
    "            ctxt_vector = torch.tensor([])\n",
    "            h_state = torch.tensor([])\n",
    "            c_state = torch.tensor([])\n",
    "            while output == []:\n",
    "                if self.current_num_batch < self.batch_size and self.sel_part < self.day_df.npartitions: # Read a new partition\n",
    "                    self.filter_partition()\n",
    "                    self.update_len()\n",
    "                elif self.current_num_batch == 0 and self.sel_part == self.day_df.npartitions: # Activate staggler mode\n",
    "                    self.batch_size = self.batch_size * self.num_steps\n",
    "                    self.num_steps = self.staggler_num_steps\n",
    "                    self.sel_part += 1\n",
    "                    self.update_len()\n",
    "                elif self.current_num_batch > 0: # Output data\n",
    "                    for j in self.lst_avail_id[:self.batch_size]:\n",
    "                        output.append(self.df_id[j].iloc[0:self.num_steps].values)                    \n",
    "                        ctxt_vector = torch.cat((ctxt_vector, torch.unsqueeze(self.saved_lstm[j][0], dim = 0)), dim = 0)                    \n",
    "                        h_state = torch.cat((h_state, torch.unsqueeze(self.saved_lstm[j][1], dim = 0)), dim = 0)\n",
    "                        c_state = torch.cat((c_state, torch.unsqueeze(self.saved_lstm[j][2], dim = 0)), dim = 0)\n",
    "                        self.df_id[j] = self.df_id[j].iloc[self.num_steps:, :]\n",
    "                        self.len_id[j] = len(self.df_id[j])\n",
    "                    self.pre_lst_avail_id = self.lst_avail_id\n",
    "                    self.update_len()\n",
    "                    output = torch.tensor(output).long()\n",
    "                    batch = torch.transpose(output, 0, 1)\n",
    "                    endx = batch.shape[2] - int(not self.bidir)\n",
    "                    endt = batch.shape[2] - int(self.bidir)\n",
    "                    datadict = {'line': batch[:, :, 0],\n",
    "                                'second': batch[:, :, 1],\n",
    "                                'day': batch[:, :, 2],\n",
    "                                'user': batch[:, :, 3],\n",
    "                                'red': batch[:, :, 4],\n",
    "                                'x': [batch[0, :, 5 + self.jagged + self.skipsos:endx]] * self.num_steps,\n",
    "                                't': [batch[0, :, 6 + self.jagged + self.skipsos:endt]] * self.num_steps,\n",
    "                                'context_vector': ctxt_vector, #,['context_vector'],\n",
    "                                'c_state_init': torch.transpose(h_state, 0,1), #state_triple['c_state_init'],\n",
    "                                'h_state_init': torch.transpose(c_state, 0,1)} #state_triple['h_state_init']}\n",
    "                    if self.jagged:\n",
    "                        datadict['lens'] = [batch[0, :, 5] - self.skipsos] * self.num_steps\n",
    "                        datadict['masks'] = [get_mask(seq_length - 2 * self.bidir, sentence_length - 2 * self.bidir) for\n",
    "                                             seq_length in datadict['lens']]\n",
    "                else: # Empty dataset.\n",
    "                    self.empty = True\n",
    "                    break\n",
    "\n",
    "            yield datadict\n",
    "    \n",
    "    def update_state(self, ctxt_vectors, h_states, c_states):\n",
    "        ctxt_vectors = ctxt_vectors.data\n",
    "        h_states = torch.transpose(h_states.data, 0,1)\n",
    "        c_states = torch.transpose(c_states.data, 0,1)\n",
    "        for usr, ctxt_v, h_state, c_state in zip(self.pre_lst_avail_id[:self.batch_size], ctxt_vectors, h_states, c_states):\n",
    "            self.saved_lstm[usr] = (ctxt_v, h_state, c_state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = [10]\n",
    "num_steps = 3\n",
    "data_handler = OnlineLMBatcher(datafolder + files[0], conf, context_size, skipsos, jagged, bid, batch_size=64, num_steps=num_steps, delimiter=\" \", skiprows=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 217,  227,  230,  113,  146,  147,  149,  156,  161, 1538,  166,  167,\n",
      "          183,  186, 2496,  187,  193,  202,  205,  242, 2510, 1548,  181,  184,\n",
      "         2640,  111, 2096, 1542,  189, 2660,  221, 1621, 2731,  724, 2740, 2741,\n",
      "         2139,  803, 2150, 1500,  747,  764, 2858,  121,  150,  784,  177,  117,\n",
      "         2973,  126,  729,  832,  833,  841,  752,  797, 2088,  725, 1550, 3198,\n",
      "         3288, 2122, 3396, 1507],\n",
      "        [ 218,  228,  231,  114,  732,  148,  742,  157,  759, 1539,  762,  168,\n",
      "          794,  800, 2497,  188,  194, 2505,  206,  243, 2511, 1549,  182,  185,\n",
      "         2728,  112, 2097, 2110,  190, 2661,  222, 1622, 2732, 2093, 2806, 2808,\n",
      "         2745, 2295, 2151, 2790,  748,  765, 2859,  122,  151,  785,  178,  118,\n",
      "         2974,  127, 2979, 3003,  834, 2160,  753,  798, 3136, 2383, 2283, 3199,\n",
      "         3289, 2123, 3397, 2388],\n",
      "        [ 824,  229,  232,  717,  733,  741, 2101,  158, 2483, 1540,  763,  169,\n",
      "          795,  801, 2498,  804,  195, 3153,  207,  839, 2512, 2115, 1573,  799,\n",
      "         2788,  714, 2261, 2111,  191, 2662,  223, 2669, 2733, 2094, 2874, 2809,\n",
      "         3066, 2296, 2756, 2971,  749,  766, 3055,  123,  743,  786,  179, 2972,\n",
      "         2975,  728, 2980, 3004,  835, 3006, 3058, 3065, 3137, 2384, 2284, 3200,\n",
      "         3290, 2409, 3456, 2389]])\n",
      "tensor([[ 208,  825,  837, 2670, 3749,  128,  744,  153,  760, 2803,  170, 2297,\n",
      "          805,  196, 3216,  203, 3473,  233, 2789, 2385, 1506,  159, 1574,  836,\n",
      "          718, 2857, 3197,  719, 3943,  750, 1589,  802, 3995,  740,  180,  796,\n",
      "         4068, 4075, 2390, 2262,  152, 2405, 1569,  715, 2092, 2734, 4161, 2095,\n",
      "         3346, 4176, 2877, 2882, 2387,  716, 3056,  726,  727, 2116,  820,  821,\n",
      "         2580, 2581, 1508,  154],\n",
      "        [ 209,  826,  838, 3081, 3750,  129,  745,  746,  761, 2804,  768, 2747,\n",
      "          806,  197, 3468,  204, 3525,  234, 3054, 2386, 3861,  160, 1575, 3005,\n",
      "         1501, 3511, 3335,  720, 3996,  751, 3148, 1592, 4064, 1516, 2880, 1577,\n",
      "         4069, 4165, 3455, 2263, 1532, 2406, 1570, 2086, 2976, 2735, 4162, 2978,\n",
      "         3521, 4270, 4177, 4179, 2977, 2856, 4341, 3269, 3270, 2117, 3282, 3283,\n",
      "         2791, 2582, 3139,  155],\n",
      "        [ 210,  827, 2157, 3082, 3751,  130, 1528, 3757, 1543, 2805,  769, 2748,\n",
      "          807,  198, 3469, 3770, 3771,  235, 3854, 3138, 4074,  757, 1576, 3526,\n",
      "         1502, 3937, 3512,  721, 4667, 1535, 3946, 1593, 4065, 1517, 4007, 1578,\n",
      "         4155, 4251, 4076, 2643, 1533, 2645, 1571, 2087, 4158, 3263, 4246, 3201,\n",
      "         4174, 4358, 4271, 4600, 4250, 4340, 4665, 4345, 4346, 2118, 4368, 4369,\n",
      "         4443, 4444, 4447,  754]])\n",
      "tensor([[ 211,  828, 2158, 3291, 3752,  131, 1529, 1544, 3206,  770, 2749, 2499,\n",
      "          199, 3470, 4604,  236, 3855, 3264,  758, 2412, 1503, 3513,  722, 1536,\n",
      "         1594, 4066, 1518, 1579, 4156, 4254, 2644, 1534, 2646, 1572, 2641, 3451,\n",
      "         4247, 3517, 2119,  755, 1568, 2513,  734, 3463, 2757, 1523, 1541, 4610,\n",
      "         2472, 2504, 2506, 3189,  192,  119,  124, 2265, 2484, 2408, 2417,  224,\n",
      "          115, 3620,  140,  144],\n",
      "        [ 212,  829, 2309, 3292, 3857,  132, 1530, 1545, 3207,  771, 2750, 2500,\n",
      "          200, 3633, 4605,  237, 3856, 3265, 2482, 2413, 1504, 3625,  723, 1537,\n",
      "         1595, 4067, 1519, 1580, 4157, 4511, 2736, 2271, 2647, 2127, 2642, 3452,\n",
      "         4248, 3628, 2120,  756, 3145, 2514,  735, 3697, 2997, 1524, 2401, 4611,\n",
      "         3260, 3284, 3285, 3190, 2420,  120,  125, 2266, 2583, 2489, 2591,  831,\n",
      "          116, 3621,  141,  145],\n",
      "        [ 213, 1611, 2426, 3359, 3858,  133, 1531, 1546, 3344,  772, 3149, 2501,\n",
      "          201, 3634, 4912,  238, 4758, 3266, 3864, 2414, 2259, 3626, 1505, 2107,\n",
      "         2140, 4151, 1520, 1581, 4243, 4512, 2737, 2272, 2868, 2878, 3132, 4159,\n",
      "         4249, 3629, 2121, 2109, 4461, 2515,  736, 4525, 2998, 1525, 2402, 4681,\n",
      "         4759, 4777, 4778, 3191, 2657, 3576, 2860, 2267, 2867, 2584, 2746, 2663,\n",
      "         3575, 3622,  142,  731]])\n",
      "tensor([[2102, 2648,  773,  175, 2415, 2502, 5085,  808,  214, 1612, 2427, 3360,\n",
      "         2260, 4152, 5139, 3267, 2863, 1521, 1526, 1582, 2475, 5243, 3345, 2281,\n",
      "         3144, 3863, 2403, 2869, 4678, 3068, 2893, 3623, 5429, 4163, 4363, 3150,\n",
      "         4666,  134, 4818, 5541, 5545, 3271, 3272, 3273, 5607, 5609, 4682, 5690,\n",
      "         4981, 2738,  165, 5821, 4160, 3057, 2108,  840,  767, 4918, 6041, 6051,\n",
      "         3192, 2601,  830, 3527],\n",
      "        [2103, 2802,  774,  176, 2588, 2655, 5086,  809,  215, 1613, 2428, 3597,\n",
      "         2473, 4153, 5341, 3268, 3579, 1522, 1527, 1583, 2476, 5244, 3460, 2282,\n",
      "         5253, 4827, 2404, 3060, 5357, 3069, 2894, 5427, 5430, 4164, 4364, 3464,\n",
      "         5517,  135, 5525, 5542, 6174, 3940, 3941, 3942, 5608, 5610, 4683, 5691,\n",
      "         4982, 2739, 2407, 5822, 4960, 5825, 2273, 2509, 5977, 4919, 6134, 6154,\n",
      "         3193, 2602, 2598, 3884],\n",
      "        [2104, 2870,  775,  793, 2589, 2656, 5087,  810,  216, 1614, 2429, 3710,\n",
      "         2474, 4154, 5342, 3453, 5142, 3997, 2100, 1584, 5241, 5434, 3461, 2585,\n",
      "         5254, 5349, 2485, 3061, 5537, 3471, 2895, 5428, 5431, 5432, 5443, 3465,\n",
      "         5518,  136, 5526, 5543, 6255, 5603, 5604, 5605, 5907, 5611, 4684, 5692,\n",
      "         4983, 2792, 5787, 5901, 4961, 5826, 2274, 5845, 5978, 5988, 6135, 6155,\n",
      "         3194, 2603, 6251, 6252]])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(data_handler):\n",
    "    print(data['line'])\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5GDnhW1w1Vj"
   },
   "source": [
    "# Class: LSTM Models (To-do: tiered model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2115,
     "status": "ok",
     "timestamp": 1616791087388,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "CfBrtJ5Cw2qS"
   },
   "outputs": [],
   "source": [
    "\n",
    "def truncated_normal_(tensor, mean=0, std=1):\n",
    "    size = tensor.shape\n",
    "    tmp = tensor.new_empty(size + (4,)).normal_()\n",
    "    valid = (tmp < 2) & (tmp > -2)\n",
    "    ind = valid.max(-1, keepdim=True)[1]\n",
    "    tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\n",
    "    tensor.data.mul_(std).add_(mean)\n",
    "    return tensor    \n",
    "\n",
    "def initialize_weights(net, initrange = 1.0):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            initrange *= 1.0/np.sqrt(m.weight.data.shape[1])\n",
    "            m.weight.data = initrange * truncated_normal_(m.weight.data, mean = 0.0, std =1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Embedding):\n",
    "            truncated_normal_(m.weight.data, mean = 0.0, std =1)\n",
    "\n",
    "\n",
    "class Fwd_LSTM(nn.Module):\n",
    "    def __init__(self, layers, vocab_size, embedding_dim, jagged = False, tiered =False, context_vector_size = 0):\n",
    "        super().__init__()\n",
    "        self.layers = layers \n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tiered = tiered\n",
    "        self.bid = False\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        if self.tiered:\n",
    "            self.embedding_dim += context_vector_size  \n",
    "\n",
    "#         self.stacked_lstm = build_stacked_lstm(self.layers, self.embedding_dim, self.bid)\n",
    "        self.stacked_lstm = nn.LSTM(self.embedding_dim, self.layers[0], len(self.layers), batch_first = True, bidirectional = self.bid)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(self.layers[-1], self.vocab_size)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, sequences, lengths = None, context_vectors = None):\n",
    "        x_lookups = self.embeddings(sequences)  # batch x seq len x embedding\n",
    "        if self.tiered:\n",
    "            cat_x_lookups = torch.tensor([])\n",
    "            x_lookups= x_lookups.transpose(0,1) #  seq len x batch x embedding\n",
    "            for x_lookup in x_lookups: #for each batch x embedding.\\\n",
    "                x_lookup = torch.unsqueeze(torch.cat((x_lookup, context_vectors), dim=1), dim=0) # 1 x batch x embedding\n",
    "                cat_x_lookups = torch.cat((cat_x_lookups, x_lookup), dim = 0) # concatenate so n x batch x embedding (n length of a concatenated sequence)\n",
    "            x_lookups = cat_x_lookups.transpose(0,1) #batch x seq len x embedding + context \n",
    "            \n",
    "        lstm_in = x_lookups\n",
    "        if self.jagged:\n",
    "            lstm_in = pack_padded_sequence(lstm_in, lengths, batch_first=True)\n",
    "        lstm_out, (hx, cx)  = self.stacked_lstm(x_lookups)\n",
    "        if self.jagged: \n",
    "            lstm_out = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "\n",
    "        output = self.tanh(lstm_out)\n",
    "        tag_size = self.hidden2tag(output)\n",
    "        return tag_size, lstm_out, hx\n",
    "    \n",
    "class Bid_LSTM(nn.Module):\n",
    "    def __init__(self, layers, vocab_size, embedding_dim, jagged = False, tiered =False, context_vector_size = 0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = layers \n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tiered = tiered\n",
    "        self.bid = True\n",
    "        \n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        \n",
    "        if self.tiered:\n",
    "            self.embedding_dim += context_vector_size\n",
    "\n",
    "        self.stacked_bid_lstm = nn.LSTM(self.embedding_dim, self.layers[0], len(self.layers), batch_first = True, bidirectional = self.bid)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(self.layers[-1] * 2, self.vocab_size)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, sequences, lengths = None, context_vectors = None):   \n",
    "        x_lookups = self.embeddings(sequences) #batch size, sequence length, embedded dimension\n",
    "        if self.tiered:\n",
    "            x_lookups = torch.cat(x_lookups, context_vectors, dim=2)\n",
    "\n",
    "        lstm_in = x_lookups\n",
    "        if self.jagged:\n",
    "            lstm_in = pack_padded_sequence(lstm_in, lengths, batch_first=True)            \n",
    "            \n",
    "        lstm_out, (hx, cx)  = self.stacked_bid_lstm(x_lookups)\n",
    "        if self.jagged:\n",
    "            lstm_out = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "        output = self.tanh(lstm_out)\n",
    "        tag_size = self.hidden2tag(output)\n",
    "           \n",
    "        return tag_size, lstm_out, hx\n",
    "    \n",
    "\n",
    "class Context_LSTM(nn.Module):\n",
    "    def __init__(self, ctxt_lv_layers, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ctxt_lv_layers = ctxt_lv_layers \n",
    "        self.input_dim = input_dim\n",
    "        self.context_lstm_layers = nn.LSTM(self.input_dim, self.ctxt_lv_layers[0], len(ctxt_lv_layers), batch_first = True, bidirectional = bid)\n",
    "        \n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, lower_lv_outputs, final_hidden, context_h, context_c, seq_len = None):   \n",
    "        if seq_len is not None:\n",
    "            mean_hidden = torch.sum(lower_lv_outputs, dim = 1) / seq_len\n",
    "        else:\n",
    "            mean_hidden = torch.mean(lower_lv_outputs, dim = 1)\n",
    "        cat_input = torch.cat((mean_hidden, final_hidden[-1]), dim=1)\n",
    "        synthetic_input = torch.unsqueeze(cat_input, dim = 1)\n",
    "\n",
    "        output, (context_hx, context_cx) = self.context_lstm_layers(synthetic_input, (context_h, context_c))\n",
    "        return output, context_hx, context_cx \n",
    "    \n",
    "class Tiered_LSTM(nn.Module):\n",
    "    def __init__(self, low_lv_layers, ctxt_lv_layers, vocab_size, embedding_dim, context_vector_size, \n",
    "                 jagged = False, bid = False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bid = bid\n",
    "        if self.bid:\n",
    "            self.model = Bid_LSTM\n",
    "        else:\n",
    "            self.model = Fwd_LSTM\n",
    "        self.low_lv_layers = low_lv_layers \n",
    "        self.ctxt_lv_layers = ctxt_lv_layers\n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.low_lv_lstm = self.model(self.low_lv_layers, self.vocab_size, self.embedding_dim, \n",
    "                                      jagged = self.jagged, tiered = True, context_vector_size = self.ctxt_lv_layers[-1])\n",
    "        self.ctxt_lv_lstm = Context_LSTM(self.ctxt_lv_layers, low_lv_layers[-1] * 2)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, user_sequences, context_vectors, context_h, context_c, lengths = None):\n",
    "        self.ctxt_vector = context_vectors\n",
    "        self.ctxt_h = context_h\n",
    "        self.ctxt_c = context_c\n",
    "        tag_output = []\n",
    "        for sequences in user_sequences: #number of steps (e.g., 3), number of users (e.g., 64), lengths of sequences (e.g., 10)\n",
    "            tag_size, low_lv_lstm_outputs, final_hidden = self.low_lv_lstm(sequences, lengths = lengths, context_vectors = self.ctxt_vector)\n",
    "            self.ctxt_vector, self.ctxt_h, self.ctxt_c = self.ctxt_lv_lstm(low_lv_lstm_outputs, final_hidden, self.ctxt_h, self.ctxt_c, seq_len = lengths)\n",
    "            tag_output.append(tag_size)\n",
    "            self.ctxt_vector = torch.squeeze(self.ctxt_vector, dim = 1)\n",
    "        return tag_output, self.ctxt_vector, self.ctxt_h, self.ctxt_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gjJnoCzw7i7"
   },
   "source": [
    "# Function: Train and evaluate LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2113,
     "status": "ok",
     "timestamp": 1616791087389,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "p62Yl6TBw9Wr"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, early_stopping, dataloader, cuda, jagged, epochs=1):\n",
    "    \n",
    "    train_losses = []\n",
    "\n",
    "    flag = False\n",
    "    for i in range(epochs):\n",
    "        for j, data in enumerate(dataloader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            X = data['x']\n",
    "            Y = data['t']\n",
    "            L = data.get('length')\n",
    "            M = data.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            output, lstm_out, hx = model(X, lengths = L) \n",
    "            token_losses = criterion(output.transpose(1,2), Y)\n",
    "            if jagged:\n",
    "                masked_losses = token_losses * M\n",
    "                line_losses = torch.sum(masked_losses, dim = 1)\n",
    "            else:\n",
    "                line_losses = torch.mean(token_losses, dim = 1)\n",
    "                \n",
    "            loss = torch.mean(line_losses, dim = 0)\n",
    "\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            early_stopping(loss, model)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                early_stopping.early_stop = False\n",
    "                early_stopping.counter = 0\n",
    "                flag = True\n",
    "                break\n",
    "            scheduler.step()\n",
    "        if flag == True:\n",
    "            break\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(f'{i}th epoch loss: {loss.item()}')\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return model, train_losses\n",
    "\n",
    "def eval_model(model, criterion, dataloader, cuda, epochs=1):\n",
    "    \n",
    "    valid_losses = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.eval() # prep model for evaluation\n",
    "        for j, data in enumerate(dataloader):\n",
    "            X = data['x']\n",
    "            Y = data['t']\n",
    "            L = data.get('length')\n",
    "            M = data.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            output, lstm_out, hx = model(X, lengths = L)\n",
    "            token_losses = criterion(output.transpose(1,2), Y)\n",
    "            if jagged:\n",
    "                masked_losses = token_losses * M\n",
    "                line_losses = torch.sum(masked_losses, dim = 1)\n",
    "            else:\n",
    "                line_losses = torch.mean(token_losses, dim = 1)\n",
    "            loss = torch.mean(line_losses, dim = 0)\n",
    "            valid_losses.append(loss.item())\n",
    "    avg_valid_losses = np.mean(valid_losses)\n",
    "    print(f'Average validated loss: {avg_valid_losses}')\n",
    "        \n",
    "    return valid_losses, np.mean(valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tiered(model, criterion, optimizer, scheduler, early_stopping, data_handler, cuda, jagged, epochs=1):\n",
    "\n",
    "    for batch in data_handler:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        if data_handler.empty == False:\n",
    "            X = batch['x']\n",
    "            C_V =  batch['context_vector']\n",
    "            C_H = batch['c_state_init']\n",
    "            C_C = batch['h_state_init']\n",
    "            Y = batch['t']\n",
    "            L = batch.get('length')\n",
    "            M = batch.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            tag_outputs, ctxt_vector, ctxt_h, ctxt_c = model(X, C_V, C_H, C_C, lengths = L)    \n",
    "            data_handler.update_state(ctxt_vector, ctxt_h, ctxt_c)\n",
    "\n",
    "            total_loss = 0\n",
    "            for output, true_y in zip(tag_outputs, Y):\n",
    "                token_losses = criterion(output.transpose(1,2), true_y)\n",
    "                if jagged:\n",
    "                    masked_losses = token_losses * M\n",
    "                    line_losses = torch.sum(masked_losses, dim = 1)\n",
    "                else:\n",
    "                    line_losses = torch.mean(token_losses, dim = 1)\n",
    "                loss = torch.mean(line_losses, dim = 0)\n",
    "                total_loss += loss\n",
    "                \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            early_stopping(total_loss, model)\n",
    "        else:\n",
    "            print('Done')\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            early_stopping.early_stop = False\n",
    "            early_stopping.counter = 0\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZZoblRnxAmS"
   },
   "source": [
    "\n",
    "# Train model\n",
    "\n",
    "## Forward LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11235,
     "status": "ok",
     "timestamp": 1616791096516,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "TuqWq1c6xBTb",
    "outputId": "23c787ba-c1df-44be-bfd8-0ccf5f9b2d23",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 0head.txt\n",
      "Validation loss decreased (inf --> 10.263971).  Saving model ...\n",
      "Validation loss decreased (10.263971 --> 10.239969).  Saving model ...\n",
      "Validation loss decreased (10.239969 --> 10.227257).  Saving model ...\n",
      "Validation loss decreased (10.227257 --> 10.206769).  Saving model ...\n",
      "Validation loss decreased (10.206769 --> 10.192543).  Saving model ...\n",
      "Validation loss decreased (10.192543 --> 10.188947).  Saving model ...\n",
      "Validation loss decreased (10.188947 --> 10.183556).  Saving model ...\n",
      "Validation loss decreased (10.183556 --> 10.166779).  Saving model ...\n",
      "Validation loss decreased (10.166779 --> 10.159013).  Saving model ...\n",
      "Validation loss decreased (10.159013 --> 10.153627).  Saving model ...\n",
      "Validation loss decreased (10.153627 --> 10.143287).  Saving model ...\n",
      "Validation loss decreased (10.143287 --> 10.139612).  Saving model ...\n",
      "Validation loss decreased (10.139612 --> 10.131794).  Saving model ...\n",
      "Validation loss decreased (10.131794 --> 10.121206).  Saving model ...\n",
      "Validation loss decreased (10.121206 --> 10.117317).  Saving model ...\n",
      "Validation loss decreased (10.117317 --> 10.115479).  Saving model ...\n",
      "Validation loss decreased (10.115479 --> 10.113614).  Saving model ...\n",
      "Validation loss decreased (10.113614 --> 10.108002).  Saving model ...\n",
      "Validation loss decreased (10.108002 --> 10.091794).  Saving model ...\n",
      "Validation loss decreased (10.091794 --> 10.089017).  Saving model ...\n",
      "Validation loss decreased (10.089017 --> 10.081607).  Saving model ...\n",
      "Validation loss decreased (10.081607 --> 10.068887).  Saving model ...\n",
      "Validation loss decreased (10.068887 --> 10.048979).  Saving model ...\n",
      "Validation loss decreased (10.048979 --> 10.043945).  Saving model ...\n",
      "Validation loss decreased (10.043945 --> 10.033232).  Saving model ...\n",
      "Validation loss decreased (10.033232 --> 10.024587).  Saving model ...\n",
      "Validation loss decreased (10.024587 --> 10.023937).  Saving model ...\n",
      "Validation loss decreased (10.023937 --> 10.010077).  Saving model ...\n",
      "Validation loss decreased (10.010077 --> 10.001074).  Saving model ...\n",
      "Validation loss decreased (10.001074 --> 9.986796).  Saving model ...\n",
      "Validation loss decreased (9.986796 --> 9.980797).  Saving model ...\n",
      "Validation loss decreased (9.980797 --> 9.967492).  Saving model ...\n",
      "Validation loss decreased (9.967492 --> 9.959514).  Saving model ...\n",
      "0th epoch loss: 9.967363357543945\n",
      "Evaluating on 1head.txt\n",
      "Average validated loss: 9.960225009918213\n",
      "Training on 1head.txt\n",
      "Validation loss decreased (9.959514 --> 9.959026).  Saving model ...\n",
      "Validation loss decreased (9.959026 --> 9.945864).  Saving model ...\n",
      "Validation loss decreased (9.945864 --> 9.928414).  Saving model ...\n",
      "Validation loss decreased (9.928414 --> 9.902798).  Saving model ...\n",
      "Validation loss decreased (9.902798 --> 9.896873).  Saving model ...\n",
      "Validation loss decreased (9.896873 --> 9.885205).  Saving model ...\n",
      "Validation loss decreased (9.885205 --> 9.867270).  Saving model ...\n",
      "Validation loss decreased (9.867270 --> 9.858369).  Saving model ...\n",
      "Validation loss decreased (9.858369 --> 9.830804).  Saving model ...\n",
      "Validation loss decreased (9.830804 --> 9.828914).  Saving model ...\n",
      "Validation loss decreased (9.828914 --> 9.815516).  Saving model ...\n",
      "Validation loss decreased (9.815516 --> 9.786221).  Saving model ...\n",
      "Validation loss decreased (9.786221 --> 9.776108).  Saving model ...\n",
      "Validation loss decreased (9.776108 --> 9.741522).  Saving model ...\n",
      "Validation loss decreased (9.741522 --> 9.702362).  Saving model ...\n",
      "Validation loss decreased (9.702362 --> 9.651360).  Saving model ...\n",
      "Validation loss decreased (9.651360 --> 9.621658).  Saving model ...\n",
      "Validation loss decreased (9.621658 --> 9.613909).  Saving model ...\n",
      "Validation loss decreased (9.613909 --> 9.596995).  Saving model ...\n",
      "Validation loss decreased (9.596995 --> 9.593287).  Saving model ...\n",
      "Validation loss decreased (9.593287 --> 9.547441).  Saving model ...\n",
      "Validation loss decreased (9.547441 --> 9.539855).  Saving model ...\n",
      "0th epoch loss: 9.539855003356934\n",
      "Evaluating on 2head.txt\n",
      "Average validated loss: 9.540420198440552\n",
      "CPU times: user 1min 54s, sys: 41.3 s, total: 2min 35s\n",
      "Wall time: 57.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Fwd_LSTM(layer_list, vocab_size, embedding_dim) #For bidirectional LSTM: bid_LSTM(layer_list, vocab_size, embedding_dim)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction= 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=0.99)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "full_losses= []\n",
    "epochs = 1\n",
    "for i, file in enumerate(files[:-1]):\n",
    "    print(f'Training on {file}')\n",
    "    dataset = LazyTextDataset(datafolder + file, sentence_length, skipsos, jagged, bid, delimiter)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, num_workers=0)\n",
    "    model, train_losses = train_model(model, criterion, optimizer, scheduler, early_stopping, dataloader, cuda, jagged, epochs)\n",
    "    full_losses = full_losses + train_losses\n",
    "    \n",
    "    print(f'Evaluating on {files[i+1]}')\n",
    "    dataset = LazyTextDataset(datafolder + files[i+1], sentence_length, skipsos, jagged, bid, delimiter)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, num_workers=0)\n",
    "    valid_losses, avg_valid_loss = eval_model(model, criterion, dataloader, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 11229,
     "status": "ok",
     "timestamp": 1616791096517,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "wgNW3kYvxD85",
    "outputId": "6c6abf92-1313-4a07-8d68-1d58bde4bd6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y - Average loss')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAytklEQVR4nO3dd3gVZfr/8fedRkhIgTRqqJEqRUIVFBEboqhrQ1dZV+XH2t1dXcvu2v1i7421N+woCiKIVFEg9ACBICCdBEIJhJB2//44A4ZwQkKSkzlJ7td15TrnzMyZ+SQncGeeZ+Z5RFUxxhhjSgpwO4Axxhj/ZAXCGGOMV1YgjDHGeGUFwhhjjFdWIIwxxnhlBcIYY4xXPisQIvK2iGSISGqxZY1EZKqIpDuPDb28r6WILBKRJSKyQkRG+yqjMcaY0omv7oMQkdOA/cD7qtrFWfYkkKWqY0TkHqChqv6rxPtCnFyHRKQBkAr0V9WtPglqjDHGK5+dQajqLCCrxOLhwHvO8/eAi7y8L09VDzkv6/kyozHGmNIFVfPxElR1m/N8O5DgbSMRaQFMBNoBd5V29iAio4BRAOHh4T07dOhQ9YmNMaYWW7hw4U5VjfO2rroLxBGqqiLitX1LVTcBXUWkKfC1iHyhqju8bDcWGAuQnJysKSkpPs1sjDG1jYj8Xtq66m6+2SEiTQCcx4zjbeycOaQCA6shmzHGmGKqu0BMAEY6z0cC35TcQESai0h953lDYACwutoSGmOMAXx7mes44BegvYhsFpHrgTHAWSKSDgxxXiMiySLypvPWjsA8EVkKzASeVtXlvsppjDHGO59d5lrdrA/CGGNOnIgsVNVkb+vsElJjjDFeWYEwxhjjlRUIY4wxXtX5AnHgUAFPTk5j464ct6MYY4xfqfMFIju3gHfnbuCRiSvdjmKMMX6lzheIxlGh3Do4iakrdzBzTabbcYwxxm/U+QIB8NcBrWgdG85D364gr6DI7TjGGOMXrEAA9YIC+e+wTqzLPMC7c9e7HccYY/yCFQjHGR3iGdwhnhd+TCdjX67bcYwxxnVWIIr577BO5BcqYyanuR3FGGNcZwWimFax4Vw/sDVfLdrCN0u2uB3HGGNcZQWihFsHt6N3q0bc/skS3p5j/RHGmLrLCkQJYSFBvH99b87t3JiHv1vJmO/TqC0DGhpjzIlwbUY5fxYaHMgrV5/Cf79J5fWZv7F+537aN46ksKiIgiKlXVwDLktu4XZMY4zxKSsQpQgMEB69qAsJkaG8OC2dH1bsIDBACBDIL1TqhwQyrGtTt2MaY4zP2HwQ5VBUpIiAiFBQWMSfXpvLxqwcfrjzNOIjQn1yTGOMqQ42H0QlBQQIIgJAUGAAz1zenZy8Qu79crn1Txhjai0rEBXQLr4Bd5/bgWlpGXy+cLPbcYwxxid8OSf12yKSISKpxZY1EpGpIpLuPDb08r7uIvKLiKwQkWUicoWvMlbGdf1b0ad1Ix7+diWbd9tQ4caY2seXZxDvAueWWHYPME1Vk4BpzuuScoBrVbWz8/7nRSTahzkrJCBAePqybqgqd3yyhIN5hW5HMsaYKuWzAqGqs4CsEouHA+85z98DLvLyvjWqmu483wpkAHG+ylkZLRqF8cSlXVm0cTfXv7fAioQxplap7j6IBFXd5jzfDiQcb2MR6Q2EAL/5OlhFDevalKcv68Yv63Zx4/sp5OZbkTDG1A6udVKr5/KfUi8BEpEmwAfAdarqdZIGERklIikikpKZ6d5kP5ec0pynLu3Gz7/t5Mb3U9ibk8/O/YfYuCuH1duzyckrcC2bMcZUVHXfKLdDRJqo6janAGR420hEIoGJwP2q+mtpO1PVscBY8NwH4YvA5XVpz+aoKnd/uYxuD085al1IUACnto1hSKcEzuyQQOMou3fCGOP/qrtATABGAmOcx29KbiAiIcB44H1V/aJ641XOZcktaBwVSuqWfYTXCyQsJIiQoACWbNzDj6t2MH18KveTSp/Wjbg8uQXnndyYsBC7md0Y4598die1iIwDBgGxwA7gAeBr4DMgEfgduFxVs0QkGRitqjeIyJ+Bd4AVxXb3F1Vdcrzj+fJO6qqgqqzN2M8PK7bzxcLNbNiVQ4N6QVzYvSn3nteBiNBgtyMaY+qg491JbUNtuEBVWbBhN5+lbGL84i0MTIrlzWuTCQq0+xaNMdXLhtrwMyJC79aNePqybjwyvAszVmfy2KRVbscyxpijWAO4y67qk8hvmft5a8562sQ14Jq+Ld2OZIwxgBUIv3Df0I6s33mAByesoFVMGAOT/PK+QGNMHWNNTH4gMEB4cUQPkuIb8LcPF/Hm7HUcKrAb7owx7rIC4Sca1Avi7b/04pSWDXl04iqGPDuTCUu3UlRUOy4iMMbUPFYg/EjT6Pq8/9fefHB9bxrUC+a2cYsZ9tIcPvj1d/YezHc7njGmjrHLXP1UYZEyfvEW3py9jrTt2YQEBXBu58Zcd2oreiQeM0q6McZUiN0HUYOpKiu27uOzlE18s2Qr2bn53Do4iVsHt7P7JowxlWb3QdRgIkKXZlE8PLwLc+8ZzMU9mvPCtHSuenMe2/YedDueMaYWswJRg4TXC+KZy7vx7OXdSN2yl/NemM2bs9exenu2zY1tjKlydh9EDXTJKc3pkdiQv3+2hEcnrgJWEdsghH5tYxnRuwX928a6HdEYUwtYgaihWseGM/6mU9m8O4e5v+1i7tqdzE7fybdLt3Jmh3juHdqBdvERbsc0xtRg1kldi+TmF/LOzxt4dfpacvILubJXC+4+pwNRYTZSrDHGO+ukriNCgwP526C2zLz7DK7p25JPF2xi6IuzWbxxt9vRjDE1kBWIWqhReAgPXtiZL/7WHxG47PVfeHP2OuvINsacECsQtVj3FtFMvHUggzvE8+jEVdzwXgoz12SSm2/jPBljymad1LVcVFgwb1zTk3d+3sCTP6QxLS2DkKAA+rRuRN82MbSJDadFozBaNAyzvgpjzFGsk7oOOZhXyPwNWcxak8msNZmkZ+w/an1kaBCJMWEkNgqjRaMwerSI5syOCQTbHdvG1Fo21Ibxau/BfDZl5bB5dw6bsg6yMSuHTbtz2JiVw+asg+QVFhHbIIRLe7bgyl4taBUb7nZkY0wVc6VAiMjbwDAgQ1W7OMsaAZ8CrYANwOWqeswlNiIyGegLzFHVYeU5nhWIqlVYpMxKz2TcvI1MS8ugsEi5fkBr/n1+R0TE7XjGmCri1mWu7wLnllh2DzBNVZOAac5rb54CrvFdNFOWwADhjPbxjL02mbn3DGZE7xa8NWc9/5u9zu1oxphq4rMCoaqzgKwSi4cD7znP3wMuKuW904BsX2UzJyYhMpTHLjqZ87s24fFJaXy3bKvbkYwx1aC6ex8TVHWb83w7kFCZnYnIKBFJEZGUzMzMyqczpQoIEJ65rBvJLRvy98+WkrKhZO03xtQ2rl2eop7Oj0p1gKjqWFVNVtXkuLi4KkpmShMaHMj/rk2mWXR9bng/hc9TNrF6ezYFhUVuRzPG+EB13wexQ0SaqOo2EWkCZFTz8U0lNQwP4d3renHl2F+564tlAIQGB9C5aRR/7pvIhd2aERhgndjG1AbVXSAmACOBMc7jN9V8fFMFWsaEM+dfg1m/cz/Lt+wldcs+5qTv5M5Pl/L6jHX84+yTOKtTgl3tZEwN58vLXMcBg4BYYAfwAPA18BmQCPyO5zLXLBFJBkar6g3Oe2cDHYAGwC7gelX94XjHs8tc3VVUpExK3cazU9awbucBeiRG89KIHjRvGOZ2NGPMcdiNcqbaFBQW8cXCzTw+aRWhwYG899fedGwS6XYsY0wpbLhvU22CAgO4sncin4/uT4AIl7/xC7+u2+V2LGNMBViBMD7RvnEEX97Un/iIelz79ny+X76t7DcZY/yKFQjjM82i6/PF6P50aRrJLeMWs8gmLjKmRrECYXyqYXgI7/61N40jQ7nz0yXsP1TgdiRjTDlZgTA+FxkazHNXdGdTVg4PTVjhdhxjTDlZgTDVonfrRtw0qB2fL9zMJOuPMKZGsBnlTLW5fUgSs9Mzufer5fRIjCYwQFi5dR+rtmXTNDqUYV2b2l3YxvgRuw/CVKv1Ow8w9IXZFKqSV3D0GE4dGkdwz3kdOP2kOESEPTl5TFmxg+mrM7imX0v6t411KbUxtZfdKGf8ypQV25m6cgcdmkTSqUkkHZtEMDt9J0/9sJqNWTn0bxtDSFAAc9J3UlCkhAQGEBQojLuxL91aRLsd35haxQqEqRHyCor4aN7vvPzTWkKDAxnWtQnDujYlIbIef3p9LgcOFfL56H60jWvgdlRjao1KFQgRuQyYrKrZIvJv4BTgUVVdVPVRK84KRO1x+Hey+GB/63ce4NLX5hIaHMiXf+tP46hQt+IZU6tUdqiN/zjFYQAwBHgLeK0qAxpTnIgcMxJs69hw3r2uN3ty8rj27Xls3XPQpXTG1B3lKRCFzuP5wFhVnQiE+C6SMd6d3DyKsdcmszErhyHPzmTsrN/It8mKjPGZ8hSILSLyBnAFMElE6pXzfcZUuVPbxTL1ztPp1yaGxyelMezFOcxJ38m2vQfZm5NvBcOYKlSePogw4FxguaqmOzPBnayqU6ojYHlZH0TdoqpMWbmDhyasYOve3KPWtYwJ4+2/9LLObGPKobKd1G2Bzap6SEQGAV2B91V1TxXnrBQrEHVTTl4B09Myyc7N50BeIQcOFfD+LxsQET6+oQ9JCRFuRzTGr1W2QCwBkoFWwCQ804R2VtWhVRuzcqxAmMPWZmQz4n/zKCpSPr6xL+0bW5EwpjSVvYqpSFULgEuAl1T1LqBJVQY0piq1i4/gk1F9CQoUrhz7Cyu27nU7kjE1UnkKRL6IjACuBb5zlgWX9SYReVtEMkQktdiyRiIyVUTSnceGpbx3pLNNuoiMLM83YkxxbeMa8OmofoQGB3Lpa7/w5ux1FFgHtjEnpDwF4jqgH/CYqq4XkdbAB+V437t4OreLuweYpqpJwDTn9VFEpBHwANAH6A08UFohMeZ4WsWGM/6mUzm1XQyPTlzFxa/OtbMJY05AmQVCVVcC/wSWi0gXPB3WT5TjfbOArBKLhwPvOc/fAy7y8tZzgKmqmqWqu4GpHFtojCmXxlGh/O/aZF656hS27c3lwpd/5pXpa92OZUyNUOZw386VS+8BGwABWojISKcAnKgEVT08GcB2IMHLNs2ATcVeb3aWecs2ChgFkJiYWIE4pi4QEc7v2oQB7WK5/+vlPPXDagoKlduHJLkdzRi/Vp75IJ4BzlbV1QAichIwDuhZmQOrqopIpUYKVNWxwFjwXMVUmX2Z2i8qLJgXr+xBvaBAnvtxDYEBcMtgKxLGlKY8fRDBh4sDgKquoRyd1KXY4dxoh/OY4WWbLUCLYq+bO8uMqbSAAOHJS7tySY9mPD1lDa/OKL25KTe/kBmrM6xz29RZ5TmDSBGRN4EPnddXAxW94WACMBIY4zx+42WbH4DHi3VMnw3cW8HjGXOMwADhqcu6UaTKk5NXs3bHfv46oDVdmkUBUFSkfLtsK098n8bWvbncOeSkKmuOys7NZ+mmvSzauJvVO7K5c0gS7eLtPg3jn8pTIP4G3Azc5ryeDbxa1ptEZBwwCIgVkc14rkwaA3wmItcDvwOXO9smA6NV9QZVzRKRR4AFzq4eVtWSnd3GVEpggPD0Zd2Ii6jHh79u5KvFW0hu2ZDh3ZvyxaItLN20h85NI2kb34CXfkrnrE4JdGoaWeHj7T2Yz98+XMgv63ahCiIQKML+3ALe+2vvKvzOjKk6NmGQqfP2Hszn85RNfPDr7/y+K4eEyHrcdU4HLunRjL0H8znruZkkRIby9c2nEhz4R6vsN0u2sHjjHv59fkeCAktvrT1UUMi1b81n0cbdjD69Lb1aNaJbi2jGzd/ImO/T+Hx0P3q1alQd36oxx6jQUBsishwotXqoateqiVc1rECYyioqUlZu20ebuHDCQv44uZ6cup3RHy7kH2edxK1nJlFQWMSY79N4c856AO4YksQdQ04qdZ+3frKYicu28cKV3Rne/Y8L8nLyCjjtyRm0jQvnk1F9j5kDw5jqcLwCcbwmpmE+ymOMXwoIkCP9EMWd26UxF3Rryos/pdOnTQwvT1/LrDWZjOzXkj0H83lxWjoD2sWS7OUs4LFJq5i4bBv3De1wVHEACAsJ4pYz2vLgtyv5ee0uBiTF+ux7M6YirInJmHLIOpDHWc/OZNeBPIIDhYeHd2FE70Syc/M5/8U5FBYpk24fSFR9zwV+BYVFvDx9Lc//mM51p7biv8M6eT1DOFRQyBlPzSA+MpTxN/W3swhT7So7WJ8xdV6j8BCeuqwrHRpH8NENfRnR23NjZkRoMC9c2Z0d+3K5b/xyVJUfV+7gnOdn8fyP6Qzv3pT/nO+9OADUCwrktjOTWLJpD9NWebvq2xj32BmEMVXglelreeqH1bRPiGD1jmzaxIVz73kdGdIxvsyzgvzCIoY8O5OwkCAm3jqAgAA7izDVp9JnECJSX0TaV20sY2qP0ae3ZWBSLJn7D/Hw8M78cMdpnNUpoVxNRsGBAdw55CRWbdvHf75JpaiodvzRZmq+8ozFdAHwNBACtBaR7njuTbjQx9mMqTECA4R3/tILhaMuhS2v4d2bsmr7Pt6YuY7s3AKeubxbhfZjTFUqz41yD+IZdnsGgKoucYb8NsYUc7x7IcoiItx7Xkei6gfz5OTV7D9UwCtXnUL9kMAqTGjMiSnXhEGqWnIQfTsHNsYHbhrUjscu7sL01RmMfGc+ufmFbkcydVh5CsQKEbkKCBSRJBF5CZjr41zG1FlX92nJ81d0Z8GGLO79ynNllDFuKE+BuBXoDBzCM8z3PuAOH2Yyps4b3r0Zfx9yEuMXb+Et545tY6pbmX0QqpoD3O98GWOqyS2D27Fy2z4en7SK9o0jGJgU53YkU8eU5yqmbzm2z2EvniG/31DVXF8EM6auE/GMOLt+5wFu+XgxE245lZYx4W7HMnVIeZqY1gH7gf85X/uAbOAk57UxxkfC6wUx9ppkROD/fbDQJi8y1ao8BaK/ql6lqt86X38GeqnqzcApPs5nTJ2XGBPGmEtOJm17Np+mbCr7DcZUkfIUiAYiknj4hfO8gfMyzyepjDFHOadzY3q1ashzU9PZf6jA7TimjihPgfgHMEdEpovIDDwzyv1TRMKB93wZzhjjISLcN7QjO/cfYuysdW7HMXVEea5imiQiSUAHZ9HqYh3Tz/sqmDHmaD0SG3J+1yb8b9Y6ru6TSEJkqNuRTC1X3rEBkoD2QDfgchG5tjIHFZHbRSRVRFaIyB1e1jcUkfEiskxE5otIl8ocz5ja4l/ndKCgqIhnp6wp93s27srhtCens2CDTe1uTkyZBUJEHgBecr7OAJ4EKjxQn/Of/Y14xnfqBgwTkXYlNrsPWOJMa3ot8EJFj2dMbZIYE8Y1fVvx+cJNrN6eXa73jJm8io1ZOXy6wDq4zYkpzxnEpcCZwHZVvQ7Pf+rHzstYfh2Beaqao6oFwEzgkhLbdAJ+AlDVNKCViCRU4pjG1Bq3Dm5HeL0gbvpoIV8t2nzc8ZoWbMhi0vLtRNQLYsqK7eQV2GWypvzKUyAOqmoRUCAikUAG0KISx0wFBopIjIiEAUO97G8pTtEQkd5AS6B5JY5pTK3RMDyEF67sjgJ//2wp/cf8xJOT08jIPvqe1aIi5dHvVtI4MpTHLjmZfbkF/LJulzuhTY1UngKRIiLReG6KWwgsAn6p6AFVdRXwBDAFmAwsAUr+CTQGiBaRJXjGglrsZRtEZJSIpIhISmZmZkUjGVPjDO6QwLS/n86H1/ehZ8uGvD7zN4a+MIdFG3cf2ebbZVtZunkvd53TnrM7JdCgXhDfL9/mYmpT0xx3ylHxTIfVXFU3Oa9bAZGquqzKAog8DmxW1VePk2E90FVV95W2H5ty1NRlq7dnc+P7KWzfm8uYP53M0JObMPjpGTRqEMKEmz3TmN7+yWJmrclkwf1DKjV3haldKjzlqHqqx6RirzdURXEQkXjnMRFPU9LHJdZHi0iI8/IGYNbxioMxdV37xhF8c/OpnNIymr9/tpQr3viFrXtz+ff5nY7McX1elybszsln3nq7msmUT3n+jFgkIr2q+LhfishK4FvgZlXdIyKjRWS0s74jkCoiq4HzgNur+PjG1DoNw0P44Po+/LlvIks37+XsTgn0bRNzZP2g9nGEhQTyfao1M5nyOW4TE4CIpAHtgN+BA4DgObno6vt45WdNTMb8Ye5vO+ncNIqo+sFHLb/5o0XMW5/FvPvOJNA5szB12/GamMozJ/U5VZzHGONj/dvGel1+3smNmbh8GykbsujjnF3MTs9kwfosbj0ziWDrmzDFlGeojd9FZACQpKrviEgcfwzWZ4ypQc5oH0+9oAC+T91O2/gGPPLdSr5ZshWAfbkFPHhhZ5cTGn9SngmDHgCS8Qy18Q4QDHwInOrbaMaYqhZeL4hB7eMYv3gL4xdvISevgNsGt2PvwXzenbuBbi2iuLiH3XJkPMrTxHQx0APP/Q+o6lYRifBpKmOMz1zQrSk/rNhBr1YNefzik0lKiCC/sIi07dnc8+VykuIj6NKsMoMlmNqiPA2Oec7lrgrgDPNtjKmhzj+5CZNuG8ino/qRlOD5Wy84MIBXrj6FRuEh/L8PFpJ1wKZ6MeUrEJ+JyBt47my+EfgRm2rUmBpLROjUNPLI/RGHxTaox+t/7knm/kPc+ekSyrrC0dR+ZRYIVX0a+AL4Ek8/xH9V9SVfBzPGVL9uLaL517kdmLkmk9npO92OY1xWnuG+/w6sVNW7VPWfqjq1GnIZY1zy576JNI0K5Zmpa+wsoo4rTxNTBDBFRGaLyC027LYxtVu9oEBuPTOJpZv28FNaxjHrs3PzKSi0YcPrgvI0MT2kqp2Bm4EmwEwR+dHnyYwxrrm0Z3MSG4XxbImziBVb9zLwyelc9eY8DhWUPg+FqR1O5LbJDGA7sAuI900cY4w/CA4M4LYzk1ixdR8/rNgOwKpt+/jzm/MIFGH++izu+nwZRUVHN0Fl5+bz0bzf2X+owI3YpoqVpw/iJhGZAUwDYoAb/W0cJmNM1buoe1PaxIbz3NR00rbv4+o351EvKJCvburPv87twISlW3l6yuoj2y/euJvzX5zD/eNTeXzSKheTm6pSnhvlWgB3qOoSABEJFZHLVPVznyYzxrgqKDCA24ckcfsnSxj+8s9E1Q9m3Ki+tIwJZ/Tpbdi0O4dXZ/xGk+j67M3J47kf02kcGco5nRMYN38jV/ZqQdfm0W5/G6YSyhzNFUBEAvEM2jcCOBuYraqX+jjbCbHRXI2pekVFyvkvzWHn/kN8MqovbeP+GIatoLCIG95PYcZqz2yOF3RryqMXdUEEznxmJk2jQhl/06nH3G9h/MvxRnMta0a504Gr8MwbPR/P+EttVDXHF0ErwwqEMb6x92A+wDFDhwPsP1TAA9+s4NR2MVzcoxmeCSBh/OLN3PnpUv7vkpMZ0TuxWvOaE1OhAiEim4GNwGvA16qaLSLrVbW176JWnBUIY/yHqnLFG7+SnpHNT/8YRMPwkLLfZFxR0SlHvwCaAlcAFzhjMNldM8aYMokID1/UmX25BTxVrCPb1CylFghVvQNoDTwDDAJWA3EicrmI2HwQxpjj6tA4kpH9WjFu/kbSttuU8jXRcS9zVY/pqjoKT7EYAQwHNlRDNmNMDXfbme0ICw7klem/uR3FVEC5b5RT1XxV/U5Vr8Zz6WuFicjtIpIqIitE5A4v66NE5FsRWepsc11ljmeMcUd0WAh/7teSicu2si5zv9txzAmq0AS0qnqwogcUkS7AjUBvoBswTETaldjsZjwDBHbD07z1jIhYL5cxNdANA9oQHBjAazPsLKKmcWOG8o7APFXNUdUCYCZwSYltFIgQzzVzDYAswO7dN6YGiouox4jeiYxfvIXNu/3uCnlzHCdUIESkcRUcMxUYKCIxIhKG5x6Lkk1WL+MpJFuB5cDtqnrM8JEiMkpEUkQkJTMzswqiGWN8YdRpbRCBN2auO2adDSnuv070DGJSZQ+oqquAJ4ApwGRgCVByWMhznOVNge7AyyIS6WVfY1U1WVWT4+LiKhvNGOMjTaPr86dTmvNpyiYy9uWiqkxduYMLXprDuc/PZm9OvtsRjRcnWiCq5J55VX1LVXuq6mnAbmBNiU2uA75yrqJaC6wHOlTFsY0x7vjboLYUFBZx/9epXPjyz9z4fgp7Duaxbud+bhm3yOaY8EMnWiCqZC5qEYl3HhPx9D98XGKTjcCZzjYJeKY6Pfbc1BhTY7SMCefCbk2ZunIHew7m8eSlXfnpH4N4ZHgXZqfvZMz3aW5HNCWUZzTXI1T11So67pciEgPkAzer6h4RGe0c43XgEeBdEVmO56zlX6pqE+QaU8M9dGEXhp7chDM6xBMc6Pn79MreiaRtz+bNOetp3ziCy5IrdRW9qUInVCCqiqoO9LLs9WLPt+IZNdYYU4tEhQVzdudjr3X59/kdSc/I5v7xqeTmF1IvKJDcgkLyCoo4q1MCLWPCXUhrXCkQxhhTXFBgAK9cdQoXvzqX/3yz4qh1M9dk8sH1fVxKVreVWSBE5FbgQ1XdXQ15jDF1VHRYCN/fPpDNuw8SGhxAaHAg7/68gZenr2XjrhwSY8LcjljnlKeTOgFYICKfici5cnjAd2OMqWKhwYG0i29A84ZhxDaox9V9EwkQGLdgo9vR6qQyC4Sq/htIAt4C/gKki8jjItLWx9mMMXVck6j6nNkxgc9TNpFXYJfBVrdyXeaqnlsdtztfBUBD4AsRedKH2Ywxhqv6JLJzfx5TV+5wO0qdU2aBcEZeXQg8CfwMnKyqfwN6An/ycT5jTB13WlIczaLr8/H8392OUueU5wyiEXCJqp6jqp+raj6AMzbSMJ+mM8bUeYEBwojeLfh57S427Dxw1LrjjeO0JyePhb9n+TperVaePogHVNVr6XbGVTLGGJ+6PLkFQQHCuPmezurM7EPc+9Vy2v9nMos3er/A8tmpa7j09V9Ytc1ms6souw/CGOP34iNDGdIxgc8XbiYqLJhXp/9Gbr5njM8JS7fSI7HhUdurKtNWZaAK//d9Gu//tbcbsWs8N+aDMMaYE3ZVn0SyDuTx5OTV9G3TiB/uPI2BSbFOITi6qSk9Yz9b9hykc9NIZq3JZNYamw6gIqxAGGNqhAHtYrn73PZ8eH0f3hzZi7ZxDTizYwIbs3L4rcR0pj+lZQDw6tWn0KJRfR6ftIrCIpt34kRZgTDG1AgBAcJNg9oxICn2yLLBHeIB+HFVxlHb/pSWQYfGEbSMCefuczqQtj2brxZtrta8tYEVCGNMjdU0uj6dmkTyU7ECsfdgPgt/332keAzr2oRuLaJ5ZsoaDuaVnJvMHI8VCGNMjTakYzwpv2ex+0AeALPTMyksUs5wCoSIcP/Qjmzfl8tbc2xamRNhBcIYU6MN7phAkcKMNZ6ziJ/SMoiqH0yPFtFHtunduhHndE7g+R/TmZy63aWkNY8VCGNMjda1WRRxEfWYtiqDoiJl5upMTj8pjqDAo/97e/qybpzcPIpbPl5kRaKcrEAYY2q0gABhcPt4Zq7JZNHG3ew6kHek/6G4iNBg3v9rbysSJ8BulDPG1HiDO8bzacomnpy8mgCB00+K87rd4SJx7dvzueXjRYzo7RlOPK9QKSgsom18Awa1j6N9QgQ2s4FLBUJEbgduxDPf9P9U9fkS6+8CrnZeBgEdgThVtYFVjDHHGJgUS0hQAPM3ZNGzZUMahoeUuu3hInHTR4v4atFmggIDCA4MIEDg84WbGfN9Go0jQzmjQxz3nNeRqPrB1fid+JdqLxAi0gVPcegN5AGTReQ7VV17eBtVfQp4ytn+AuBOKw7GmNKEhQTRv20MM1ZnckZ772cPxUWEBnudxnTb3oPMXJ3JzDWZfLJgEwmRodwx5CRfRK4R3OiD6AjMU9UcVS0AZgKXHGf7EcC4aklmjKmxzu7UGIAzOyZUeB9NoupzZe9EXvtzTzo3jeSX33ZVVbwayY0CkQoMFJEYEQkDhgItvG3orD8X+LKU9aNEJEVEUjIzbawVY+qyK3q1YOJtA+jYJLJK9tevTQyLN+05MihgXVTtBcIZIvwJYAowGVgClPYJXAD8XFrzkqqOVdVkVU2Oiyv7tNIYU3sFBgidm0ZV2f76tokhr6CIRaUMJ14XuHKZq6q+pao9VfU0YDewppRNr8Sal4wxLujVuhEBAr+uq7vdn64UCBGJdx4T8fQ/fOxlmyjgdOCb6k1njDEQGRpMl2ZR/FqH+yHculHuSxFZCXwL3Kyqe0RktIiMLrbNxcAUVT3gfRfGGONbnn6I3XV2kD+3mpgGqmonVe2mqtOcZa+r6uvFtnlXVa90I58xxgD0bRtDfqHW2X4IG2rDGGNK0atVIwIDpM5e7moFwhhjStGgXhAnN4vil3VWIIwxxpTQr20MSzftISevwO0o1c4KhDHGHEffNjEUFCkpG/7oh1izI5vXZ/5W6+e5tgJhjDHHkdyyIUEBcqSZaXZ6Jn96dS5jvk+r9X0TViCMMeY4wusF0a1FNL+u28VnCzZx3TsLaNawPg3qBfHdsq1ux/MpKxDGGFOGvm0asXjjHu7+chn92sbw+eh+DOkYz+QV28kvLHI7ns9YgTDGmDKc0d4zQ92VvVrw9l96EREazPldm7InJ5+5tbiZyWaUM8aYMiS3asS8+84kPqLekZnmBibFElEviInLtpY6g11NZ2cQxhhTDgmRoUdNQxoaHMhZnRL4YcUO8gpqZzOTFQhjjKmgYd2asPdgPj+v3el2FJ+wAmGMMRU0oF0cEaFBfLdsm9tRfMIKhDHGVFBIUADndG7MlJXbOVRQ+0Z8tQJhjDGVcH7XJmTnFjAnvfY1M1mBMMaYSji1bSxR9YOZWAubmaxAGGNMJYQEBXBel8ZMWLqVh75dQdaBPLcjVRkrEMYYU0n3nNeBy5Kb897cDZz+5HRem/Ebufml90lMTt3O1j0HqzFhxViBMMaYSooOC+H/LunKD3ecRp82jXhichoXvfIz2bn5x2z71aLNjP5wIf/vg4UU+PkwHa4UCBG5XURSRWSFiNxRyjaDRGSJs83Mao5ojDEnLCkhgjdH9mLsNT1Jz9jPHZ8sOWpI8DU7srl/fCrNouuzfMte3p27wb2w5VDtBUJEugA3Ar2BbsAwEWlXYpto4FXgQlXtDFxW3TmNMaaizu7cmAcv6MS0tAyemJwGwIFDBdz00SLC6wUx/qb+DO4QzzNT1rApK8fltKVz4wyiIzBPVXNUtQCYCVxSYpurgK9UdSOAqmZUc0ZjjKmUa/q14tp+LRk7ax2fp2zivvHLWZe5nxdHdCc+MpRHLuqCCPz761RU/XPiITcKRCowUERiRCQMGAq0KLHNSUBDEZkhIgtF5FpvOxKRUSKSIiIpmZmZPo5tjDEn5r/DOjGgXSx3f7mMb5Zs5e9nnUT/trEANIuuzz/Pbs/MNZl866eXyFZ7gVDVVcATwBRgMrAEKNndHwT0BM4HzgH+IyInednXWFVNVtXkuLjaOZqiMabmCgoM4JWrTqF9QgRnd0rgpkFHtaYzsn8rujWP4uFvV7Anx/8uj3Wlk1pV31LVnqp6GrAbWFNik83AD6p6QFV3ArPw9FcYY0yNEhUWzMTbBvLGNT0JCJCj1gUGCI9fcjI79+fx6YJNLiUsnVtXMcU7j4l4+h8+LrHJN8AAEQlymqH6AKuqN6UxxlSNwAA5aqjw4jo3jaJTk0imrtxRzanK5tZ9EF+KyErgW+BmVd0jIqNFZDQcaYaaDCwD5gNvqmqqS1mNMcanzuqUwMKNu9m1/5DbUY7iVhPTQFXtpKrdVHWas+x1VX292DZPOdt0UdXn3chpjDHV4axOCajCtDT/umDT7qQ2xhiXdW4aSbPo+n7XzGQFwhhjXCYiDOkYz+z0TA7mHX1RZ3ZuPjPXZLpyr4QVCGOM8QNDOiWQm1/EnBLTl97z1XJGvj3flbMLKxDGGOMH+rSOIaJeEFNXbj+ybO5vO5m4bBshgQE89O3KY84ufM0KhDHG+IGQoAAGdYhn2qoMCouUgsIiHpqwkmbR9fnfyGS27DnIazPWVmsmKxDGGOMnzuqUwK4DeSzeuJsPfv2d1Tuy+c+wjpx+UhwXdW/K6zPXsWHngWrLYwXCGGP8xKD2cQQHCp8s2MSzU9cwoF0s53RuDMB9QzsSEhTAQ9+uqLYOaysQxhjjJyJDg+nbJoYvFm7mYF4hD17Y6cgd2PGRodwxJInpqzP5cVX13C9hBcIYY/zIkI4JAPylfyvaxUcctW5k/1aclNCAf325jM9TNlFU5NszCSsQxhjjRy45pRl3DEnijrOOGcCaYGd02MRGYdz1xTIufGUOv67b5bMs4q8TVZyo5ORkTUlJcTuGMcb4nKoyYelWnvg+ja17czm/axNeHtGj1AEBj0dEFqpqsrd1QZVOaowxplqJCMO7N+Oczo15a856DuYVVqg4lMUKhDHG1FChwYHcfEa7sjesIOuDMMYY45UVCGOMMV5ZgTDGGOOVFQhjjDFeWYEwxhjjlRUIY4wxXlmBMMYY45UVCGOMMV7VmqE2RCQT+L0Su4gFdpa5VfXz11zgv9n8NRf4bzZ/zQX+m81fc8GJZWupqnHeVtSaAlFZIpJS2ngkbvLXXOC/2fw1F/hvNn/NBf6bzV9zQdVlsyYmY4wxXlmBMMYY45UViD+MdTtAKfw1F/hvNn/NBf6bzV9zgf9m89dcUEXZrA/CGGOMV3YGYYwxxisrEMYYY7yq8wVCRM4VkdUislZE7nE5y9sikiEiqcWWNRKRqSKS7jw2dCFXCxGZLiIrRWSFiNzuR9lCRWS+iCx1sj3kLG8tIvOcz/VTEQmp7mxOjkARWSwi3/lZrg0islxElohIirPMHz7PaBH5QkTSRGSViPTzk1ztnZ/V4a99InKHn2S70/ndTxWRcc6/iSr5PavTBUJEAoFXgPOATsAIEenkYqR3gXNLLLsHmKaqScA053V1KwD+oaqdgL7Azc7PyR+yHQIGq2o3oDtwroj0BZ4AnlPVdsBu4HoXsgHcDqwq9tpfcgGcoardi10v7w+f5wvAZFXtAHTD87NzPZeqrnZ+Vt2BnkAOMN7tbCLSDLgNSFbVLkAgcCVV9XumqnX2C+gH/FDs9b3AvS5nagWkFnu9GmjiPG8CrPaDn9s3wFn+lg0IAxYBffDcRRrk7XOuxjzN8fynMRj4DhB/yOUcewMQW2KZq58nEAWsx7l4xl9yecl5NvCzP2QDmgGbgEZ4ppD+Djinqn7P6vQZBH/8cA/b7CzzJwmqus15vh1IcDOMiLQCegDz8JNsTjPOEiADmAr8BuxR1QJnE7c+1+eBu4Ei53WMn+QCUGCKiCwUkVHOMrc/z9ZAJvCO0yz3poiE+0Gukq4ExjnPXc2mqluAp4GNwDZgL7CQKvo9q+sFokZRz58Drl2XLCINgC+BO1R1X/F1bmZT1UL1nPo3B3oDHdzIUZyIDAMyVHWh21lKMUBVT8HTvHqziJxWfKVLn2cQcArwmqr2AA5QosnGD/4NhAAXAp+XXOdGNqfPYzie4toUCOfYZuoKq+sFYgvQotjr5s4yf7JDRJoAOI8ZboQQkWA8xeEjVf3Kn7Idpqp7gOl4TqmjRSTIWeXG53oqcKGIbAA+wdPM9IIf5AKO/OWJqmbgaUvvjfuf52Zgs6rOc15/gadguJ2ruPOARaq6w3ntdrYhwHpVzVTVfOArPL97VfJ7VtcLxAIgyenxD8Fz6jjB5UwlTQBGOs9H4mn/r1YiIsBbwCpVfdbPssWJSLTzvD6evpFVeArFpW5lU9V7VbW5qrbC83v1k6pe7XYuABEJF5GIw8/xtKmn4vLnqarbgU0i0t5ZdCaw0u1cJYzgj+YlcD/bRqCviIQ5/04P/8yq5vfMzc4ef/gChgJr8LRb3+9ylnF42hHz8fw1dT2edutpQDrwI9DIhVwD8Jw6LwOWOF9D/SRbV2Cxky0V+K+zvA0wH1iLpzmgnouf6yDgO3/J5WRY6nytOPx77yefZ3cgxfk8vwYa+kMuJ1s4sAuIKrbM9WzAQ0Ca8/v/AVCvqn7PbKgNY4wxXtX1JiZjjDGlsAJhjDHGKysQxhhjvLICYYwxxisrEMYYY7yyAmFqNREZJCIqIhcUW/adiAyqov1vEJHYqthXGcd5yhmx86kSyx8UkX+ewH6iReSmcmw3Q0QqPem9qdmsQJi6YDNwv9shSip2p2t5jAK6qupdlTxsNFBmgTAGrEAYPycivURkmTPGfbjzV3SXE9zNUmCviJzlZf9HzgBEJFlEZjjPHxSR90Rktoj8LiKXiMiTzhwKk52hRw6721k+X0TaOe+PE5EvRWSB83Vqsf1+ICI/47mpqXgWcc4UUp39XeEsnwA0ABYeXlZCNxH5xZmT4EbnPQ1EZJqILHL2NdzZdgzQVjxzGjzlbPsvZ5ulIjKm2H4vc76nNSIy8MR+5KY2OJG/YIypdqq6wPkP8lGgPvChqqaW8TZvHgMewTPaa3m1Bc7AM1fIL8CfVPVuERkPnI/nTl+Avap6sohci2cE12F4xl16TlXniEgi8APQ0dm+E57B8g6WON4leO4k7gbEAgtEZJaqXigi+9UzIKE3XfHM0xEOLBaRiXjGBLpYVfc5BfBX5+d4D9Dl8L5E5Dw8g731UdUcEWlUbL9BqtpbRIYCD+AZ98fUIVYgTE3wMJ5xs3LxTI5ywlR1loggIgNO4G3fq2q+iCzHMxHLZGf5cjzzdhw2rtjjc87zIUAnz/A4AESKZzRcgAleigN4hjQZp6qFeAaBmwn0ouzxwb5x9ndQRKbjGXhvIvC4eEZpLcIz3LO3oaiHAO+oag6AqmYVW3d4UMaFJb5fU0dYgTA1QQyeJpZgIBTPMNBHiMjNwI3Oy6GqurWU/TwG/BvPDHmHFfBHU2toie0PAahqkYjk6x/j0hRx9L8d9fI8AOirqrklslIyfxUoOV6OAlcDcUBPp8ht4NjvryyHnMdC7P+KOsn6IExN8AbwH+AjPFMpHkVVX1FnOsjjFAdUdQqewd+6Flu8Ac8UkgB/qmC+K4o9/uI8nwLcengDEelejv3MBq4QzwRIccBpeAZcK8twp48mBs/AgAvwzM6W4RSHM4CWzrbZQESx904FrhORMCdn8SYmU8fZXwXGrznt+vmq+rF45hCfKyKDVfWnCu7yMY4e+vgh4C0ReQSYUcF9NhSRZXj+4h7hLLsNeMVZHgTMAkaXsZ/xeOayWIrnLOBu9QyBXZZleIZ3jgUeUdWtIvIR8K3TPJaCZ7RPVHWXiPwsIql4mtDucopXiojkAZOA+8r7jZvazUZzNcYY45U1MRljjPHKCoQxxhivrEAYY4zxygqEMcYYr6xAGGOM8coKhDHGGK+sQBhjjPHq/wNdObMEUBCodQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(full_losses)\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('x - Number of batch')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - Average loss')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkOOqtkYxGWy"
   },
   "source": [
    "# Check forward LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11223,
     "status": "ok",
     "timestamp": 1616791096518,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "GmgoSqb5xINj",
    "outputId": "1d838f19-479e-4e05-8fb4-b883894c6c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: tensor([ 4, 23,  4, 14, 14,  6, 16, 21,  9,  1])\n",
      "Model prediction: tensor([[   12,   381,   191,   381,   191, 18536,   381,    12,   255,     1]])\n"
     ]
    }
   ],
   "source": [
    "file = \"2head.txt\"\n",
    "dataset = LazyTextDataset(datafolder + file, sentence_length, skipsos, jagged, bid, delimiter)\n",
    "model.eval()\n",
    "test_input = torch.unsqueeze(dataset[1]['x'], dim=0)\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "output, lstm_out, hx = model(test_input)\n",
    "print(f\"Ground truth: {dataset[1]['t']}\")\n",
    "print(f'Model prediction: {torch.argmax(output, dim=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the tiered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context_size = [10]\n",
    "layer_list = [5] #hidden units of each layer.\n",
    "num_steps = 3\n",
    "model = Tiered_LSTM(layer_list, context_size, vocab_size, embedding_dim, context_size[0], jagged = False, bid = False)\n",
    "data_handler = OnlineLMBatcher(datafolder + files[0], conf, context_size, skipsos, jagged, bid, batch_size=64, num_steps=num_steps, delimiter=\" \", skiprows=0)\n",
    "criterion = nn.CrossEntropyLoss(reduction= 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=0.99)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 30.767872).  Saving model ...\n",
      "Validation loss decreased (30.767872 --> 30.748810).  Saving model ...\n",
      "Validation loss decreased (30.748810 --> 30.742208).  Saving model ...\n",
      "Validation loss decreased (30.742208 --> 30.710390).  Saving model ...\n",
      "Validation loss decreased (30.710390 --> 30.687914).  Saving model ...\n",
      "Validation loss decreased (30.687914 --> 30.673775).  Saving model ...\n",
      "Validation loss decreased (30.673775 --> 30.656340).  Saving model ...\n",
      "Validation loss decreased (30.656340 --> 30.631748).  Saving model ...\n",
      "Validation loss decreased (30.631748 --> 30.594673).  Saving model ...\n",
      "Validation loss decreased (30.594673 --> 30.573406).  Saving model ...\n",
      "Validation loss decreased (30.573406 --> 30.538422).  Saving model ...\n",
      "Validation loss decreased (30.538422 --> 30.466778).  Saving model ...\n",
      "Validation loss decreased (30.466778 --> 30.445755).  Saving model ...\n",
      "Validation loss decreased (30.445755 --> 30.428713).  Saving model ...\n",
      "Validation loss decreased (30.428713 --> 30.374882).  Saving model ...\n",
      "Validation loss decreased (30.374882 --> 30.339428).  Saving model ...\n",
      "Validation loss decreased (30.339428 --> 30.293497).  Saving model ...\n",
      "Validation loss decreased (30.293497 --> 30.292114).  Saving model ...\n",
      "Validation loss decreased (30.292114 --> 30.196617).  Saving model ...\n",
      "Validation loss decreased (30.196617 --> 30.165756).  Saving model ...\n",
      "Validation loss decreased (30.165756 --> 30.162277).  Saving model ...\n",
      "Validation loss decreased (30.162277 --> 30.082691).  Saving model ...\n",
      "Validation loss decreased (30.082691 --> 29.994984).  Saving model ...\n",
      "Validation loss decreased (29.994984 --> 29.883993).  Saving model ...\n",
      "Validation loss decreased (29.883993 --> 29.776182).  Saving model ...\n",
      "Validation loss decreased (29.776182 --> 29.756445).  Saving model ...\n",
      "Validation loss decreased (29.756445 --> 29.722973).  Saving model ...\n",
      "Validation loss decreased (29.722973 --> 29.637266).  Saving model ...\n",
      "Validation loss decreased (29.637266 --> 29.598694).  Saving model ...\n",
      "Validation loss decreased (29.598694 --> 29.552326).  Saving model ...\n",
      "Validation loss decreased (29.552326 --> 29.406925).  Saving model ...\n",
      "Validation loss decreased (29.406925 --> 29.269299).  Saving model ...\n",
      "Validation loss decreased (29.269299 --> 29.148153).  Saving model ...\n",
      "Validation loss decreased (29.148153 --> 29.059399).  Saving model ...\n",
      "Validation loss decreased (29.059399 --> 28.894745).  Saving model ...\n",
      "Validation loss decreased (28.894745 --> 28.871515).  Saving model ...\n",
      "Validation loss decreased (28.871515 --> 28.579668).  Saving model ...\n",
      "Validation loss decreased (28.579668 --> 28.469458).  Saving model ...\n",
      "Validation loss decreased (28.469458 --> 28.434017).  Saving model ...\n",
      "Validation loss decreased (28.434017 --> 28.299532).  Saving model ...\n",
      "Validation loss decreased (28.299532 --> 28.079739).  Saving model ...\n",
      "Validation loss decreased (28.079739 --> 27.527384).  Saving model ...\n",
      "Validation loss decreased (27.527384 --> 27.189360).  Saving model ...\n",
      "Validation loss decreased (27.189360 --> 27.104124).  Saving model ...\n",
      "Validation loss decreased (27.104124 --> 26.988014).  Saving model ...\n",
      "Validation loss decreased (26.988014 --> 26.930752).  Saving model ...\n",
      "Validation loss decreased (26.930752 --> 26.839403).  Saving model ...\n",
      "Validation loss decreased (26.839403 --> 26.748606).  Saving model ...\n",
      "Validation loss decreased (26.748606 --> 26.629938).  Saving model ...\n",
      "Validation loss decreased (26.629938 --> 26.512169).  Saving model ...\n",
      "Validation loss decreased (26.512169 --> 26.473335).  Saving model ...\n",
      "Validation loss decreased (26.473335 --> 26.374271).  Saving model ...\n",
      "Validation loss decreased (26.374271 --> 26.165211).  Saving model ...\n",
      "Validation loss decreased (26.165211 --> 26.095787).  Saving model ...\n",
      "Validation loss decreased (26.095787 --> 25.692852).  Saving model ...\n",
      "Validation loss decreased (25.692852 --> 25.523830).  Saving model ...\n",
      "Validation loss decreased (25.523830 --> 25.428001).  Saving model ...\n",
      "Validation loss decreased (25.428001 --> 25.324200).  Saving model ...\n",
      "Validation loss decreased (25.324200 --> 25.181227).  Saving model ...\n",
      "Validation loss decreased (25.181227 --> 25.117472).  Saving model ...\n",
      "Validation loss decreased (25.117472 --> 25.052921).  Saving model ...\n",
      "Validation loss decreased (25.052921 --> 24.924971).  Saving model ...\n",
      "Validation loss decreased (24.924971 --> 24.799534).  Saving model ...\n",
      "Validation loss decreased (24.799534 --> 24.768520).  Saving model ...\n",
      "Validation loss decreased (24.768520 --> 24.702412).  Saving model ...\n",
      "Validation loss decreased (24.702412 --> 24.572472).  Saving model ...\n",
      "Validation loss decreased (24.572472 --> 24.507412).  Saving model ...\n",
      "Validation loss decreased (24.507412 --> 24.474758).  Saving model ...\n",
      "Validation loss decreased (24.474758 --> 24.440884).  Saving model ...\n",
      "Validation loss decreased (24.440884 --> 24.372269).  Saving model ...\n",
      "Validation loss decreased (24.372269 --> 24.304144).  Saving model ...\n",
      "Validation loss decreased (24.304144 --> 24.203804).  Saving model ...\n",
      "Validation loss decreased (24.203804 --> 24.040329).  Saving model ...\n",
      "Validation loss decreased (24.040329 --> 9.352553).  Saving model ...\n",
      "Validation loss decreased (9.352553 --> 9.188872).  Saving model ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_tiered(model, criterion, optimizer, scheduler, early_stopping, data_handler, cuda, jagged, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gdp0FidFQhu3"
   },
   "source": [
    "### (By overfitting LSTM model on a small dataset, let me check whether the model has ability to learn the relation between input and output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 11534,
     "status": "ok",
     "timestamp": 1616791096836,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "-1B5aPzMxJlT"
   },
   "outputs": [],
   "source": [
    "# mb_size = 1\n",
    "test_batch_size = 1\n",
    "sos = torch.zeros(mb_size * test_batch_size, 1, dtype=torch.long)\n",
    "eos = torch.ones(mb_size * test_batch_size, 1, dtype=torch.long)\n",
    "ex_sentences = torch.LongTensor(mb_size * test_batch_size, conf['sentence_length']-2 ).random_(0, vocab_size)\n",
    "example_sentences = torch.cat((sos, ex_sentences, eos), axis=1)\n",
    "\n",
    "startx = int(skipsos)+ int(jagged)\n",
    "startt = int(skipsos)+ int(jagged) + 1\n",
    "endx = example_sentences.shape[1]- int(not(bid))\n",
    "endt = example_sentences.shape[1] - int(bid)\n",
    "\n",
    "input_sentences = np.split(example_sentences[:,startx:endx], test_batch_size)\n",
    "output_sentences = np.split(example_sentences[:,startt:endt], test_batch_size)\n",
    "data = []\n",
    "\n",
    "for x, t in zip(input_sentences, output_sentences):\n",
    "    tmp_dict={}\n",
    "    tmp_dict['x'] = x\n",
    "    tmp_dict['t'] = t\n",
    "    data.append(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230187,
     "status": "ok",
     "timestamp": 1616791315493,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "cOM7J2Y_xK67",
    "outputId": "816014f3-6122-4e12-a120-97c2d928c7a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th epoch loss: 10.259586334228516\n",
      "500th epoch loss: 6.789942264556885\n",
      "1000th epoch loss: 5.702245235443115\n",
      "1500th epoch loss: 5.073347091674805\n",
      "2000th epoch loss: 4.646107196807861\n",
      "2500th epoch loss: 4.320845603942871\n",
      "CPU times: user 49min 5s, sys: 19min 10s, total: 1h 8min 16s\n",
      "Wall time: 23min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Fwd_LSTM(layer_list, vocab_size, embedding_dim) #For bidirectional LSTM bid_LSTM(layer_list, vocab_size, embedding_dim)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=1)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=False)\n",
    "epochs = 3000\n",
    "model, train_losses = train_model(model, criterion, optimizer, scheduler, early_stopping, data, cuda, jagged, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 230183,
     "status": "ok",
     "timestamp": 1616791315494,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "lyMnmxlJKxBP",
    "outputId": "2597d9cc-4d54-4003-99c1-5e451a619137"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y - Average loss')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('x - Number of batch')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - Average loss')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230515,
     "status": "ok",
     "timestamp": 1616791315830,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "cgNPbcpU57Zp",
    "outputId": "696824d1-e674-421f-c2cd-aa43c965d854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: \n",
      " tensor([[23639, 12979,  9196,  3985, 26736, 13381, 24275,  3640, 23000,     1],\n",
      "        [17623, 21580, 14561, 18211, 11036, 16939, 17691, 24724, 11123,     1],\n",
      "        [17539, 18365, 25013, 22322, 12050, 20236, 24495,  7433, 21945,     1],\n",
      "        [ 4051, 18495, 10171, 24140, 18188, 13225,  9786, 10284, 11779,     1],\n",
      "        [19982, 18385, 14285, 11609, 17590,  6754, 24605, 25004, 18248,     1]])\n",
      "Model prediction: \n",
      " tensor([[12979, 12979, 12979,  3985, 24304, 24059, 17668, 17668,     1,     1],\n",
      "        [28177, 18211, 18211, 18211,  8646, 24654, 17668,  1949,  6695,     1],\n",
      "        [18211, 19994, 18211, 18211, 18211,  8451,  7577,  4258,     1,     1],\n",
      "        [12979,  6488,  6488,  6488,     1,  2174, 17668, 24059, 24059,     1],\n",
      "        [19982, 18385,  1949,  7886,     1, 26623,  8669, 18385,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "test_input = data[0]['x']\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "output, lstm_out, hx = model(test_input[:5,:])\n",
    "print(f\"Ground truth: \\n {data[0]['t'][:5,:]}\")\n",
    "print(f'Model prediction: \\n {torch.argmax(output, dim=2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1rIDpHKr5dyYDqgfJHqEe",
   "collapsed_sections": [],
   "mount_file_id": "1XofCw7SikjyLrq8NHxPt_E_C2eQksVny",
   "name": "Test_code(Dataloader + LSTM + Training loop).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
