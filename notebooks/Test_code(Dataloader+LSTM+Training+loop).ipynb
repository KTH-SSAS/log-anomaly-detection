{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHjrroZ3KHgR"
   },
   "source": [
    "*This is code to test the functionality of LSTM. If this code is messy, sorry in advance... this is my third or second time dealing with Pytorch...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1825,
     "status": "ok",
     "timestamp": 1616791087071,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "-jHRSWrKAiLV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "# torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7-RVMKFGxV_"
   },
   "source": [
    "# Parameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1826,
     "status": "ok",
     "timestamp": 1616791087076,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "U-taqYgpwa-l"
   },
   "outputs": [],
   "source": [
    "#manual setting for parameters\n",
    "cwd = os.getcwd()\n",
    "specpath = cwd + '/safekit/features/specs/lm/'\n",
    "datapath = cwd + '/data_examples/lanl/lm_feats/'\n",
    "layer_list = [10] #hidden units of each layer.\n",
    "lr = 1e-3 #learning rate .\n",
    "embedding_dim = 20 # one word/char will be mapped to this dimension.\n",
    "mb_size = 128 #size of mini batch.\n",
    "maxbadcount = 10\n",
    "patience = 20\n",
    "test = True\n",
    "delimiter = ' '\n",
    "direction = 'fwd' \n",
    "token_level = 'word'\n",
    "tiered = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1823,
     "status": "ok",
     "timestamp": 1616791087077,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "IvOiQ6jUwfEy"
   },
   "outputs": [],
   "source": [
    "if token_level == 'word':\n",
    "    datafolder = datapath + 'word_day_split/'\n",
    "    config = 'lanl_word_config.json'\n",
    "    jagged = False\n",
    "else:\n",
    "    datafolder = datapath + 'raw_day_split/'\n",
    "    config = 'lanl_char_config.json'\n",
    "    jagged = True\n",
    "\n",
    "if direction == 'fwd':\n",
    "    bid = False\n",
    "else: \n",
    "    bid = True\n",
    "\n",
    "if direction == 'fwd' and token_level == 'word':\n",
    "    skipsos = True\n",
    "else:\n",
    "    skipsos = False\n",
    "\n",
    "conf = json.load(open(specpath + config, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1616791087077,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "pU9M0LU_wgKr"
   },
   "outputs": [],
   "source": [
    "vocab_size = conf['token_set_size']  \n",
    "weekend_days = conf[\"weekend_days\"]\n",
    "sentence_length = conf['sentence_length'] - 1 - int(skipsos) + int(bid)\n",
    "if test:\n",
    "    files = conf[\"test_files\"] # 5000 lines from each of day 0, day 1 and day 2\n",
    "else:\n",
    "    files = [str(i) + '.txt' for i in range(conf[\"num_days\"]) if i not in weekend_days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKtKVxdBwlX7"
   },
   "source": [
    "# Class: Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1616791087078,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "ZcThzOufwu9k"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter % 10 == 0:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}. Best loss: {-self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3WovjO0wyFa"
   },
   "source": [
    "# Class: Dataset handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1814,
     "status": "ok",
     "timestamp": 1616791087079,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "lFqZ7Ld-MGQG"
   },
   "outputs": [],
   "source": [
    "def get_mask(lens, num_tokens):\n",
    "    \"\"\"\n",
    "    For masking output of lm_rnn for jagged sequences for correct gradient update.\n",
    "    Sequence length of 0 will output nan for that row of mask so don't do this.\n",
    "\n",
    "    :param lens: Numpy vector of sequence lengths\n",
    "    :param num_tokens: (int) Number of predicted tokens in sentence.\n",
    "    :return: A numpy array mask MB X num_tokens\n",
    "             For each row there are: lens[i] values of 1/lens[i]\n",
    "                                     followed by num_tokens - lens[i] zeros\n",
    "    \"\"\"\n",
    "    mask_template = torch.arange(num_tokens, dtype=torch.float)\n",
    "    return (mask_template < lens) / lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1810,
     "status": "ok",
     "timestamp": 1616791087079,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "WjEzp-zJwzO6"
   },
   "outputs": [],
   "source": [
    "class LazyTextDataset(Dataset):\n",
    "    def __init__(self, filename, sentence_length, skipsos, jagged, bidir, delimiter, transform=None):\n",
    "        self._filename = filename\n",
    "        self._total_data = 0\n",
    "        self.transform = transform\n",
    "        self.f = open(filename, 'r')\n",
    "        self._total_data = len(self.f.readlines()) - 1\n",
    "        self.f = open(filename, 'r')\n",
    "        \n",
    "        self.delimiter = delimiter\n",
    "        self.skipsos = skipsos\n",
    "        self.jagged = jagged\n",
    "        self.bidir = bidir\n",
    "        self.sentence_length = sentence_length\n",
    "       \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        l = self.f.readline()\n",
    "        sentence_length = self.sentence_length - 1 - int(self.skipsos) + int(self.bidir)\n",
    "        if l != '':\n",
    "            line = torch.tensor([int(k) for k in l.strip().split(self.delimiter)])\n",
    "            self.endx = len(line) - int(not self.bidir)\n",
    "            self.endt = len(line) - int(self.bidir)\n",
    "\n",
    "            self.datadict = {'line': line[0],\n",
    "                            'second': line[1],\n",
    "                            'day': line[2],\n",
    "                            'user': line[3],\n",
    "                            'red': line[4],\n",
    "                            'x': line[(5 + int(self.jagged) + int(self.skipsos)):self.endx],\n",
    "                            't': line[(6 + int(self.jagged) + int(self.skipsos)):self.endt]}\n",
    "            if self.jagged:\n",
    "                self.datadict['length'] = line[5]\n",
    "                self.datadict['mask'] = get_mask(self.datadict['length'] - 2*int(self.bidir) - int(self.skipsos), self.sentence_length - 2*int(self.bidir))\n",
    "                # assert np.all(self.datadict['lengths'] <= x.get_shape().as_list()[1]), 'Sequence found greater than num_tokens_predicted'\n",
    "                # assert np.nonzero(self.datadict['lengths'])[0].shape[0] == self.datadict['lengths'].shape[0], \\\n",
    "                #     'Sequence lengths must be greater than zero.' \\\n",
    "                #     'Found zero length sequence in datadict[\"lengths\"]: %s' % self.datadict['lengths']  \n",
    "\n",
    "        return self.datadict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._total_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5GDnhW1w1Vj"
   },
   "source": [
    "# Class: LSTM Models (To-do: tiered model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2115,
     "status": "ok",
     "timestamp": 1616791087388,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "CfBrtJ5Cw2qS"
   },
   "outputs": [],
   "source": [
    "\n",
    "def truncated_normal_(tensor, mean=0, std=1):\n",
    "    size = tensor.shape\n",
    "    tmp = tensor.new_empty(size + (4,)).normal_()\n",
    "    valid = (tmp < 2) & (tmp > -2)\n",
    "    ind = valid.max(-1, keepdim=True)[1]\n",
    "    tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\n",
    "    tensor.data.mul_(std).add_(mean)\n",
    "    return tensor    \n",
    "\n",
    "def initialize_weights(net, initrange = 1.0):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            initrange *= 1.0/np.sqrt(m.weight.data.shape[1])\n",
    "            m.weight.data = initrange * truncated_normal_(m.weight.data, mean = 0.0, std =1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Embedding):\n",
    "            truncated_normal_(m.weight.data, mean = 0.0, std =1)\n",
    "\n",
    "\n",
    "# def build_stacked_lstm(layers, embedding_dim, bid):\n",
    "#     lstm_lst = []\n",
    "#     for i, unit_size in enumerate(layers):\n",
    "#         if i == 0:\n",
    "#             lstm_lst.append(('LSTM_fwd'+str(i), nn.LSTM(embedding_dim, unit_size, batch_first = True, bidirectional = bid)))\n",
    "#         else:\n",
    "#             lstm_lst.append(('LSTM_fwd'+str(i), nn.LSTM(layers[i-1], unit_size, batch_first = True, bidirectional = bid)))\n",
    "#     return nn.Sequential(OrderedDict(lstm_lst))      \n",
    "\n",
    "\n",
    "class Fwd_LSTM(nn.Module):\n",
    "    def __init__(self, layers, vocab_size, embedding_dim, jagged = False, tiered =False, context_vector_size = 0):\n",
    "        super().__init__()\n",
    "        self.layers = layers \n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tiered = tiered\n",
    "        self.bid = False\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        if self.tiered:\n",
    "            self.embedding_dim += context_vector_size  \n",
    "\n",
    "#         self.stacked_lstm = build_stacked_lstm(self.layers, self.embedding_dim, self.bid)\n",
    "        self.stacked_lstm = nn.LSTM(self.embedding_dim, self.layers[0], len(self.layers), batch_first = True, bidirectional = self.bid)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(self.layers[-1], self.vocab_size)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, sequences, lengths = None, context_vectors = None):\n",
    "        \n",
    "        x_lookups = self.embeddings(sequences) \n",
    "        if self.tiered:\n",
    "            x_lookups = torch.cat(x_lookups, context_vectors, dim=2)\n",
    "\n",
    "        lstm_in = x_lookups\n",
    "        if self.jagged:\n",
    "            lstm_in = pack_padded_sequence(lstm_in, lengths, batch_first=True)\n",
    "            \n",
    "        lstm_out, (hx, cx)  = self.stacked_lstm(x_lookups)\n",
    "        if self.jagged: \n",
    "            lstm_out = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "\n",
    "        output = self.tanh(lstm_out)\n",
    "        tag_size = self.hidden2tag(output)\n",
    "\n",
    "        return tag_size, lstm_out, hx\n",
    "    \n",
    "class Bid_LSTM(nn.Module):\n",
    "    def __init__(self, layers, vocab_size, embedding_dim, jagged = False, tiered =False, context_vector_size = 0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = layers \n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tiered = tiered\n",
    "        self.bid = True\n",
    "        \n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        \n",
    "        if self.tiered:\n",
    "            self.embedding_dim += context_vector_size\n",
    "\n",
    "#         self.stacked_bid_lstm = build_stacked_lstm(self.layers, self.embedding_dim, self.bid)\n",
    "        self.stacked_bid_lstm = nn.LSTM(self.embedding_dim, self.layers[0], len(self.layers), batch_first = True, bidirectional = self.bid)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(self.layers[-1] * 2, self.vocab_size)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, sequences, lengths = None, context_vectors = None):   \n",
    "        x_lookups = self.embeddings(sequences) #batch size, sequence length, embedded dimension\n",
    "        if self.tiered:\n",
    "            x_lookups = torch.cat(x_lookups, context_vectors, dim=2)\n",
    "\n",
    "        lstm_in = x_lookups\n",
    "        if self.jagged:\n",
    "            lstm_in = pack_padded_sequence(lstm_in, lengths, batch_first=True)            \n",
    "            \n",
    "        lstm_out, (hx, cx)  = self.stacked_bid_lstm(x_lookups)\n",
    "        if self.jagged:\n",
    "            lstm_out = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "        output = self.tanh(lstm_out)\n",
    "        tag_size = self.hidden2tag(output)\n",
    "           \n",
    "        return tag_size, lstm_out, hx\n",
    "\n",
    "class Context_LSTM(nn.Module):\n",
    "    def __init__(self, ctxt_lv_layers, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ctxt_lv_layers = ctxt_lv_layers \n",
    "        self.input_dim = input_dim\n",
    "        self.context_lstm_layers = nn.LSTM(input_dim, self.ctxt_lv_layers[0], len(ctxt_lv_layers), batch_first = True, bidirectional = bid)\n",
    "        #build_stacked_lstm(self.ctxt_lv_layers, self.input_dim, False)\n",
    "        \n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, lower_lv_outputs, final_hidden, context_h, context_c, seq_len = None):   \n",
    "\n",
    "        if seq_len is not None:\n",
    "            mean_hidden = torch.sum(lower_lv_outputs, dim = 1) / seq_len\n",
    "        else:\n",
    "            mean_hidden = torch.mean(lower_lv_outputs, dim = 1)\n",
    "        synthetic_input = torch.cat(mean_hidden, final_hidden, dim=1)\n",
    "        output, (context_hx, context_cx) = self.context_lstm_layers(synthetic_input, (context_h, context_c))\n",
    "        \n",
    "        return output, context_hx, context_cx \n",
    "    \n",
    "class Tiered_LSTM(nn.Module):\n",
    "    def __init__(self, low_lv_layers, ctxt_lv_layers, vocab_size, embedding_dim, context_vector_size, \n",
    "                 jagged = False, bid = False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bid = bid\n",
    "        if self.bid:\n",
    "            self.model = Bid_LSTM\n",
    "        else:\n",
    "            self.model = Fwd_LSTM\n",
    "        self.low_lv_layers = low_lv_layers \n",
    "        self.ctxt_lv_layers = ctxt_lv_layers\n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "#         self.ctxt_vector = torch.zeros([1, context_vector_size])\n",
    "        \n",
    "        self.ctxt_state = (torch.zeros([len(self.ctxt_lv_layers), self.ctxt_lv_layers[0]]), \\\n",
    "                            torch.zeros([len(self.ctxt_lv_layers), self.ctxt_lv_layers[0]])) \n",
    "        \n",
    "        self.low_lv_lstm = self.model(self.low_lv_layers, self.vocab_size, self.embedding_dim, \n",
    "                                      jagged = self.jagged, tiered = True, context_vector_size = self.ctxt_lv_layers[-1])\n",
    "        self.ctxt_lv_lstm = Context_LSTM(self.ctxt_lv_layers, low_lv_layers[-1] * 2)\n",
    "\n",
    "        # self.tanh = nn.Tanh()\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, user_sequences, context_vectors, context_h, context_c, lengths = None):\n",
    "        self.ctxt_vector = context_vectors\n",
    "        self.ctxt_h = context_h\n",
    "        self.ctxt_c = context_c\n",
    "        self.tag_output = []\n",
    "        for sequences in range(user_sequences): #number of steps (e.g., 3), number of users (e.g., 64), lengths of sequences (e.g., 10)\n",
    "            tag_size, low_lv_lstm_outputs, final_hidden = self.low_lv_lstm(sequences, lengths = lengths, context_vectors = self.ctxt_vector)\n",
    "            self.ctxt_vector, (self.ctxt_h, self.ctxt_c) = self.ctxt_lv_lstm(low_lv_lstm_outputs, final_hidden, self.ctxt_h, self.ctxt_c, seq_len = lengths)\n",
    "            self.tag_output.append(tag_size)\n",
    "        return self.tag_output, self.ctxt_vector, self.ctxt_h, self.ctxt_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gjJnoCzw7i7"
   },
   "source": [
    "# Function: Train and evaluate LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2113,
     "status": "ok",
     "timestamp": 1616791087389,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "p62Yl6TBw9Wr"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, early_stopping, dataloader, cuda, jagged, epochs=1):\n",
    "    \n",
    "    train_losses = []\n",
    "\n",
    "    flag = False\n",
    "    for i in range(epochs):\n",
    "        for j, data in enumerate(dataloader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            X = data['x']\n",
    "            Y = data['t']\n",
    "            L = data.get('length')\n",
    "            M = data.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            output, lstm_out, hx = model(X, lengths = L) \n",
    "            token_losses = criterion(output.transpose(1,2), Y)\n",
    "            if jagged:\n",
    "                masked_losses = token_losses * M\n",
    "                line_losses = torch.sum(masked_losses, dim = 1)\n",
    "            else:\n",
    "                line_losses = torch.mean(token_losses, dim = 1)\n",
    "                \n",
    "            loss = torch.mean(line_losses, dim = 0)\n",
    "\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            early_stopping(loss, model)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                early_stopping.early_stop = False\n",
    "                early_stopping.counter = 0\n",
    "                flag = True\n",
    "                break\n",
    "            scheduler.step()\n",
    "        if flag == True:\n",
    "            break\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(f'{i}th epoch loss: {loss.item()}')\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return model, train_losses\n",
    "\n",
    "def eval_model(model, criterion, dataloader, cuda, epochs=1):\n",
    "    \n",
    "    valid_losses = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.eval() # prep model for evaluation\n",
    "        for j, data in enumerate(dataloader):\n",
    "            X = data['x']\n",
    "            Y = data['t']\n",
    "            L = data.get('length')\n",
    "            M = data.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            output, lstm_out, hx = model(X, lengths = L)\n",
    "            token_losses = criterion(output.transpose(1,2), Y)\n",
    "            if jagged:\n",
    "                masked_losses = token_losses * M\n",
    "                line_losses = torch.sum(masked_losses, dim = 1)\n",
    "            else:\n",
    "                line_losses = torch.mean(token_losses, dim = 1)\n",
    "            loss = torch.mean(line_losses, dim = 0)\n",
    "            valid_losses.append(loss.item())\n",
    "    avg_valid_losses = np.mean(valid_losses)\n",
    "    print(f'Average validated loss: {avg_valid_losses}')\n",
    "        \n",
    "    return valid_losses, np.mean(valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZZoblRnxAmS"
   },
   "source": [
    "\n",
    "# Train model\n",
    "\n",
    "## Forward LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11235,
     "status": "ok",
     "timestamp": 1616791096516,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "TuqWq1c6xBTb",
    "outputId": "23c787ba-c1df-44be-bfd8-0ccf5f9b2d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 0head.txt\n",
      "Validation loss decreased (inf --> 10.221434).  Saving model ...\n",
      "Validation loss decreased (10.221434 --> 10.210814).  Saving model ...\n",
      "Validation loss decreased (10.210814 --> 10.205189).  Saving model ...\n",
      "Validation loss decreased (10.205189 --> 10.196102).  Saving model ...\n",
      "Validation loss decreased (10.196102 --> 10.194693).  Saving model ...\n",
      "Validation loss decreased (10.194693 --> 10.191687).  Saving model ...\n",
      "Validation loss decreased (10.191687 --> 10.176392).  Saving model ...\n",
      "Validation loss decreased (10.176392 --> 10.174111).  Saving model ...\n",
      "Validation loss decreased (10.174111 --> 10.173953).  Saving model ...\n",
      "Validation loss decreased (10.173953 --> 10.161388).  Saving model ...\n",
      "Validation loss decreased (10.161388 --> 10.152346).  Saving model ...\n",
      "Validation loss decreased (10.152346 --> 10.134550).  Saving model ...\n",
      "Validation loss decreased (10.134550 --> 10.123980).  Saving model ...\n",
      "Validation loss decreased (10.123980 --> 10.114590).  Saving model ...\n",
      "Validation loss decreased (10.114590 --> 10.109043).  Saving model ...\n",
      "Validation loss decreased (10.109043 --> 10.081168).  Saving model ...\n",
      "Validation loss decreased (10.081168 --> 10.077822).  Saving model ...\n",
      "Validation loss decreased (10.077822 --> 10.074339).  Saving model ...\n",
      "Validation loss decreased (10.074339 --> 10.062359).  Saving model ...\n",
      "Validation loss decreased (10.062359 --> 10.059578).  Saving model ...\n",
      "Validation loss decreased (10.059578 --> 10.047594).  Saving model ...\n",
      "Validation loss decreased (10.047594 --> 10.045343).  Saving model ...\n",
      "Validation loss decreased (10.045343 --> 10.010273).  Saving model ...\n",
      "Validation loss decreased (10.010273 --> 10.010248).  Saving model ...\n",
      "Validation loss decreased (10.010248 --> 10.004206).  Saving model ...\n",
      "Validation loss decreased (10.004206 --> 9.973734).  Saving model ...\n",
      "Validation loss decreased (9.973734 --> 9.969620).  Saving model ...\n",
      "0th epoch loss: 10.03593921661377\n",
      "Evaluating on 1head.txt\n",
      "Average validated loss: 9.977945590019226\n",
      "Training on 1head.txt\n",
      "Validation loss decreased (9.969620 --> 9.958189).  Saving model ...\n",
      "Validation loss decreased (9.958189 --> 9.953235).  Saving model ...\n",
      "Validation loss decreased (9.953235 --> 9.926273).  Saving model ...\n",
      "Validation loss decreased (9.926273 --> 9.901384).  Saving model ...\n",
      "Validation loss decreased (9.901384 --> 9.888351).  Saving model ...\n",
      "Validation loss decreased (9.888351 --> 9.870294).  Saving model ...\n",
      "Validation loss decreased (9.870294 --> 9.865818).  Saving model ...\n",
      "Validation loss decreased (9.865818 --> 9.837620).  Saving model ...\n",
      "Validation loss decreased (9.837620 --> 9.814800).  Saving model ...\n",
      "Validation loss decreased (9.814800 --> 9.804744).  Saving model ...\n",
      "Validation loss decreased (9.804744 --> 9.792288).  Saving model ...\n",
      "Validation loss decreased (9.792288 --> 9.788888).  Saving model ...\n",
      "Validation loss decreased (9.788888 --> 9.754530).  Saving model ...\n",
      "Validation loss decreased (9.754530 --> 9.744293).  Saving model ...\n",
      "Validation loss decreased (9.744293 --> 9.744240).  Saving model ...\n",
      "Validation loss decreased (9.744240 --> 9.741070).  Saving model ...\n",
      "Validation loss decreased (9.741070 --> 9.740780).  Saving model ...\n",
      "Validation loss decreased (9.740780 --> 9.690306).  Saving model ...\n",
      "Validation loss decreased (9.690306 --> 9.684692).  Saving model ...\n",
      "Validation loss decreased (9.684692 --> 9.684224).  Saving model ...\n",
      "Validation loss decreased (9.684224 --> 9.650510).  Saving model ...\n",
      "Validation loss decreased (9.650510 --> 9.617351).  Saving model ...\n",
      "Validation loss decreased (9.617351 --> 9.605008).  Saving model ...\n",
      "Validation loss decreased (9.605008 --> 9.549013).  Saving model ...\n",
      "Validation loss decreased (9.549013 --> 9.546669).  Saving model ...\n",
      "0th epoch loss: 9.553922653198242\n",
      "Evaluating on 2head.txt\n",
      "Average validated loss: 9.537913942337036\n",
      "CPU times: user 4.38 s, sys: 2.05 s, total: 6.43 s\n",
      "Wall time: 9.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Fwd_LSTM(layer_list, vocab_size, embedding_dim) #For bidirectional LSTM: bid_LSTM(layer_list, vocab_size, embedding_dim)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction= 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=0.99)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "full_losses= []\n",
    "epochs = 1\n",
    "for i, file in enumerate(files[:-1]):\n",
    "    print(f'Training on {file}')\n",
    "    dataset = LazyTextDataset(datafolder + file, sentence_length, skipsos, jagged, bid, delimiter)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, num_workers=0)\n",
    "    model, train_losses = train_model(model, criterion, optimizer, scheduler, early_stopping, dataloader, cuda, jagged, epochs)\n",
    "    full_losses = full_losses + train_losses\n",
    "    \n",
    "    print(f'Evaluating on {files[i+1]}')\n",
    "    dataset = LazyTextDataset(datafolder + files[i+1], sentence_length, skipsos, jagged, bid, delimiter)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, num_workers=0)\n",
    "    valid_losses, avg_valid_loss = eval_model(model, criterion, dataloader, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 11229,
     "status": "ok",
     "timestamp": 1616791096517,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "wgNW3kYvxD85",
    "outputId": "6c6abf92-1313-4a07-8d68-1d58bde4bd6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y - Average loss')"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(full_losses)\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('x - Number of batch')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - Average loss')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkOOqtkYxGWy"
   },
   "source": [
    "# Check models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11223,
     "status": "ok",
     "timestamp": 1616791096518,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "GmgoSqb5xINj",
    "outputId": "1d838f19-479e-4e05-8fb4-b883894c6c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: tensor([   4, 1181,    4,   18,   18,    6,   16,   21,    9,    1])\n",
      "Model prediction: tensor([[ 159,    6,  159,    6, 6030,  319,  187, 4979,   16,    1]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "dataset = LazyTextDataset(datafolder + file, sentence_length, skipsos, jagged, bid, delimiter)\n",
    "model.eval()\n",
    "test_input = torch.unsqueeze(dataset[1]['x'], dim=0)\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "output, lstm_out, hx = model(test_input)\n",
    "print(f\"Ground truth: {dataset[1]['t']}\")\n",
    "print(f'Model prediction: {torch.argmax(output, dim=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gdp0FidFQhu3"
   },
   "source": [
    "### (By overfitting LSTM model on a small dataset, let me check whether the model has ability to learn the relation between input and output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 11534,
     "status": "ok",
     "timestamp": 1616791096836,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "-1B5aPzMxJlT"
   },
   "outputs": [],
   "source": [
    "# mb_size = 1\n",
    "test_batch_size = 1\n",
    "sos = torch.zeros(mb_size * test_batch_size, 1, dtype=torch.long)\n",
    "eos = torch.ones(mb_size * test_batch_size, 1, dtype=torch.long)\n",
    "ex_sentences = torch.LongTensor(mb_size * test_batch_size, conf['sentence_length']-2 ).random_(0, vocab_size)\n",
    "example_sentences = torch.cat((sos, ex_sentences, eos), axis=1)\n",
    "\n",
    "startx = int(skipsos)+ int(jagged)\n",
    "startt = int(skipsos)+ int(jagged) + 1\n",
    "endx = example_sentences.shape[1]- int(not(bid))\n",
    "endt = example_sentences.shape[1] - int(bid)\n",
    "\n",
    "input_sentences = np.split(example_sentences[:,startx:endx], test_batch_size)\n",
    "output_sentences = np.split(example_sentences[:,startt:endt], test_batch_size)\n",
    "data = []\n",
    "\n",
    "for x, t in zip(input_sentences, output_sentences):\n",
    "    tmp_dict={}\n",
    "    tmp_dict['x'] = x\n",
    "    tmp_dict['t'] = t\n",
    "    data.append(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230187,
     "status": "ok",
     "timestamp": 1616791315493,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "cOM7J2Y_xK67",
    "outputId": "816014f3-6122-4e12-a120-97c2d928c7a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th epoch loss: 10.261510848999023\n",
      "500th epoch loss: 5.311619758605957\n",
      "1000th epoch loss: 3.0353987216949463\n",
      "1500th epoch loss: 1.9604352712631226\n",
      "CPU times: user 34.7 s, sys: 21.9 s, total: 56.6 s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Fwd_LSTM(layer_list, vocab_size, embedding_dim) #For bidirectional LSTM bid_LSTM(layer_list, vocab_size, embedding_dim)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=1)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=False)\n",
    "epochs = 3000\n",
    "model, train_losses = train_model(model, criterion, optimizer, scheduler, early_stopping, data, cuda, jagged, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 230183,
     "status": "ok",
     "timestamp": 1616791315494,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "lyMnmxlJKxBP",
    "outputId": "2597d9cc-4d54-4003-99c1-5e451a619137"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y - Average loss')"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('x - Number of batch')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - Average loss')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230515,
     "status": "ok",
     "timestamp": 1616791315830,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "cgNPbcpU57Zp",
    "outputId": "696824d1-e674-421f-c2cd-aa43c965d854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: \n",
      " tensor([[18267, 26759, 12659, 14223,  1637, 10081, 25518,  6155, 10320,     1],\n",
      "        [25697, 18728, 27357, 11398,   170,    10, 24543, 26286,  9296,     1],\n",
      "        [16580, 18845, 13587,  3908, 15255,  1532, 17531,  9731, 28102,     1],\n",
      "        [13651, 15831, 12225, 15163, 18350, 13931, 18323, 23112, 13144,     1],\n",
      "        [ 7045, 21756, 13765, 21227,  8815, 25386, 26296, 26677,  5014,     1]])\n",
      "Model prediction: \n",
      " tensor([[24771, 26759, 12659, 14223,  1637, 10081, 25518,  6155, 10320,     1],\n",
      "        [25697, 18728, 27357, 11398,   170,    10, 24543, 26286,  9296,     1],\n",
      "        [16580, 18845, 13587,  3908, 15255,  1532, 17531,  9731, 28102,     1],\n",
      "        [13651, 15831, 12225, 15163, 18350, 22861, 18323, 23112, 13144,     1],\n",
      "        [ 7045, 21756, 13765, 21227,  8815, 25386, 26296, 26677,  5014,     1]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_input = data[0]['x'].cuda()\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "output, lstm_out, hx = model(test_input[:5,:])\n",
    "print(f\"Ground truth: \\n {data[0]['t'][:5,:]}\")\n",
    "print(f'Model prediction: \\n {torch.argmax(output, dim=2)}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1rIDpHKr5dyYDqgfJHqEe",
   "collapsed_sections": [],
   "mount_file_id": "1XofCw7SikjyLrq8NHxPt_E_C2eQksVny",
   "name": "Test_code(Dataloader + LSTM + Training loop).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
