{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHjrroZ3KHgR"
   },
   "source": [
    "*This is code to test the functionality of LSTM. If this code is messy, sorry in advance... this is my third or second time dealing with Pytorch...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1825,
     "status": "ok",
     "timestamp": 1616791087071,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "-jHRSWrKAiLV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "# torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7-RVMKFGxV_"
   },
   "source": [
    "# Parameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1826,
     "status": "ok",
     "timestamp": 1616791087076,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "U-taqYgpwa-l"
   },
   "outputs": [],
   "source": [
    "#manual setting for parameters\n",
    "cwd = os.getcwd()\n",
    "specpath = cwd + '/safekit/features/specs/lm/'\n",
    "datapath = cwd + '/data_examples/lanl/lm_feats/'\n",
    "layer_list = [10] #hidden units of each layer.\n",
    "lr = 1e-3 #learning rate .\n",
    "embedding_dim = 20 # one word/char will be mapped to this dimension.\n",
    "mb_size = 128 #size of mini batch.\n",
    "maxbadcount = 10\n",
    "patience = 20\n",
    "test = False\n",
    "delimiter = ' '\n",
    "direction = 'fwd' \n",
    "token_level = 'word'\n",
    "tiered = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1823,
     "status": "ok",
     "timestamp": 1616791087077,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "IvOiQ6jUwfEy"
   },
   "outputs": [],
   "source": [
    "if token_level == 'word':\n",
    "    datafolder = datapath + 'word_day_split/'\n",
    "    config = 'lanl_word_config.json'\n",
    "    jagged = False\n",
    "else:\n",
    "    datafolder = datapath + 'raw_day_split/'\n",
    "    config = 'lanl_char_config.json'\n",
    "    jagged = True\n",
    "\n",
    "if direction == 'fwd':\n",
    "    bid = False\n",
    "else: \n",
    "    bid = True\n",
    "\n",
    "if direction == 'fwd' and token_level == 'word':\n",
    "    skipsos = True\n",
    "else:\n",
    "    skipsos = False\n",
    "\n",
    "conf = json.load(open(specpath + config, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1616791087077,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "pU9M0LU_wgKr"
   },
   "outputs": [],
   "source": [
    "vocab_size = conf['token_set_size']  \n",
    "weekend_days = conf[\"weekend_days\"]\n",
    "sentence_length = conf['sentence_length'] - 1 - int(skipsos) + int(bid)\n",
    "if test:\n",
    "    files = conf[\"test_files\"] # 5000 lines from day 2\n",
    "else:\n",
    "    files = conf[\"train_files\"] + conf[\"test_files\"] # 5000 lines from each of day 0, day 1 and day 2\n",
    "    # files = [str(i) + '.txt' for i in range(conf[\"num_days\"]) if i not in weekend_days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKtKVxdBwlX7"
   },
   "source": [
    "# Class: Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1616791087078,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "ZcThzOufwu9k"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter % 10 == 0:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}. Best loss: {-self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3WovjO0wyFa"
   },
   "source": [
    "# Class: Dataset handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1814,
     "status": "ok",
     "timestamp": 1616791087079,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "lFqZ7Ld-MGQG"
   },
   "outputs": [],
   "source": [
    "def get_mask(lens, num_tokens):\n",
    "    \"\"\"\n",
    "    For masking output of lm_rnn for jagged sequences for correct gradient update.\n",
    "    Sequence length of 0 will output nan for that row of mask so don't do this.\n",
    "\n",
    "    :param lens: Numpy vector of sequence lengths\n",
    "    :param num_tokens: (int) Number of predicted tokens in sentence.\n",
    "    :return: A numpy array mask MB X num_tokens\n",
    "             For each row there are: lens[i] values of 1/lens[i]\n",
    "                                     followed by num_tokens - lens[i] zeros\n",
    "    \"\"\"\n",
    "    mask_template = torch.arange(num_tokens, dtype=torch.float)\n",
    "    return (mask_template < lens) / lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1810,
     "status": "ok",
     "timestamp": 1616791087079,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "WjEzp-zJwzO6"
   },
   "outputs": [],
   "source": [
    "class LazyTextDataset(Dataset):\n",
    "    def __init__(self, filename, sentence_length, skipsos, jagged, bidir, delimiter, transform=None):\n",
    "        self._filename = filename\n",
    "        self._total_data = 0\n",
    "        self.transform = transform\n",
    "        self.f = open(filename, 'r')\n",
    "        self._total_data = len(self.f.readlines()) - 1\n",
    "        self.f = open(filename, 'r')\n",
    "        \n",
    "        self.delimiter = delimiter\n",
    "        self.skipsos = skipsos\n",
    "        self.jagged = jagged\n",
    "        self.bidir = bidir\n",
    "        self.sentence_length = sentence_length\n",
    "       \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        l = self.f.readline()\n",
    "        sentence_length = self.sentence_length - 1 - int(self.skipsos) + int(self.bidir)\n",
    "        if l != '':\n",
    "            line = torch.tensor([int(k) for k in l.strip().split(self.delimiter)])\n",
    "            self.endx = len(line) - int(not self.bidir)\n",
    "            self.endt = len(line) - int(self.bidir)\n",
    "\n",
    "            self.datadict = {'line': line[0],\n",
    "                            'second': line[1],\n",
    "                            'day': line[2],\n",
    "                            'user': line[3],\n",
    "                            'red': line[4],\n",
    "                            'x': line[(5 + int(self.jagged) + int(self.skipsos)):self.endx],\n",
    "                            't': line[(6 + int(self.jagged) + int(self.skipsos)):self.endt]}\n",
    "            if self.jagged:\n",
    "                self.datadict['length'] = line[5]\n",
    "                self.datadict['mask'] = get_mask(self.datadict['length'] - 2*int(self.bidir) - int(self.skipsos), self.sentence_length - 2*int(self.bidir))\n",
    "                # assert np.all(self.datadict['lengths'] <= x.get_shape().as_list()[1]), 'Sequence found greater than num_tokens_predicted'\n",
    "                # assert np.nonzero(self.datadict['lengths'])[0].shape[0] == self.datadict['lengths'].shape[0], \\\n",
    "                #     'Sequence lengths must be greater than zero.' \\\n",
    "                #     'Found zero length sequence in datadict[\"lengths\"]: %s' % self.datadict['lengths']  \n",
    "\n",
    "        return self.datadict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._total_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handler for a tiered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineLMBatcher: \n",
    "    # It seems Pytorch dataset and dataloader can't sort users... so I needed to build it from scratch..\n",
    "    def __init__(self, file_path, conf, context_size, skipsos, jagged, bidir, batch_size=100, num_steps=5, delimiter=\" \", skiprows=0):\n",
    "        cols = ['line', 'second', 'day', 'user', 'red'] + [f'x_{i}' for i in range(conf['sentence_length'])]\n",
    "        self.day_df = dd.read_csv(file_path, names=cols, sep = ' ', blocksize=25e3)\n",
    "        self.user_id = [] # set()\n",
    "        self.lst_avail_id = []\n",
    "        self.pre_lst_avail_id = []\n",
    "        self.df_id = {}\n",
    "        self.len_id = {}\n",
    "        self.saved_lstm = {}\n",
    "        self.context_size = context_size\n",
    "        self.sel_part = 0\n",
    "        self.current_num_batch = 0\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.staggler_num_steps = 1\n",
    "        self.jagged = jagged\n",
    "        self.skipsos = skipsos\n",
    "        self.bidir = bidir\n",
    "        self.sentence_length = (conf['sentence_length'] - 1) - int(self.skipsos) + int(self.bidir)\n",
    "        self.empty = False\n",
    "        \n",
    "    def filter_partition(self):\n",
    "        partition = self.day_df.get_partition(self.sel_part)\n",
    "        current_ids = partition.user.drop_duplicates().compute().tolist()\n",
    "        for c_id in current_ids:\n",
    "            if c_id not in self.user_id:\n",
    "                self.df_id[c_id] = None\n",
    "                self.saved_lstm[c_id] = (torch.zeros((self.context_size[0])),\\\n",
    "                                         torch.zeros((len(self.context_size), self.context_size[0])),\\\n",
    "                                         torch.zeros((len(self.context_size), self.context_size[0])))\n",
    "            self.df_id[c_id] = pd.concat([self.df_id[c_id], partition[partition.user == c_id].compute()], axis=0)\n",
    "            self.len_id[c_id] = len(self.df_id[c_id])\n",
    "\n",
    "        self.user_id = current_ids + [usr for usr in self.user_id if usr not in current_ids]\n",
    "        self.sel_part += 1   \n",
    "\n",
    "    def update_len(self):\n",
    "        self.lst_avail_id = []\n",
    "        self.current_num_batch = 0\n",
    "        for j in self.user_id:\n",
    "            above_num_steps = self.len_id[j] >= self.num_steps\n",
    "            self.current_num_batch += above_num_steps\n",
    "            if above_num_steps and j not in self.lst_avail_id:\n",
    "                self.lst_avail_id.append(j)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while not self.empty:\n",
    "            output = []\n",
    "            datadict = {}\n",
    "            ctxt_vector = torch.tensor([])\n",
    "            h_state = torch.tensor([])\n",
    "            c_state = torch.tensor([])\n",
    "            while output == []:\n",
    "                if self.current_num_batch < self.batch_size and self.sel_part < self.day_df.npartitions: # Read a new partition\n",
    "                    self.filter_partition()\n",
    "                    self.update_len()\n",
    "                elif self.current_num_batch == 0 and self.sel_part == self.day_df.npartitions: # Activate staggler mode\n",
    "                    self.batch_size = self.batch_size * self.num_steps\n",
    "                    self.num_steps = self.staggler_num_steps\n",
    "                    self.sel_part += 1\n",
    "                    self.update_len()\n",
    "                elif self.current_num_batch > 0: # Output data\n",
    "                    for j in self.lst_avail_id[:self.batch_size]:\n",
    "                        output.append(self.df_id[j].iloc[0:self.num_steps].values)                    \n",
    "                        ctxt_vector = torch.cat((ctxt_vector, torch.unsqueeze(self.saved_lstm[j][0], dim = 0)), dim = 0)                    \n",
    "                        h_state = torch.cat((h_state, torch.unsqueeze(self.saved_lstm[j][1], dim = 0)), dim = 0)\n",
    "                        c_state = torch.cat((c_state, torch.unsqueeze(self.saved_lstm[j][2], dim = 0)), dim = 0)\n",
    "                        self.df_id[j] = self.df_id[j].iloc[self.num_steps:, :]\n",
    "                        self.len_id[j] = len(self.df_id[j])\n",
    "                    self.pre_lst_avail_id = self.lst_avail_id\n",
    "                    self.update_len()\n",
    "                    output = torch.tensor(output).long()\n",
    "                    batch = torch.transpose(output, 0, 1)\n",
    "                    endx = batch.shape[2] - int(not self.bidir)\n",
    "                    endt = batch.shape[2] - int(self.bidir)\n",
    "                    datadict = {'line': batch[:, :, 0],\n",
    "                                'second': batch[:, :, 1],\n",
    "                                'day': batch[:, :, 2],\n",
    "                                'user': batch[:, :, 3],\n",
    "                                'red': batch[:, :, 4],\n",
    "                                'x': [batch[0, :, 5 + self.jagged + self.skipsos:endx]] * self.num_steps,\n",
    "                                't': [batch[0, :, 6 + self.jagged + self.skipsos:endt]] * self.num_steps,\n",
    "                                'context_vector': ctxt_vector, #,['context_vector'],\n",
    "                                'c_state_init': torch.transpose(h_state, 0,1), #state_triple['c_state_init'],\n",
    "                                'h_state_init': torch.transpose(c_state, 0,1)} #state_triple['h_state_init']}\n",
    "                    if self.jagged:\n",
    "                        datadict['lens'] = [batch[0, :, 5] - self.skipsos] * self.num_steps\n",
    "                        datadict['masks'] = [get_mask(seq_length - 2 * self.bidir, sentence_length - 2 * self.bidir) for\n",
    "                                             seq_length in datadict['lens']]\n",
    "                else: # Empty dataset.\n",
    "                    self.empty = True\n",
    "                    break\n",
    "\n",
    "            yield datadict\n",
    "    \n",
    "    def update_state(self, ctxt_vectors, h_states, c_states):\n",
    "        ctxt_vectors = ctxt_vectors.data\n",
    "        h_states = torch.transpose(h_states.data, 0,1)\n",
    "        c_states = torch.transpose(c_states.data, 0,1)\n",
    "        for usr, ctxt_v, h_state, c_state in zip(self.pre_lst_avail_id[:self.batch_size], ctxt_vectors, h_states, c_states):\n",
    "            self.saved_lstm[usr] = (ctxt_v, h_state, c_state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = [10]\n",
    "num_steps = 3\n",
    "data_handler = OnlineLMBatcher(datafolder + files[0], conf, context_size, skipsos, jagged, bid, batch_size=64, num_steps=num_steps, delimiter=\" \", skiprows=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 217,  227,  230,  113,  146,  147,  149,  156,  161, 1538,  166,  167,\n",
      "          183,  186, 2496,  187,  193,  202,  205,  242, 2510, 1548,  181,  184,\n",
      "         2640,  111, 2096, 1542,  189, 2660,  221, 1621, 2731,  724, 2740, 2741,\n",
      "         2139,  803, 2150, 1500,  747,  764, 2858,  121,  150,  784,  177,  117,\n",
      "         2973,  126,  729,  832,  833,  841,  752,  797, 2088,  725, 1550, 3198,\n",
      "         3288, 2122, 3396, 1507],\n",
      "        [ 218,  228,  231,  114,  732,  148,  742,  157,  759, 1539,  762,  168,\n",
      "          794,  800, 2497,  188,  194, 2505,  206,  243, 2511, 1549,  182,  185,\n",
      "         2728,  112, 2097, 2110,  190, 2661,  222, 1622, 2732, 2093, 2806, 2808,\n",
      "         2745, 2295, 2151, 2790,  748,  765, 2859,  122,  151,  785,  178,  118,\n",
      "         2974,  127, 2979, 3003,  834, 2160,  753,  798, 3136, 2383, 2283, 3199,\n",
      "         3289, 2123, 3397, 2388],\n",
      "        [ 824,  229,  232,  717,  733,  741, 2101,  158, 2483, 1540,  763,  169,\n",
      "          795,  801, 2498,  804,  195, 3153,  207,  839, 2512, 2115, 1573,  799,\n",
      "         2788,  714, 2261, 2111,  191, 2662,  223, 2669, 2733, 2094, 2874, 2809,\n",
      "         3066, 2296, 2756, 2971,  749,  766, 3055,  123,  743,  786,  179, 2972,\n",
      "         2975,  728, 2980, 3004,  835, 3006, 3058, 3065, 3137, 2384, 2284, 3200,\n",
      "         3290, 2409, 3456, 2389]])\n",
      "tensor([[ 208,  825,  837, 2670, 3749,  128,  744,  153,  760, 2803,  170, 2297,\n",
      "          805,  196, 3216,  203, 3473,  233, 2789, 2385, 1506,  159, 1574,  836,\n",
      "          718, 2857, 3197,  719, 3943,  750, 1589,  802, 3995,  740,  180,  796,\n",
      "         4068, 4075, 2390, 2262,  152, 2405, 1569,  715, 2092, 2734, 4161, 2095,\n",
      "         3346, 4176, 2877, 2882, 2387,  716, 3056,  726,  727, 2116,  820,  821,\n",
      "         2580, 2581, 1508,  154],\n",
      "        [ 209,  826,  838, 3081, 3750,  129,  745,  746,  761, 2804,  768, 2747,\n",
      "          806,  197, 3468,  204, 3525,  234, 3054, 2386, 3861,  160, 1575, 3005,\n",
      "         1501, 3511, 3335,  720, 3996,  751, 3148, 1592, 4064, 1516, 2880, 1577,\n",
      "         4069, 4165, 3455, 2263, 1532, 2406, 1570, 2086, 2976, 2735, 4162, 2978,\n",
      "         3521, 4270, 4177, 4179, 2977, 2856, 4341, 3269, 3270, 2117, 3282, 3283,\n",
      "         2791, 2582, 3139,  155],\n",
      "        [ 210,  827, 2157, 3082, 3751,  130, 1528, 3757, 1543, 2805,  769, 2748,\n",
      "          807,  198, 3469, 3770, 3771,  235, 3854, 3138, 4074,  757, 1576, 3526,\n",
      "         1502, 3937, 3512,  721, 4667, 1535, 3946, 1593, 4065, 1517, 4007, 1578,\n",
      "         4155, 4251, 4076, 2643, 1533, 2645, 1571, 2087, 4158, 3263, 4246, 3201,\n",
      "         4174, 4358, 4271, 4600, 4250, 4340, 4665, 4345, 4346, 2118, 4368, 4369,\n",
      "         4443, 4444, 4447,  754]])\n",
      "tensor([[ 211,  828, 2158, 3291, 3752,  131, 1529, 1544, 3206,  770, 2749, 2499,\n",
      "          199, 3470, 4604,  236, 3855, 3264,  758, 2412, 1503, 3513,  722, 1536,\n",
      "         1594, 4066, 1518, 1579, 4156, 4254, 2644, 1534, 2646, 1572, 2641, 3451,\n",
      "         4247, 3517, 2119,  755, 1568, 2513,  734, 3463, 2757, 1523, 1541, 4610,\n",
      "         2472, 2504, 2506, 3189,  192,  119,  124, 2265, 2484, 2408, 2417,  224,\n",
      "          115, 3620,  140,  144],\n",
      "        [ 212,  829, 2309, 3292, 3857,  132, 1530, 1545, 3207,  771, 2750, 2500,\n",
      "          200, 3633, 4605,  237, 3856, 3265, 2482, 2413, 1504, 3625,  723, 1537,\n",
      "         1595, 4067, 1519, 1580, 4157, 4511, 2736, 2271, 2647, 2127, 2642, 3452,\n",
      "         4248, 3628, 2120,  756, 3145, 2514,  735, 3697, 2997, 1524, 2401, 4611,\n",
      "         3260, 3284, 3285, 3190, 2420,  120,  125, 2266, 2583, 2489, 2591,  831,\n",
      "          116, 3621,  141,  145],\n",
      "        [ 213, 1611, 2426, 3359, 3858,  133, 1531, 1546, 3344,  772, 3149, 2501,\n",
      "          201, 3634, 4912,  238, 4758, 3266, 3864, 2414, 2259, 3626, 1505, 2107,\n",
      "         2140, 4151, 1520, 1581, 4243, 4512, 2737, 2272, 2868, 2878, 3132, 4159,\n",
      "         4249, 3629, 2121, 2109, 4461, 2515,  736, 4525, 2998, 1525, 2402, 4681,\n",
      "         4759, 4777, 4778, 3191, 2657, 3576, 2860, 2267, 2867, 2584, 2746, 2663,\n",
      "         3575, 3622,  142,  731]])\n",
      "tensor([[2102, 2648,  773,  175, 2415, 2502, 5085,  808,  214, 1612, 2427, 3360,\n",
      "         2260, 4152, 5139, 3267, 2863, 1521, 1526, 1582, 2475, 5243, 3345, 2281,\n",
      "         3144, 3863, 2403, 2869, 4678, 3068, 2893, 3623, 5429, 4163, 4363, 3150,\n",
      "         4666,  134, 4818, 5541, 5545, 3271, 3272, 3273, 5607, 5609, 4682, 5690,\n",
      "         4981, 2738,  165, 5821, 4160, 3057, 2108,  840,  767, 4918, 6041, 6051,\n",
      "         3192, 2601,  830, 3527],\n",
      "        [2103, 2802,  774,  176, 2588, 2655, 5086,  809,  215, 1613, 2428, 3597,\n",
      "         2473, 4153, 5341, 3268, 3579, 1522, 1527, 1583, 2476, 5244, 3460, 2282,\n",
      "         5253, 4827, 2404, 3060, 5357, 3069, 2894, 5427, 5430, 4164, 4364, 3464,\n",
      "         5517,  135, 5525, 5542, 6174, 3940, 3941, 3942, 5608, 5610, 4683, 5691,\n",
      "         4982, 2739, 2407, 5822, 4960, 5825, 2273, 2509, 5977, 4919, 6134, 6154,\n",
      "         3193, 2602, 2598, 3884],\n",
      "        [2104, 2870,  775,  793, 2589, 2656, 5087,  810,  216, 1614, 2429, 3710,\n",
      "         2474, 4154, 5342, 3453, 5142, 3997, 2100, 1584, 5241, 5434, 3461, 2585,\n",
      "         5254, 5349, 2485, 3061, 5537, 3471, 2895, 5428, 5431, 5432, 5443, 3465,\n",
      "         5518,  136, 5526, 5543, 6255, 5603, 5604, 5605, 5907, 5611, 4684, 5692,\n",
      "         4983, 2792, 5787, 5901, 4961, 5826, 2274, 5845, 5978, 5988, 6135, 6155,\n",
      "         3194, 2603, 6251, 6252]])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(data_handler):\n",
    "    print(data['line'])\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5GDnhW1w1Vj"
   },
   "source": [
    "# Class: LSTM Models (To-do: tiered model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2115,
     "status": "ok",
     "timestamp": 1616791087388,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "CfBrtJ5Cw2qS"
   },
   "outputs": [],
   "source": [
    "\n",
    "def truncated_normal_(tensor, mean=0, std=1):\n",
    "    size = tensor.shape\n",
    "    tmp = tensor.new_empty(size + (4,)).normal_()\n",
    "    valid = (tmp < 2) & (tmp > -2)\n",
    "    ind = valid.max(-1, keepdim=True)[1]\n",
    "    tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\n",
    "    tensor.data.mul_(std).add_(mean)\n",
    "    return tensor    \n",
    "\n",
    "def initialize_weights(net, initrange = 1.0):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            initrange *= 1.0/np.sqrt(m.weight.data.shape[1])\n",
    "            m.weight.data = initrange * truncated_normal_(m.weight.data, mean = 0.0, std =1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Embedding):\n",
    "            truncated_normal_(m.weight.data, mean = 0.0, std =1)\n",
    "\n",
    "\n",
    "class Fwd_LSTM(nn.Module):\n",
    "    def __init__(self, layers, vocab_size, embedding_dim, jagged = False, tiered =False, context_vector_size = 0):\n",
    "        super().__init__()\n",
    "        self.layers = layers \n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tiered = tiered\n",
    "        self.bid = False\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        if self.tiered:\n",
    "            self.embedding_dim += context_vector_size  \n",
    "\n",
    "#         self.stacked_lstm = build_stacked_lstm(self.layers, self.embedding_dim, self.bid)\n",
    "        self.stacked_lstm = nn.LSTM(self.embedding_dim, self.layers[0], len(self.layers), batch_first = True, bidirectional = self.bid)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(self.layers[-1], self.vocab_size)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, sequences, lengths = None, context_vectors = None):\n",
    "        x_lookups = self.embeddings(sequences)  # batch x seq len x embedding\n",
    "        if self.tiered:\n",
    "            cat_x_lookups = torch.tensor([])\n",
    "            x_lookups= x_lookups.transpose(0,1) #  seq len x batch x embedding\n",
    "            for x_lookup in x_lookups: #for each batch x embedding.\\\n",
    "                x_lookup = torch.unsqueeze(torch.cat((x_lookup, context_vectors), dim=1), dim=0) # 1 x batch x embedding\n",
    "                cat_x_lookups = torch.cat((cat_x_lookups, x_lookup), dim = 0) # concatenate so n x batch x embedding (n length of a concatenated sequence)\n",
    "            x_lookups = cat_x_lookups.transpose(0,1) #batch x seq len x embedding + context \n",
    "            \n",
    "        lstm_in = x_lookups\n",
    "        if self.jagged:\n",
    "            lstm_in = pack_padded_sequence(lstm_in, lengths, batch_first=True)\n",
    "        lstm_out, (hx, cx)  = self.stacked_lstm(x_lookups)\n",
    "        if self.jagged: \n",
    "            lstm_out = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "\n",
    "        output = self.tanh(lstm_out)\n",
    "        tag_size = self.hidden2tag(output)\n",
    "        return tag_size, lstm_out, hx\n",
    "    \n",
    "class Bid_LSTM(nn.Module):\n",
    "    def __init__(self, layers, vocab_size, embedding_dim, jagged = False, tiered =False, context_vector_size = 0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = layers \n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tiered = tiered\n",
    "        self.bid = True\n",
    "        \n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        \n",
    "        if self.tiered:\n",
    "            self.embedding_dim += context_vector_size\n",
    "\n",
    "        self.stacked_bid_lstm = nn.LSTM(self.embedding_dim, self.layers[0], len(self.layers), batch_first = True, bidirectional = self.bid)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(self.layers[-1] * 2, self.vocab_size)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, sequences, lengths = None, context_vectors = None):   \n",
    "        x_lookups = self.embeddings(sequences) #batch size, sequence length, embedded dimension\n",
    "        if self.tiered:\n",
    "            x_lookups = torch.cat(x_lookups, context_vectors, dim=2)\n",
    "\n",
    "        lstm_in = x_lookups\n",
    "        if self.jagged:\n",
    "            lstm_in = pack_padded_sequence(lstm_in, lengths, batch_first=True)            \n",
    "            \n",
    "        lstm_out, (hx, cx)  = self.stacked_bid_lstm(x_lookups)\n",
    "        if self.jagged:\n",
    "            lstm_out = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "        output = self.tanh(lstm_out)\n",
    "        tag_size = self.hidden2tag(output)\n",
    "           \n",
    "        return tag_size, lstm_out, hx\n",
    "    \n",
    "\n",
    "class Context_LSTM(nn.Module):\n",
    "    def __init__(self, ctxt_lv_layers, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ctxt_lv_layers = ctxt_lv_layers \n",
    "        self.input_dim = input_dim\n",
    "        self.context_lstm_layers = nn.LSTM(self.input_dim, self.ctxt_lv_layers[0], len(ctxt_lv_layers), batch_first = True, bidirectional = bid)\n",
    "        \n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, lower_lv_outputs, final_hidden, context_h, context_c, seq_len = None):   \n",
    "        if seq_len is not None:\n",
    "            mean_hidden = torch.sum(lower_lv_outputs, dim = 1) / seq_len\n",
    "        else:\n",
    "            mean_hidden = torch.mean(lower_lv_outputs, dim = 1)\n",
    "        cat_input = torch.cat((mean_hidden, final_hidden[-1]), dim=1)\n",
    "        synthetic_input = torch.unsqueeze(cat_input, dim = 1)\n",
    "\n",
    "        output, (context_hx, context_cx) = self.context_lstm_layers(synthetic_input, (context_h, context_c))\n",
    "        return output, context_hx, context_cx \n",
    "    \n",
    "class Tiered_LSTM(nn.Module):\n",
    "    def __init__(self, low_lv_layers, ctxt_lv_layers, vocab_size, embedding_dim, context_vector_size, \n",
    "                 jagged = False, bid = False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bid = bid\n",
    "        if self.bid:\n",
    "            self.model = Bid_LSTM\n",
    "        else:\n",
    "            self.model = Fwd_LSTM\n",
    "        self.low_lv_layers = low_lv_layers \n",
    "        self.ctxt_lv_layers = ctxt_lv_layers\n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.low_lv_lstm = self.model(self.low_lv_layers, self.vocab_size, self.embedding_dim, \n",
    "                                      jagged = self.jagged, tiered = True, context_vector_size = self.ctxt_lv_layers[-1])\n",
    "        self.ctxt_lv_lstm = Context_LSTM(self.ctxt_lv_layers, low_lv_layers[-1] * 2)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, user_sequences, context_vectors, context_h, context_c, lengths = None):\n",
    "        self.ctxt_vector = context_vectors\n",
    "        self.ctxt_h = context_h\n",
    "        self.ctxt_c = context_c\n",
    "        tag_output = []\n",
    "        for sequences in user_sequences: #number of steps (e.g., 3), number of users (e.g., 64), lengths of sequences (e.g., 10)\n",
    "            tag_size, low_lv_lstm_outputs, final_hidden = self.low_lv_lstm(sequences, lengths = lengths, context_vectors = self.ctxt_vector)\n",
    "            self.ctxt_vector, self.ctxt_h, self.ctxt_c = self.ctxt_lv_lstm(low_lv_lstm_outputs, final_hidden, self.ctxt_h, self.ctxt_c, seq_len = lengths)\n",
    "            tag_output.append(tag_size)\n",
    "            self.ctxt_vector = torch.squeeze(self.ctxt_vector, dim = 1)\n",
    "        return tag_output, self.ctxt_vector, self.ctxt_h, self.ctxt_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gjJnoCzw7i7"
   },
   "source": [
    "# Function: Train and evaluate LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2113,
     "status": "ok",
     "timestamp": 1616791087389,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "p62Yl6TBw9Wr"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, early_stopping, dataloader, cuda, jagged, epochs=1):\n",
    "    \n",
    "    train_losses = []\n",
    "\n",
    "    flag = False\n",
    "    for i in range(epochs):\n",
    "        for j, data in enumerate(dataloader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            X = data['x']\n",
    "            Y = data['t']\n",
    "            L = data.get('length')\n",
    "            M = data.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            output, lstm_out, hx = model(X, lengths = L) \n",
    "            token_losses = criterion(output.transpose(1,2), Y)\n",
    "            if jagged:\n",
    "                masked_losses = token_losses * M\n",
    "                line_losses = torch.sum(masked_losses, dim = 1)\n",
    "            else:\n",
    "                line_losses = torch.mean(token_losses, dim = 1)\n",
    "                \n",
    "            loss = torch.mean(line_losses, dim = 0)\n",
    "\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            early_stopping(loss, model)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                early_stopping.early_stop = False\n",
    "                early_stopping.counter = 0\n",
    "                flag = True\n",
    "                break\n",
    "            scheduler.step()\n",
    "        if flag == True:\n",
    "            break\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(f'{i}th epoch loss: {loss.item()}')\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return model, train_losses\n",
    "\n",
    "def eval_model(model, criterion, dataloader, cuda, epochs=1):\n",
    "    \n",
    "    valid_losses = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.eval() # prep model for evaluation\n",
    "        for j, data in enumerate(dataloader):\n",
    "            X = data['x']\n",
    "            Y = data['t']\n",
    "            L = data.get('length')\n",
    "            M = data.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            output, lstm_out, hx = model(X, lengths = L)\n",
    "            token_losses = criterion(output.transpose(1,2), Y)\n",
    "            if jagged:\n",
    "                masked_losses = token_losses * M\n",
    "                line_losses = torch.sum(masked_losses, dim = 1)\n",
    "            else:\n",
    "                line_losses = torch.mean(token_losses, dim = 1)\n",
    "            loss = torch.mean(line_losses, dim = 0)\n",
    "            valid_losses.append(loss.item())\n",
    "    avg_valid_losses = np.mean(valid_losses)\n",
    "    print(f'Average validated loss: {avg_valid_losses}')\n",
    "        \n",
    "    return valid_losses, np.mean(valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tiered(model, criterion, optimizer, scheduler, early_stopping, data_handler, cuda, jagged, epochs=1):\n",
    "\n",
    "    for batch in data_handler:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        if data_handler.empty == False:\n",
    "            X = batch['x']\n",
    "            C_V =  batch['context_vector']\n",
    "            C_H = batch['c_state_init']\n",
    "            C_C = batch['h_state_init']\n",
    "            Y = batch['t']\n",
    "            L = batch.get('length')\n",
    "            M = batch.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            tag_outputs, ctxt_vector, ctxt_h, ctxt_c = model(X, C_V, C_H, C_C, lengths = L)    \n",
    "            data_handler.update_state(ctxt_vector, ctxt_h, ctxt_c)\n",
    "\n",
    "            total_loss = 0\n",
    "            for output, true_y in zip(tag_outputs, Y):\n",
    "                token_losses = criterion(output.transpose(1,2), true_y)\n",
    "                if jagged:\n",
    "                    masked_losses = token_losses * M\n",
    "                    line_losses = torch.sum(masked_losses, dim = 1)\n",
    "                else:\n",
    "                    line_losses = torch.mean(token_losses, dim = 1)\n",
    "                loss = torch.mean(line_losses, dim = 0)\n",
    "                total_loss += loss\n",
    "                \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            early_stopping(total_loss, model)\n",
    "        else:\n",
    "            print('Done')\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            early_stopping.early_stop = False\n",
    "            early_stopping.counter = 0\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZZoblRnxAmS"
   },
   "source": [
    "\n",
    "# Train model\n",
    "\n",
    "## Forward LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11235,
     "status": "ok",
     "timestamp": 1616791096516,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "TuqWq1c6xBTb",
    "outputId": "23c787ba-c1df-44be-bfd8-0ccf5f9b2d23",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 0head.txt\n",
      "Validation loss decreased (inf --> 10.267607).  Saving model ...\n",
      "Validation loss decreased (10.267607 --> 10.249669).  Saving model ...\n",
      "Validation loss decreased (10.249669 --> 10.242489).  Saving model ...\n",
      "Validation loss decreased (10.242489 --> 10.239690).  Saving model ...\n",
      "Validation loss decreased (10.239690 --> 10.235801).  Saving model ...\n",
      "Validation loss decreased (10.235801 --> 10.227585).  Saving model ...\n",
      "Validation loss decreased (10.227585 --> 10.225038).  Saving model ...\n",
      "Validation loss decreased (10.225038 --> 10.216071).  Saving model ...\n",
      "Validation loss decreased (10.216071 --> 10.211380).  Saving model ...\n",
      "Validation loss decreased (10.211380 --> 10.199918).  Saving model ...\n",
      "Validation loss decreased (10.199918 --> 10.187543).  Saving model ...\n",
      "Validation loss decreased (10.187543 --> 10.185026).  Saving model ...\n",
      "Validation loss decreased (10.185026 --> 10.183716).  Saving model ...\n",
      "Validation loss decreased (10.183716 --> 10.170731).  Saving model ...\n",
      "Validation loss decreased (10.170731 --> 10.164155).  Saving model ...\n",
      "Validation loss decreased (10.164155 --> 10.160100).  Saving model ...\n",
      "Validation loss decreased (10.160100 --> 10.154974).  Saving model ...\n",
      "Validation loss decreased (10.154974 --> 10.146931).  Saving model ...\n",
      "Validation loss decreased (10.146931 --> 10.137600).  Saving model ...\n",
      "Validation loss decreased (10.137600 --> 10.114287).  Saving model ...\n",
      "Validation loss decreased (10.114287 --> 10.104498).  Saving model ...\n",
      "Validation loss decreased (10.104498 --> 10.099924).  Saving model ...\n",
      "Validation loss decreased (10.099924 --> 10.096033).  Saving model ...\n",
      "Validation loss decreased (10.096033 --> 10.083307).  Saving model ...\n",
      "Validation loss decreased (10.083307 --> 10.077273).  Saving model ...\n",
      "Validation loss decreased (10.077273 --> 10.056475).  Saving model ...\n",
      "Validation loss decreased (10.056475 --> 10.054604).  Saving model ...\n",
      "Validation loss decreased (10.054604 --> 10.041602).  Saving model ...\n",
      "Validation loss decreased (10.041602 --> 10.031924).  Saving model ...\n",
      "0th epoch loss: 10.0319242477417\n",
      "Evaluating on 1head.txt\n",
      "Average validated loss: 10.041326713562011\n",
      "Training on 1head.txt\n",
      "Validation loss decreased (10.031924 --> 10.025528).  Saving model ...\n",
      "Validation loss decreased (10.025528 --> 10.009987).  Saving model ...\n",
      "Validation loss decreased (10.009987 --> 10.007651).  Saving model ...\n",
      "Validation loss decreased (10.007651 --> 9.998669).  Saving model ...\n",
      "Validation loss decreased (9.998669 --> 9.996099).  Saving model ...\n",
      "Validation loss decreased (9.996099 --> 9.987434).  Saving model ...\n",
      "Validation loss decreased (9.987434 --> 9.972578).  Saving model ...\n",
      "Validation loss decreased (9.972578 --> 9.960989).  Saving model ...\n",
      "Validation loss decreased (9.960989 --> 9.957727).  Saving model ...\n",
      "Validation loss decreased (9.957727 --> 9.953501).  Saving model ...\n",
      "Validation loss decreased (9.953501 --> 9.945300).  Saving model ...\n",
      "Validation loss decreased (9.945300 --> 9.933399).  Saving model ...\n",
      "Validation loss decreased (9.933399 --> 9.914695).  Saving model ...\n",
      "Validation loss decreased (9.914695 --> 9.907543).  Saving model ...\n",
      "Validation loss decreased (9.907543 --> 9.890150).  Saving model ...\n",
      "Validation loss decreased (9.890150 --> 9.887424).  Saving model ...\n",
      "Validation loss decreased (9.887424 --> 9.859329).  Saving model ...\n",
      "Validation loss decreased (9.859329 --> 9.846726).  Saving model ...\n",
      "Validation loss decreased (9.846726 --> 9.823849).  Saving model ...\n",
      "Validation loss decreased (9.823849 --> 9.813616).  Saving model ...\n",
      "Validation loss decreased (9.813616 --> 9.799974).  Saving model ...\n",
      "Validation loss decreased (9.799974 --> 9.782872).  Saving model ...\n",
      "Validation loss decreased (9.782872 --> 9.778118).  Saving model ...\n",
      "Validation loss decreased (9.778118 --> 9.755149).  Saving model ...\n",
      "Validation loss decreased (9.755149 --> 9.741795).  Saving model ...\n",
      "Validation loss decreased (9.741795 --> 9.739416).  Saving model ...\n",
      "Validation loss decreased (9.739416 --> 9.684388).  Saving model ...\n",
      "0th epoch loss: 9.684388160705566\n",
      "Evaluating on 2head.txt\n",
      "Average validated loss: 9.719424390792847\n",
      "CPU times: user 1min 55s, sys: 39 s, total: 2min 34s\n",
      "Wall time: 56.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Fwd_LSTM(layer_list, vocab_size, embedding_dim) #For bidirectional LSTM: bid_LSTM(layer_list, vocab_size, embedding_dim)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction= 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=0.99)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "full_losses= []\n",
    "epochs = 1\n",
    "for i, file in enumerate(files[:-1]):\n",
    "    print(f'Training on {file}')\n",
    "    dataset = LazyTextDataset(datafolder + file, sentence_length, skipsos, jagged, bid, delimiter)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, num_workers=0)\n",
    "    model, train_losses = train_model(model, criterion, optimizer, scheduler, early_stopping, dataloader, cuda, jagged, epochs)\n",
    "    full_losses = full_losses + train_losses\n",
    "    \n",
    "    print(f'Evaluating on {files[i+1]}')\n",
    "    dataset = LazyTextDataset(datafolder + files[i+1], sentence_length, skipsos, jagged, bid, delimiter)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, num_workers=0)\n",
    "    valid_losses, avg_valid_loss = eval_model(model, criterion, dataloader, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 11229,
     "status": "ok",
     "timestamp": 1616791096517,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "wgNW3kYvxD85",
    "outputId": "6c6abf92-1313-4a07-8d68-1d58bde4bd6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y - Average loss')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(full_losses)\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('x - Number of batch')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - Average loss')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkOOqtkYxGWy"
   },
   "source": [
    "# Check forward LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11223,
     "status": "ok",
     "timestamp": 1616791096518,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "GmgoSqb5xINj",
    "outputId": "1d838f19-479e-4e05-8fb4-b883894c6c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: tensor([ 4, 23,  4, 14, 14,  6, 16, 21,  9,  1])\n",
      "Model prediction: tensor([[ 1819,    84,   229,    84,   303, 17356,     1,   530,   530,     1]])\n"
     ]
    }
   ],
   "source": [
    "file = \"2head.txt\"\n",
    "dataset = LazyTextDataset(datafolder + file, sentence_length, skipsos, jagged, bid, delimiter)\n",
    "model.eval()\n",
    "test_input = torch.unsqueeze(dataset[1]['x'], dim=0)\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "output, lstm_out, hx = model(test_input)\n",
    "print(f\"Ground truth: {dataset[1]['t']}\")\n",
    "print(f'Model prediction: {torch.argmax(output, dim=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the tiered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context_size = [10]\n",
    "layer_list = [5] #hidden units of each layer.\n",
    "num_steps = 3\n",
    "model = Tiered_LSTM(layer_list, context_size, vocab_size, embedding_dim, context_size[0], jagged = False, bid = False)\n",
    "data_handler = OnlineLMBatcher(datafolder + files[0], conf, context_size, skipsos, jagged, bid, batch_size=64, num_steps=num_steps, delimiter=\" \", skiprows=0)\n",
    "criterion = nn.CrossEntropyLoss(reduction= 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=0.99)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 30.887043).  Saving model ...\n",
      "Validation loss decreased (30.887043 --> 30.862492).  Saving model ...\n",
      "Validation loss decreased (30.862492 --> 30.834791).  Saving model ...\n",
      "Validation loss decreased (30.834791 --> 30.819456).  Saving model ...\n",
      "Validation loss decreased (30.819456 --> 30.793690).  Saving model ...\n",
      "Validation loss decreased (30.793690 --> 30.762918).  Saving model ...\n",
      "Validation loss decreased (30.762918 --> 30.725296).  Saving model ...\n",
      "Validation loss decreased (30.725296 --> 30.714081).  Saving model ...\n",
      "Validation loss decreased (30.714081 --> 30.693302).  Saving model ...\n",
      "Validation loss decreased (30.693302 --> 30.670261).  Saving model ...\n",
      "Validation loss decreased (30.670261 --> 30.660814).  Saving model ...\n",
      "Validation loss decreased (30.660814 --> 30.571449).  Saving model ...\n",
      "Validation loss decreased (30.571449 --> 30.548882).  Saving model ...\n",
      "Validation loss decreased (30.548882 --> 30.536812).  Saving model ...\n",
      "Validation loss decreased (30.536812 --> 30.536362).  Saving model ...\n",
      "Validation loss decreased (30.536362 --> 30.530045).  Saving model ...\n",
      "Validation loss decreased (30.530045 --> 30.500912).  Saving model ...\n",
      "Validation loss decreased (30.500912 --> 30.427296).  Saving model ...\n",
      "Validation loss decreased (30.427296 --> 30.370159).  Saving model ...\n",
      "Validation loss decreased (30.370159 --> 30.337616).  Saving model ...\n",
      "Validation loss decreased (30.337616 --> 30.336147).  Saving model ...\n",
      "Validation loss decreased (30.336147 --> 30.255283).  Saving model ...\n",
      "Validation loss decreased (30.255283 --> 30.162014).  Saving model ...\n",
      "Validation loss decreased (30.162014 --> 30.112034).  Saving model ...\n",
      "Validation loss decreased (30.112034 --> 30.074112).  Saving model ...\n",
      "Validation loss decreased (30.074112 --> 30.051611).  Saving model ...\n",
      "Validation loss decreased (30.051611 --> 30.027695).  Saving model ...\n",
      "Validation loss decreased (30.027695 --> 29.994713).  Saving model ...\n",
      "Validation loss decreased (29.994713 --> 29.946760).  Saving model ...\n",
      "Validation loss decreased (29.946760 --> 29.906895).  Saving model ...\n",
      "Validation loss decreased (29.906895 --> 29.821072).  Saving model ...\n",
      "Validation loss decreased (29.821072 --> 29.820454).  Saving model ...\n",
      "Validation loss decreased (29.820454 --> 29.739193).  Saving model ...\n",
      "Validation loss decreased (29.739193 --> 29.737438).  Saving model ...\n",
      "Validation loss decreased (29.737438 --> 29.577541).  Saving model ...\n",
      "Validation loss decreased (29.577541 --> 29.573891).  Saving model ...\n",
      "Validation loss decreased (29.573891 --> 29.481441).  Saving model ...\n",
      "Validation loss decreased (29.481441 --> 29.434799).  Saving model ...\n",
      "Validation loss decreased (29.434799 --> 29.425442).  Saving model ...\n",
      "Validation loss decreased (29.425442 --> 29.406656).  Saving model ...\n",
      "Validation loss decreased (29.406656 --> 29.271685).  Saving model ...\n",
      "Validation loss decreased (29.271685 --> 29.237314).  Saving model ...\n",
      "Validation loss decreased (29.237314 --> 29.232994).  Saving model ...\n",
      "Validation loss decreased (29.232994 --> 29.216663).  Saving model ...\n",
      "Validation loss decreased (29.216663 --> 29.175264).  Saving model ...\n",
      "Validation loss decreased (29.175264 --> 29.155388).  Saving model ...\n",
      "Validation loss decreased (29.155388 --> 28.900059).  Saving model ...\n",
      "Validation loss decreased (28.900059 --> 28.882462).  Saving model ...\n",
      "Validation loss decreased (28.882462 --> 28.839268).  Saving model ...\n",
      "Validation loss decreased (28.839268 --> 28.752462).  Saving model ...\n",
      "Validation loss decreased (28.752462 --> 28.581043).  Saving model ...\n",
      "Validation loss decreased (28.581043 --> 28.292152).  Saving model ...\n",
      "Validation loss decreased (28.292152 --> 28.053537).  Saving model ...\n",
      "Validation loss decreased (28.053537 --> 28.028568).  Saving model ...\n",
      "Validation loss decreased (28.028568 --> 27.947346).  Saving model ...\n",
      "Validation loss decreased (27.947346 --> 27.746544).  Saving model ...\n",
      "Validation loss decreased (27.746544 --> 27.242599).  Saving model ...\n",
      "EarlyStopping counter: 10 out of 20. Best loss: 27.242599487304688\n",
      "Validation loss decreased (27.242599 --> 27.086794).  Saving model ...\n",
      "Validation loss decreased (27.086794 --> 26.840731).  Saving model ...\n",
      "Validation loss decreased (26.840731 --> 26.718981).  Saving model ...\n",
      "Validation loss decreased (26.718981 --> 26.638056).  Saving model ...\n",
      "Validation loss decreased (26.638056 --> 26.556887).  Saving model ...\n",
      "Validation loss decreased (26.556887 --> 26.475615).  Saving model ...\n",
      "Validation loss decreased (26.475615 --> 26.352806).  Saving model ...\n",
      "Validation loss decreased (26.352806 --> 26.271667).  Saving model ...\n",
      "Validation loss decreased (26.271667 --> 26.191246).  Saving model ...\n",
      "Validation loss decreased (26.191246 --> 26.029713).  Saving model ...\n",
      "Validation loss decreased (26.029713 --> 25.845234).  Saving model ...\n",
      "Validation loss decreased (25.845234 --> 25.752659).  Saving model ...\n",
      "Validation loss decreased (25.752659 --> 25.449299).  Saving model ...\n",
      "Validation loss decreased (25.449299 --> 25.297966).  Saving model ...\n",
      "Validation loss decreased (25.297966 --> 25.144903).  Saving model ...\n",
      "Validation loss decreased (25.144903 --> 24.918600).  Saving model ...\n",
      "Validation loss decreased (24.918600 --> 24.709351).  Saving model ...\n",
      "Validation loss decreased (24.709351 --> 24.698015).  Saving model ...\n",
      "Validation loss decreased (24.698015 --> 24.624844).  Saving model ...\n",
      "Validation loss decreased (24.624844 --> 24.177969).  Saving model ...\n",
      "Validation loss decreased (24.177969 --> 9.205985).  Saving model ...\n",
      "Validation loss decreased (9.205985 --> 8.932480).  Saving model ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_tiered(model, criterion, optimizer, scheduler, early_stopping, data_handler, cuda, jagged, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gdp0FidFQhu3"
   },
   "source": [
    "### (By overfitting LSTM model on a small dataset, let me check whether the model has ability to learn the relation between input and output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 11534,
     "status": "ok",
     "timestamp": 1616791096836,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "-1B5aPzMxJlT"
   },
   "outputs": [],
   "source": [
    "# mb_size = 1\n",
    "test_batch_size = 1\n",
    "sos = torch.zeros(mb_size * test_batch_size, 1, dtype=torch.long)\n",
    "eos = torch.ones(mb_size * test_batch_size, 1, dtype=torch.long)\n",
    "ex_sentences = torch.LongTensor(mb_size * test_batch_size, conf['sentence_length']-2 ).random_(0, vocab_size)\n",
    "example_sentences = torch.cat((sos, ex_sentences, eos), axis=1)\n",
    "\n",
    "startx = int(skipsos)+ int(jagged)\n",
    "startt = int(skipsos)+ int(jagged) + 1\n",
    "endx = example_sentences.shape[1]- int(not(bid))\n",
    "endt = example_sentences.shape[1] - int(bid)\n",
    "\n",
    "input_sentences = np.split(example_sentences[:,startx:endx], test_batch_size)\n",
    "output_sentences = np.split(example_sentences[:,startt:endt], test_batch_size)\n",
    "data = []\n",
    "\n",
    "for x, t in zip(input_sentences, output_sentences):\n",
    "    tmp_dict={}\n",
    "    tmp_dict['x'] = x\n",
    "    tmp_dict['t'] = t\n",
    "    data.append(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230187,
     "status": "ok",
     "timestamp": 1616791315493,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "cOM7J2Y_xK67",
    "outputId": "816014f3-6122-4e12-a120-97c2d928c7a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th epoch loss: 10.267622947692871\n",
      "500th epoch loss: 6.830822467803955\n",
      "1000th epoch loss: 5.730741024017334\n",
      "1500th epoch loss: 5.094110012054443\n",
      "2000th epoch loss: 4.64980936050415\n",
      "2500th epoch loss: 4.304615020751953\n",
      "CPU times: user 49min 31s, sys: 18min 3s, total: 1h 7min 34s\n",
      "Wall time: 31min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Fwd_LSTM(layer_list, vocab_size, embedding_dim) #For bidirectional LSTM bid_LSTM(layer_list, vocab_size, embedding_dim)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=1)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=False)\n",
    "epochs = 3000\n",
    "model, train_losses = train_model(model, criterion, optimizer, scheduler, early_stopping, data, cuda, jagged, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 230183,
     "status": "ok",
     "timestamp": 1616791315494,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "lyMnmxlJKxBP",
    "outputId": "2597d9cc-4d54-4003-99c1-5e451a619137"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y - Average loss')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('x - Number of batch')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - Average loss')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230515,
     "status": "ok",
     "timestamp": 1616791315830,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "cgNPbcpU57Zp",
    "outputId": "696824d1-e674-421f-c2cd-aa43c965d854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: \n",
      " tensor([[21348, 23271,  9777, 10794, 20819, 21461, 10261, 18006, 26942,     1],\n",
      "        [16986,  9585, 26224,  6343, 14685, 14458,  7014,  2104,  8851,     1],\n",
      "        [ 5455, 21333, 19518, 16742,  8826, 11628, 25545, 15454,  9366,     1],\n",
      "        [20787, 23147,  5041, 27811, 14159,  5125, 14308, 12235,  9412,     1],\n",
      "        [24634, 25814, 16463,  8804,  2954, 15159, 27832,  5075, 15858,     1]])\n",
      "Model prediction: \n",
      " tensor([[ 8039,  8039,  8039,  8039,  8039,  8039,  8039, 14326,     1,     1],\n",
      "        [11509,  9585,   269,     1,     1,     1, 14326, 13434,  8456,     1],\n",
      "        [12355, 23564, 27811, 20540, 20540, 20147,  9901,  5851,     1,     1],\n",
      "        [ 4089, 11509, 12355,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [23948,  4089,     1,     1,     1,  8039, 10580, 10580,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "test_input = data[0]['x']\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "output, lstm_out, hx = model(test_input[:5,:])\n",
    "print(f\"Ground truth: \\n {data[0]['t'][:5,:]}\")\n",
    "print(f'Model prediction: \\n {torch.argmax(output, dim=2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1rIDpHKr5dyYDqgfJHqEe",
   "collapsed_sections": [],
   "mount_file_id": "1XofCw7SikjyLrq8NHxPt_E_C2eQksVny",
   "name": "Test_code(Dataloader + LSTM + Training loop).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
