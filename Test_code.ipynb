{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHjrroZ3KHgR"
   },
   "source": [
    "*This is code to test the functionality of LSTM. If this code is messy, sorry in advance... this is my third or second time dealing with Pytorch...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1825,
     "status": "ok",
     "timestamp": 1616791087071,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "-jHRSWrKAiLV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "# torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7-RVMKFGxV_"
   },
   "source": [
    "# Parameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1826,
     "status": "ok",
     "timestamp": 1616791087076,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "U-taqYgpwa-l"
   },
   "outputs": [],
   "source": [
    "#manual setting for parameters\n",
    "cwd = os.getcwd()\n",
    "specpath = cwd + '/safekit/features/specs/lm/'\n",
    "datapath = cwd + '/data_examples/lanl/lm_feats/'\n",
    "layer_list = [10] #hidden units of each layer.\n",
    "lr = 1e-3 #learning rate .\n",
    "embedding_dim = 20 # one word/char will be mapped to this dimension.\n",
    "mb_size = 128 #size of mini batch.\n",
    "maxbadcount = 10\n",
    "patience = 20\n",
    "test = False\n",
    "delimiter = ' '\n",
    "direction = 'fwd' \n",
    "token_level = 'word'\n",
    "tiered = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1823,
     "status": "ok",
     "timestamp": 1616791087077,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "IvOiQ6jUwfEy"
   },
   "outputs": [],
   "source": [
    "if token_level == 'word':\n",
    "    datafolder = datapath + 'word_day_split/'\n",
    "    config = 'lanl_word_config.json'\n",
    "    jagged = False\n",
    "else:\n",
    "    datafolder = datapath + 'raw_day_split/'\n",
    "    config = 'lanl_char_config.json'\n",
    "    jagged = True\n",
    "\n",
    "if direction == 'fwd':\n",
    "    bid = False\n",
    "else: \n",
    "    bid = True\n",
    "\n",
    "if direction == 'fwd' and token_level == 'word':\n",
    "    skipsos = True\n",
    "else:\n",
    "    skipsos = False\n",
    "\n",
    "conf = json.load(open(specpath + config, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1616791087077,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "pU9M0LU_wgKr"
   },
   "outputs": [],
   "source": [
    "vocab_size = conf['token_set_size']  \n",
    "weekend_days = conf[\"weekend_days\"]\n",
    "sentence_length = conf['sentence_length'] - 1 - int(skipsos) + int(bid)\n",
    "if test:\n",
    "    files = conf[\"test_files\"] # 5000 lines from day 2\n",
    "else:\n",
    "    files = conf[\"train_files\"] + conf[\"test_files\"] # 5000 lines from each of day 0, day 1 and day 2\n",
    "    # files = [str(i) + '.txt' for i in range(conf[\"num_days\"]) if i not in weekend_days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKtKVxdBwlX7"
   },
   "source": [
    "# Class: Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1616791087078,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "ZcThzOufwu9k"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter % 10 == 0:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}. Best loss: {-self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3WovjO0wyFa"
   },
   "source": [
    "# Class: Dataset handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1814,
     "status": "ok",
     "timestamp": 1616791087079,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "lFqZ7Ld-MGQG"
   },
   "outputs": [],
   "source": [
    "def get_mask(lens, num_tokens):\n",
    "    \"\"\"\n",
    "    For masking output of lm_rnn for jagged sequences for correct gradient update.\n",
    "    Sequence length of 0 will output nan for that row of mask so don't do this.\n",
    "\n",
    "    :param lens: Numpy vector of sequence lengths\n",
    "    :param num_tokens: (int) Number of predicted tokens in sentence.\n",
    "    :return: A numpy array mask MB X num_tokens\n",
    "             For each row there are: lens[i] values of 1/lens[i]\n",
    "                                     followed by num_tokens - lens[i] zeros\n",
    "    \"\"\"\n",
    "    mask_template = torch.arange(num_tokens, dtype=torch.float)\n",
    "    return (mask_template < lens) / lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1810,
     "status": "ok",
     "timestamp": 1616791087079,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "WjEzp-zJwzO6"
   },
   "outputs": [],
   "source": [
    "class LazyTextDataset(Dataset):\n",
    "    def __init__(self, filename, sentence_length, skipsos, jagged, bidir, delimiter, transform=None):\n",
    "        self._filename = filename\n",
    "        self._total_data = 0\n",
    "        self.transform = transform\n",
    "        self.f = open(filename, 'r')\n",
    "        self._total_data = len(self.f.readlines()) - 1\n",
    "        self.f = open(filename, 'r')\n",
    "        \n",
    "        self.delimiter = delimiter\n",
    "        self.skipsos = skipsos\n",
    "        self.jagged = jagged\n",
    "        self.bidir = bidir\n",
    "        self.sentence_length = sentence_length\n",
    "       \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        l = self.f.readline()\n",
    "        sentence_length = self.sentence_length - 1 - int(self.skipsos) + int(self.bidir)\n",
    "        if l != '':\n",
    "            line = torch.tensor([int(k) for k in l.strip().split(self.delimiter)])\n",
    "            self.endx = len(line) - int(not self.bidir)\n",
    "            self.endt = len(line) - int(self.bidir)\n",
    "\n",
    "            self.datadict = {'line': line[0],\n",
    "                            'second': line[1],\n",
    "                            'day': line[2],\n",
    "                            'user': line[3],\n",
    "                            'red': line[4],\n",
    "                            'x': line[(5 + int(self.jagged) + int(self.skipsos)):self.endx],\n",
    "                            't': line[(6 + int(self.jagged) + int(self.skipsos)):self.endt]}\n",
    "            if self.jagged:\n",
    "                self.datadict['length'] = line[5]\n",
    "                self.datadict['mask'] = get_mask(self.datadict['length'] - 2*int(self.bidir) - int(self.skipsos), self.sentence_length - 2*int(self.bidir))\n",
    "                # assert np.all(self.datadict['lengths'] <= x.get_shape().as_list()[1]), 'Sequence found greater than num_tokens_predicted'\n",
    "                # assert np.nonzero(self.datadict['lengths'])[0].shape[0] == self.datadict['lengths'].shape[0], \\\n",
    "                #     'Sequence lengths must be greater than zero.' \\\n",
    "                #     'Found zero length sequence in datadict[\"lengths\"]: %s' % self.datadict['lengths']  \n",
    "\n",
    "        return self.datadict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._total_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handler for a tiered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineLMBatcher: \n",
    "    # It seems Pytorch dataset and dataloader can't sort users... so I needed to build it from scratch..\n",
    "    def __init__(self, file_path, conf, context_size, skipsos, jagged, bidir, batch_size=100, num_steps=5, delimiter=\" \", skiprows=0):\n",
    "        cols = ['line', 'second', 'day', 'user', 'red'] + [f'x_{i}' for i in range(conf['sentence_length'])]\n",
    "        self.day_df = dd.read_csv(file_path, names=cols, sep = ' ', blocksize=25e3)\n",
    "        self.user_id = [] # set()\n",
    "        self.lst_avail_id = []\n",
    "        self.pre_lst_avail_id = []\n",
    "        self.df_id = {}\n",
    "        self.len_id = {}\n",
    "        self.saved_lstm = {}\n",
    "        self.context_size = context_size\n",
    "        self.sel_part = 0\n",
    "        self.current_num_batch = 0\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.staggler_num_steps = 1\n",
    "        self.jagged = jagged\n",
    "        self.skipsos = skipsos\n",
    "        self.bidir = bidir\n",
    "        self.sentence_length = (conf['sentence_length'] - 1) - int(self.skipsos) + int(self.bidir)\n",
    "        self.empty = False\n",
    "        \n",
    "    def filter_partition(self):\n",
    "        partition = self.day_df.get_partition(self.sel_part)\n",
    "        current_ids = partition.user.drop_duplicates().compute().tolist()\n",
    "        for c_id in current_ids:\n",
    "            if c_id not in self.user_id:\n",
    "                self.df_id[c_id] = None\n",
    "                self.saved_lstm[c_id] = (torch.zeros((self.context_size[0])),\\\n",
    "                                         torch.zeros((len(self.context_size), self.context_size[0])),\\\n",
    "                                         torch.zeros((len(self.context_size), self.context_size[0])))\n",
    "            self.df_id[c_id] = pd.concat([self.df_id[c_id], partition[partition.user == c_id].compute()], axis=0)\n",
    "            self.len_id[c_id] = len(self.df_id[c_id])\n",
    "\n",
    "        self.user_id = current_ids + [usr for usr in self.user_id if usr not in current_ids]\n",
    "        self.sel_part += 1   \n",
    "\n",
    "    def update_len(self):\n",
    "        self.lst_avail_id = []\n",
    "        self.current_num_batch = 0\n",
    "        for j in self.user_id:\n",
    "            above_num_steps = self.len_id[j] >= self.num_steps\n",
    "            self.current_num_batch += above_num_steps\n",
    "            if above_num_steps and j not in self.lst_avail_id:\n",
    "                self.lst_avail_id.append(j)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while not self.empty:\n",
    "            output = []\n",
    "            datadict = {}\n",
    "            ctxt_vector = torch.tensor([])\n",
    "            h_state = torch.tensor([])\n",
    "            c_state = torch.tensor([])\n",
    "            while output == []:\n",
    "                if self.current_num_batch < self.batch_size and self.sel_part < self.day_df.npartitions: # Read a new partition\n",
    "                    self.filter_partition()\n",
    "                    self.update_len()\n",
    "                elif self.current_num_batch == 0 and self.sel_part == self.day_df.npartitions: # Activate staggler mode\n",
    "                    self.batch_size = self.batch_size * self.num_steps\n",
    "                    self.num_steps = self.staggler_num_steps\n",
    "                    self.sel_part += 1\n",
    "                    self.update_len()\n",
    "                elif self.current_num_batch > 0: # Output data\n",
    "                    for j in self.lst_avail_id[:self.batch_size]:\n",
    "                        output.append(self.df_id[j].iloc[0:self.num_steps].values)                    \n",
    "                        ctxt_vector = torch.cat((ctxt_vector, torch.unsqueeze(self.saved_lstm[j][0], dim = 0)), dim = 0)                    \n",
    "                        h_state = torch.cat((h_state, torch.unsqueeze(self.saved_lstm[j][1], dim = 0)), dim = 0)\n",
    "                        c_state = torch.cat((c_state, torch.unsqueeze(self.saved_lstm[j][2], dim = 0)), dim = 0)\n",
    "                        self.df_id[j] = self.df_id[j].iloc[self.num_steps:, :]\n",
    "                        self.len_id[j] = len(self.df_id[j])\n",
    "                    self.pre_lst_avail_id = self.lst_avail_id\n",
    "                    self.update_len()\n",
    "                    output = torch.tensor(output).long()\n",
    "                    batch = torch.transpose(output, 0, 1)\n",
    "                    endx = batch.shape[2] - int(not self.bidir)\n",
    "                    endt = batch.shape[2] - int(self.bidir)\n",
    "                    datadict = {'line': batch[:, :, 0],\n",
    "                                'second': batch[:, :, 1],\n",
    "                                'day': batch[:, :, 2],\n",
    "                                'user': batch[:, :, 3],\n",
    "                                'red': batch[:, :, 4],\n",
    "                                'x': [batch[0, :, 5 + self.jagged + self.skipsos:endx]] * self.num_steps,\n",
    "                                't': [batch[0, :, 6 + self.jagged + self.skipsos:endt]] * self.num_steps,\n",
    "                                'context_vector': ctxt_vector, #,['context_vector'],\n",
    "                                'c_state_init': torch.transpose(h_state, 0,1), #state_triple['c_state_init'],\n",
    "                                'h_state_init': torch.transpose(c_state, 0,1)} #state_triple['h_state_init']}\n",
    "                    if self.jagged:\n",
    "                        datadict['lens'] = [batch[0, :, 5] - self.skipsos] * self.num_steps\n",
    "                        datadict['masks'] = [get_mask(seq_length - 2 * self.bidir, sentence_length - 2 * self.bidir) for\n",
    "                                             seq_length in datadict['lens']]\n",
    "                else: # Empty dataset.\n",
    "                    self.empty = True\n",
    "                    break\n",
    "\n",
    "            yield datadict\n",
    "    \n",
    "    def update_state(self, ctxt_vectors, h_states, c_states):\n",
    "        ctxt_vectors = ctxt_vectors.data\n",
    "        h_states = torch.transpose(h_states.data, 0,1)\n",
    "        c_states = torch.transpose(c_states.data, 0,1)\n",
    "        for usr, ctxt_v, h_state, c_state in zip(self.pre_lst_avail_id[:self.batch_size], ctxt_vectors, h_states, c_states):\n",
    "            self.saved_lstm[usr] = (ctxt_v, h_state, c_state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = [10]\n",
    "num_steps = 3\n",
    "data_handler = OnlineLMBatcher(datafolder + files[0], conf, context_size, skipsos, jagged, bid, batch_size=64, num_steps=num_steps, delimiter=\" \", skiprows=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(data_handler):\n",
    "    print(data['line'])\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5GDnhW1w1Vj"
   },
   "source": [
    "# Class: LSTM Models (To-do: tiered model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2115,
     "status": "ok",
     "timestamp": 1616791087388,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "CfBrtJ5Cw2qS"
   },
   "outputs": [],
   "source": [
    "\n",
    "def truncated_normal_(tensor, mean=0, std=1):\n",
    "    size = tensor.shape\n",
    "    tmp = tensor.new_empty(size + (4,)).normal_()\n",
    "    valid = (tmp < 2) & (tmp > -2)\n",
    "    ind = valid.max(-1, keepdim=True)[1]\n",
    "    tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\n",
    "    tensor.data.mul_(std).add_(mean)\n",
    "    return tensor    \n",
    "\n",
    "def initialize_weights(net, initrange = 1.0):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            initrange *= 1.0/np.sqrt(m.weight.data.shape[1])\n",
    "            m.weight.data = initrange * truncated_normal_(m.weight.data, mean = 0.0, std =1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Embedding):\n",
    "            truncated_normal_(m.weight.data, mean = 0.0, std =1)\n",
    "\n",
    "\n",
    "class Fwd_LSTM(nn.Module):\n",
    "    def __init__(self, layers, vocab_size, embedding_dim, jagged = False, tiered =False, context_vector_size = 0):\n",
    "        super().__init__()\n",
    "        self.layers = layers \n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tiered = tiered\n",
    "        self.bid = False\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        if self.tiered:\n",
    "            self.embedding_dim += context_vector_size  \n",
    "\n",
    "#         self.stacked_lstm = build_stacked_lstm(self.layers, self.embedding_dim, self.bid)\n",
    "        self.stacked_lstm = nn.LSTM(self.embedding_dim, self.layers[0], len(self.layers), batch_first = True, bidirectional = self.bid)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(self.layers[-1], self.vocab_size)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, sequences, lengths = None, context_vectors = None):\n",
    "        x_lookups = self.embeddings(sequences)  # batch x seq len x embedding\n",
    "        if self.tiered:\n",
    "            cat_x_lookups = torch.tensor([])\n",
    "            x_lookups= x_lookups.transpose(0,1) #  seq len x batch x embedding\n",
    "            for x_lookup in x_lookups: #for each batch x embedding.\\\n",
    "                x_lookup = torch.unsqueeze(torch.cat((x_lookup, context_vectors), dim=1), dim=0) # 1 x batch x embedding\n",
    "                cat_x_lookups = torch.cat((cat_x_lookups, x_lookup), dim = 0) # concatenate so n x batch x embedding (n length of a concatenated sequence)\n",
    "            x_lookups = cat_x_lookups.transpose(0,1) #batch x seq len x embedding + context \n",
    "            \n",
    "        lstm_in = x_lookups\n",
    "        if self.jagged:\n",
    "            lstm_in = pack_padded_sequence(lstm_in, lengths, batch_first=True)\n",
    "        lstm_out, (hx, cx)  = self.stacked_lstm(x_lookups)\n",
    "        if self.jagged: \n",
    "            lstm_out = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "\n",
    "        output = self.tanh(lstm_out)\n",
    "        tag_size = self.hidden2tag(output)\n",
    "        return tag_size, lstm_out, hx\n",
    "    \n",
    "class Bid_LSTM(nn.Module):\n",
    "    def __init__(self, layers, vocab_size, embedding_dim, jagged = False, tiered =False, context_vector_size = 0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = layers \n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tiered = tiered\n",
    "        self.bid = True\n",
    "        \n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        \n",
    "        if self.tiered:\n",
    "            self.embedding_dim += context_vector_size\n",
    "\n",
    "        self.stacked_bid_lstm = nn.LSTM(self.embedding_dim, self.layers[0], len(self.layers), batch_first = True, bidirectional = self.bid)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(self.layers[-1] * 2, self.vocab_size)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, sequences, lengths = None, context_vectors = None):   \n",
    "        x_lookups = self.embeddings(sequences) #batch size, sequence length, embedded dimension\n",
    "        if self.tiered:\n",
    "            x_lookups = torch.cat(x_lookups, context_vectors, dim=2)\n",
    "\n",
    "        lstm_in = x_lookups\n",
    "        if self.jagged:\n",
    "            lstm_in = pack_padded_sequence(lstm_in, lengths, batch_first=True)            \n",
    "            \n",
    "        lstm_out, (hx, cx)  = self.stacked_bid_lstm(x_lookups)\n",
    "        if self.jagged:\n",
    "            lstm_out = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "        output = self.tanh(lstm_out)\n",
    "        tag_size = self.hidden2tag(output)\n",
    "           \n",
    "        return tag_size, lstm_out, hx\n",
    "    \n",
    "\n",
    "class Context_LSTM(nn.Module):\n",
    "    def __init__(self, ctxt_lv_layers, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ctxt_lv_layers = ctxt_lv_layers \n",
    "        self.input_dim = input_dim\n",
    "        self.context_lstm_layers = nn.LSTM(self.input_dim, self.ctxt_lv_layers[0], len(ctxt_lv_layers), batch_first = True, bidirectional = bid)\n",
    "        \n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, lower_lv_outputs, final_hidden, context_h, context_c, seq_len = None):   \n",
    "        if seq_len is not None:\n",
    "            mean_hidden = torch.sum(lower_lv_outputs, dim = 1) / seq_len\n",
    "        else:\n",
    "            mean_hidden = torch.mean(lower_lv_outputs, dim = 1)\n",
    "        cat_input = torch.cat((mean_hidden, final_hidden[-1]), dim=1)\n",
    "        synthetic_input = torch.unsqueeze(cat_input, dim = 1)\n",
    "\n",
    "        output, (context_hx, context_cx) = self.context_lstm_layers(synthetic_input, (context_h, context_c))\n",
    "        return output, context_hx, context_cx \n",
    "    \n",
    "class Tiered_LSTM(nn.Module):\n",
    "    def __init__(self, low_lv_layers, ctxt_lv_layers, vocab_size, embedding_dim, context_vector_size, \n",
    "                 jagged = False, bid = False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bid = bid\n",
    "        if self.bid:\n",
    "            self.model = Bid_LSTM\n",
    "        else:\n",
    "            self.model = Fwd_LSTM\n",
    "        self.low_lv_layers = low_lv_layers \n",
    "        self.ctxt_lv_layers = ctxt_lv_layers\n",
    "        self.jagged = jagged\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.low_lv_lstm = self.model(self.low_lv_layers, self.vocab_size, self.embedding_dim, \n",
    "                                      jagged = self.jagged, tiered = True, context_vector_size = self.ctxt_lv_layers[-1])\n",
    "        self.ctxt_lv_lstm = Context_LSTM(self.ctxt_lv_layers, low_lv_layers[-1] * 2)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, user_sequences, context_vectors, context_h, context_c, lengths = None):\n",
    "        self.ctxt_vector = context_vectors\n",
    "        self.ctxt_h = context_h\n",
    "        self.ctxt_c = context_c\n",
    "        tag_output = []\n",
    "        for sequences in user_sequences: #number of steps (e.g., 3), number of users (e.g., 64), lengths of sequences (e.g., 10)\n",
    "            tag_size, low_lv_lstm_outputs, final_hidden = self.low_lv_lstm(sequences, lengths = lengths, context_vectors = self.ctxt_vector)\n",
    "            self.ctxt_vector, self.ctxt_h, self.ctxt_c = self.ctxt_lv_lstm(low_lv_lstm_outputs, final_hidden, self.ctxt_h, self.ctxt_c, seq_len = lengths)\n",
    "            tag_output.append(tag_size)\n",
    "            self.ctxt_vector = torch.squeeze(self.ctxt_vector, dim = 1)\n",
    "        return tag_output, self.ctxt_vector, self.ctxt_h, self.ctxt_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gjJnoCzw7i7"
   },
   "source": [
    "# Function: Train and evaluate LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2113,
     "status": "ok",
     "timestamp": 1616791087389,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "p62Yl6TBw9Wr"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, early_stopping, dataloader, cuda, jagged, epochs=1):\n",
    "    \n",
    "    train_losses = []\n",
    "\n",
    "    flag = False\n",
    "    for i in range(epochs):\n",
    "        for j, data in enumerate(dataloader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            X = data['x']\n",
    "            Y = data['t']\n",
    "            L = data.get('length')\n",
    "            M = data.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            output, lstm_out, hx = model(X, lengths = L) \n",
    "            token_losses = criterion(output.transpose(1,2), Y)\n",
    "            if jagged:\n",
    "                masked_losses = token_losses * M\n",
    "                line_losses = torch.sum(masked_losses, dim = 1)\n",
    "            else:\n",
    "                line_losses = torch.mean(token_losses, dim = 1)\n",
    "                \n",
    "            loss = torch.mean(line_losses, dim = 0)\n",
    "\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            early_stopping(loss, model)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                early_stopping.early_stop = False\n",
    "                early_stopping.counter = 0\n",
    "                flag = True\n",
    "                break\n",
    "            scheduler.step()\n",
    "        if flag == True:\n",
    "            break\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(f'{i}th epoch loss: {loss.item()}')\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return model, train_losses\n",
    "\n",
    "def eval_model(model, criterion, dataloader, cuda, epochs=1):\n",
    "    \n",
    "    valid_losses = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.eval() # prep model for evaluation\n",
    "        for j, data in enumerate(dataloader):\n",
    "            X = data['x']\n",
    "            Y = data['t']\n",
    "            L = data.get('length')\n",
    "            M = data.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            output, lstm_out, hx = model(X, lengths = L)\n",
    "            token_losses = criterion(output.transpose(1,2), Y)\n",
    "            if jagged:\n",
    "                masked_losses = token_losses * M\n",
    "                line_losses = torch.sum(masked_losses, dim = 1)\n",
    "            else:\n",
    "                line_losses = torch.mean(token_losses, dim = 1)\n",
    "            loss = torch.mean(line_losses, dim = 0)\n",
    "            valid_losses.append(loss.item())\n",
    "    avg_valid_losses = np.mean(valid_losses)\n",
    "    print(f'Average validated loss: {avg_valid_losses}')\n",
    "        \n",
    "    return valid_losses, np.mean(valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tiered(model, criterion, optimizer, scheduler, early_stopping, data_handler, cuda, jagged, epochs=1):\n",
    "\n",
    "    for batch in data_handler:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        if data_handler.empty == False:\n",
    "            X = batch['x']\n",
    "            C_V =  batch['context_vector']\n",
    "            C_H = batch['c_state_init']\n",
    "            C_C = batch['h_state_init']\n",
    "            Y = batch['t']\n",
    "            L = batch.get('length')\n",
    "            M = batch.get('mask')\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                if jagged:\n",
    "                    L = L.cuda()\n",
    "                    M = M.cuda()\n",
    "            tag_outputs, ctxt_vector, ctxt_h, ctxt_c = model(X, C_V, C_H, C_C, lengths = L)    \n",
    "            data_handler.update_state(ctxt_vector, ctxt_h, ctxt_c)\n",
    "\n",
    "            total_loss = 0\n",
    "            for output, true_y in zip(tag_outputs, Y):\n",
    "                token_losses = criterion(output.transpose(1,2), true_y)\n",
    "                if jagged:\n",
    "                    masked_losses = token_losses * M\n",
    "                    line_losses = torch.sum(masked_losses, dim = 1)\n",
    "                else:\n",
    "                    line_losses = torch.mean(token_losses, dim = 1)\n",
    "                loss = torch.mean(line_losses, dim = 0)\n",
    "                total_loss += loss\n",
    "                \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            early_stopping(total_loss, model)\n",
    "        else:\n",
    "            print('Done')\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            early_stopping.early_stop = False\n",
    "            early_stopping.counter = 0\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZZoblRnxAmS"
   },
   "source": [
    "\n",
    "# Train model\n",
    "\n",
    "## Forward LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11235,
     "status": "ok",
     "timestamp": 1616791096516,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "TuqWq1c6xBTb",
    "outputId": "23c787ba-c1df-44be-bfd8-0ccf5f9b2d23"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Fwd_LSTM(layer_list, vocab_size, embedding_dim) #For bidirectional LSTM: bid_LSTM(layer_list, vocab_size, embedding_dim)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction= 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=0.99)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "full_losses= []\n",
    "epochs = 1\n",
    "for i, file in enumerate(files[:-1]):\n",
    "    print(f'Training on {file}')\n",
    "    dataset = LazyTextDataset(datafolder + file, sentence_length, skipsos, jagged, bid, delimiter)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, num_workers=0)\n",
    "    model, train_losses = train_model(model, criterion, optimizer, scheduler, early_stopping, dataloader, cuda, jagged, epochs)\n",
    "    full_losses = full_losses + train_losses\n",
    "    \n",
    "    print(f'Evaluating on {files[i+1]}')\n",
    "    dataset = LazyTextDataset(datafolder + files[i+1], sentence_length, skipsos, jagged, bid, delimiter)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, num_workers=0)\n",
    "    valid_losses, avg_valid_loss = eval_model(model, criterion, dataloader, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 11229,
     "status": "ok",
     "timestamp": 1616791096517,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "wgNW3kYvxD85",
    "outputId": "6c6abf92-1313-4a07-8d68-1d58bde4bd6b"
   },
   "outputs": [],
   "source": [
    "plt.plot(full_losses)\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('x - Number of batch')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - Average loss')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_line(model, criterion, dataloader, cuda):\n",
    "    \n",
    "    valid_losses = []\n",
    "    valid_losses_lines = []\n",
    "\n",
    "    model.eval() # prep model for evaluation\n",
    "    for j, data in enumerate(dataloader):\n",
    "        X = data['x']\n",
    "        Y = data['t']\n",
    "        L = data.get('length')\n",
    "        M = data.get('mask')\n",
    "        if cuda:\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            if jagged:\n",
    "                L = L.cuda()\n",
    "                M = M.cuda()\n",
    "        output, lstm_out, hx = model(X, lengths = L)\n",
    "        token_losses = criterion(output.transpose(1,2), Y)\n",
    "        if jagged:\n",
    "            masked_losses = token_losses * M\n",
    "            line_losses = torch.sum(masked_losses, dim = 1)\n",
    "        else:\n",
    "            line_losses = torch.mean(token_losses, dim = 1)\n",
    "        valid_losses_lines.extend([(data['second'][i].item(), line_losses[i].item()) for i in range(len(line_losses))])\n",
    "        loss = torch.mean(line_losses, dim = 0)\n",
    "        valid_losses.append(loss.item())\n",
    "    avg_valid_losses = np.mean(valid_losses)\n",
    "    print(f'Average validated loss: {avg_valid_losses}')\n",
    "        \n",
    "    return valid_losses, np.mean(valid_losses), valid_losses_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = files[0]\n",
    "dataset = LazyTextDataset(datafolder + file, sentence_length, skipsos, jagged, bid, delimiter)\n",
    "dataloader = DataLoader(dataset, batch_size=128, num_workers=0)\n",
    "valid_losses, avg_valid_loss, valid_losses_lines = eval_model_line(model, criterion, dataloader, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_losses_by_time = {valid_losses_lines[0][0]: []}\n",
    "this_second = valid_losses_lines[0][0]\n",
    "for second, loss in valid_losses_lines:\n",
    "    if second != this_second:\n",
    "        line_losses_by_time[second] = [loss]\n",
    "        this_second = second\n",
    "    line_losses_by_time[second].append(loss)\n",
    "    \n",
    "percentile75 = []\n",
    "percentile95 = []\n",
    "percentile99 = []\n",
    "for key in line_losses_by_time.keys():\n",
    "    percentile75.append(np.percentile(line_losses_by_time[key], 75))\n",
    "    percentile95.append(np.percentile(line_losses_by_time[key], 95))\n",
    "    percentile99.append(np.percentile(line_losses_by_time[key], 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(percentile75)\n",
    "plt.plot(percentile95)\n",
    "plt.plot(percentile99)\n",
    "\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('x - Second')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - Average loss')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkOOqtkYxGWy"
   },
   "source": [
    "# Check forward LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11223,
     "status": "ok",
     "timestamp": 1616791096518,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "GmgoSqb5xINj",
    "outputId": "1d838f19-479e-4e05-8fb4-b883894c6c03"
   },
   "outputs": [],
   "source": [
    "file = \"2head.txt\"\n",
    "dataset = LazyTextDataset(datafolder + file, sentence_length, skipsos, jagged, bid, delimiter)\n",
    "model.eval()\n",
    "test_input = torch.unsqueeze(dataset[1]['x'], dim=0)\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "output, lstm_out, hx = model(test_input)\n",
    "print(f\"Ground truth: {dataset[1]['t']}\")\n",
    "print(f'Model prediction: {torch.argmax(output, dim=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the tiered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context_size = [10]\n",
    "layer_list = [5] #hidden units of each layer.\n",
    "num_steps = 3\n",
    "model = Tiered_LSTM(layer_list, context_size, vocab_size, embedding_dim, context_size[0], jagged = False, bid = False)\n",
    "data_handler = OnlineLMBatcher(datafolder + files[0], conf, context_size, skipsos, jagged, bid, batch_size=64, num_steps=num_steps, delimiter=\" \", skiprows=0)\n",
    "criterion = nn.CrossEntropyLoss(reduction= 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=0.99)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_tiered(model, criterion, optimizer, scheduler, early_stopping, data_handler, cuda, jagged, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gdp0FidFQhu3"
   },
   "source": [
    "### (By overfitting LSTM model on a small dataset, let me check whether the model has ability to learn the relation between input and output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11534,
     "status": "ok",
     "timestamp": 1616791096836,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "-1B5aPzMxJlT"
   },
   "outputs": [],
   "source": [
    "# mb_size = 1\n",
    "test_batch_size = 1\n",
    "sos = torch.zeros(mb_size * test_batch_size, 1, dtype=torch.long)\n",
    "eos = torch.ones(mb_size * test_batch_size, 1, dtype=torch.long)\n",
    "ex_sentences = torch.LongTensor(mb_size * test_batch_size, conf['sentence_length']-2 ).random_(0, vocab_size)\n",
    "example_sentences = torch.cat((sos, ex_sentences, eos), axis=1)\n",
    "\n",
    "startx = int(skipsos)+ int(jagged)\n",
    "startt = int(skipsos)+ int(jagged) + 1\n",
    "endx = example_sentences.shape[1]- int(not(bid))\n",
    "endt = example_sentences.shape[1] - int(bid)\n",
    "\n",
    "input_sentences = np.split(example_sentences[:,startx:endx], test_batch_size)\n",
    "output_sentences = np.split(example_sentences[:,startt:endt], test_batch_size)\n",
    "data = []\n",
    "\n",
    "for x, t in zip(input_sentences, output_sentences):\n",
    "    tmp_dict={}\n",
    "    tmp_dict['x'] = x\n",
    "    tmp_dict['t'] = t\n",
    "    data.append(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230187,
     "status": "ok",
     "timestamp": 1616791315493,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "cOM7J2Y_xK67",
    "outputId": "816014f3-6122-4e12-a120-97c2d928c7a3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Fwd_LSTM(layer_list, vocab_size, embedding_dim) #For bidirectional LSTM bid_LSTM(layer_list, vocab_size, embedding_dim)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma=1)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=False)\n",
    "epochs = 3000\n",
    "model, train_losses = train_model(model, criterion, optimizer, scheduler, early_stopping, data, cuda, jagged, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 230183,
     "status": "ok",
     "timestamp": 1616791315494,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "lyMnmxlJKxBP",
    "outputId": "2597d9cc-4d54-4003-99c1-5e451a619137"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('x - Number of batch')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - Average loss')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230515,
     "status": "ok",
     "timestamp": 1616791315830,
     "user": {
      "displayName": "김영우",
      "photoUrl": "",
      "userId": "05084645099903710941"
     },
     "user_tz": -60
    },
    "id": "cgNPbcpU57Zp",
    "outputId": "696824d1-e674-421f-c2cd-aa43c965d854"
   },
   "outputs": [],
   "source": [
    "test_input = data[0]['x']\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "output, lstm_out, hx = model(test_input[:5,:])\n",
    "print(f\"Ground truth: \\n {data[0]['t'][:5,:]}\")\n",
    "print(f'Model prediction: \\n {torch.argmax(output, dim=2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1rIDpHKr5dyYDqgfJHqEe",
   "collapsed_sections": [],
   "mount_file_id": "1XofCw7SikjyLrq8NHxPt_E_C2eQksVny",
   "name": "Test_code(Dataloader + LSTM + Training loop).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}